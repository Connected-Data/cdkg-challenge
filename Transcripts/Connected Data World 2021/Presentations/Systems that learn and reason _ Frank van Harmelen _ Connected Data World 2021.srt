1
00:00:07,380 --> 00:00:09,080
Good morning or
good afternoon,

2
00:00:09,220 --> 00:00:10,740
depending on wherever you are

3
00:00:10,740 --> 00:00:12,840
on the globe when you
are watching this.

4
00:00:14,385 --> 00:00:15,845
My name is Frank van Harmelen,

5
00:00:16,065 --> 00:00:17,425
and I would like
to discuss with

6
00:00:17,425 --> 00:00:19,585
you in the next half hour AI

7
00:00:19,585 --> 00:00:22,085
systems that learn
and reason.

8
00:00:25,540 --> 00:00:27,220
So first, let's take a,

9
00:00:27,380 --> 00:00:28,740
a broader look at at where I

10
00:00:28,900 --> 00:00:30,760
where modern AI is is going.

11
00:00:31,085 --> 00:00:33,245
So here are are
just two quotes

12
00:00:33,245 --> 00:00:35,085
from from recent
blogs and from

13
00:00:35,085 --> 00:00:36,945
the web page of
recent AI centers

14
00:00:37,245 --> 00:00:38,305
that have been initiated.

15
00:00:39,340 --> 00:00:41,340
And they all talk about making

16
00:00:41,340 --> 00:00:42,780
artificial intelligence more

17
00:00:42,780 --> 00:00:43,600
human centered,

18
00:00:44,220 --> 00:00:46,220
making AI systems that support

19
00:00:46,220 --> 00:00:48,240
people and that are
competent partners.

20
00:00:48,865 --> 00:00:51,825
So the emphasis
in modern AI is

21
00:00:51,825 --> 00:00:53,605
is less on replacing,

22
00:00:54,625 --> 00:00:56,005
people by AI systems,

23
00:00:56,225 --> 00:00:58,405
but more on AI systems that

24
00:00:58,930 --> 00:01:01,010
collaborate with people and

25
00:01:01,010 --> 00:01:01,910
support them.

26
00:01:02,210 --> 00:01:04,070
But at the same time,

27
00:01:04,690 --> 00:01:06,815
here's another quote
from a popular

28
00:01:06,815 --> 00:01:08,735
blog, current AI systems are

29
00:01:08,735 --> 00:01:10,815
often incompetent because they

30
00:01:10,815 --> 00:01:12,015
lack background and,

31
00:01:12,255 --> 00:01:13,555
and contextual knowledge,

32
00:01:13,750 --> 00:01:15,270
and they cannot even explain

33
00:01:15,270 --> 00:01:17,450
their actions.
And so, clearly,

34
00:01:18,470 --> 00:01:19,830
current AI systems with their

35
00:01:19,830 --> 00:01:20,950
lack of background
knowledge and

36
00:01:20,950 --> 00:01:22,070
and their lack of contextual

37
00:01:22,070 --> 00:01:23,450
knowledge and their lack of

38
00:01:23,795 --> 00:01:25,255
ability to explain
themselves,

39
00:01:26,115 --> 00:01:27,555
they are not very
human centered,

40
00:01:27,555 --> 00:01:29,155
and they cannot
support people,

41
00:01:29,155 --> 00:01:30,935
and they cannot be
competent partners.

42
00:01:32,520 --> 00:01:35,340
Right. So, what's
holding AI back?

43
00:01:35,400 --> 00:01:37,960
Right. So why are
we in the situation

44
00:01:37,960 --> 00:01:38,840
where, on the one hand,

45
00:01:38,840 --> 00:01:40,445
we would like to build systems

46
00:01:40,445 --> 00:01:41,645
that support and collaborate

47
00:01:41,645 --> 00:01:44,145
with people, but on
the other hand,

48
00:01:44,365 --> 00:01:46,845
our systems are
somehow incompetent

49
00:01:46,845 --> 00:01:48,205
and they lack
background knowledge

50
00:01:48,205 --> 00:01:49,745
and contextual knowledge about

51
00:01:50,030 --> 00:01:51,890
the tasks that we
ask them to do.

52
00:01:52,510 --> 00:01:55,550
And, a a common analysis these

53
00:01:55,550 --> 00:01:57,710
days is that what's holding AI

54
00:01:57,710 --> 00:01:59,885
back is that for a long time,

55
00:01:59,885 --> 00:02:01,165
AI researchers have locked

56
00:02:01,165 --> 00:02:03,985
themselves into one
of two towers.

57
00:02:04,125 --> 00:02:06,845
Now we all know
the famous story

58
00:02:06,845 --> 00:02:08,910
of the two towers. Right?

59
00:02:08,910 --> 00:02:11,570
And, in the case of AI,

60
00:02:11,950 --> 00:02:13,650
we could call
these the symbolic

61
00:02:13,790 --> 00:02:16,370
AI tower and
the statistical AI tower.

62
00:02:17,405 --> 00:02:19,805
And as as always in a kingdom

63
00:02:19,805 --> 00:02:21,025
with with two towers,

64
00:02:21,085 --> 00:02:23,165
one tower thinks
that the other

65
00:02:23,165 --> 00:02:25,885
tower is evil and
that they are

66
00:02:25,885 --> 00:02:27,790
wrong and that you should not

67
00:02:27,790 --> 00:02:30,210
really discuss,
with with them.

68
00:02:30,430 --> 00:02:32,450
You should even
fight them maybe.

69
00:02:32,990 --> 00:02:34,885
And in fact,
maybe there's even

70
00:02:34,885 --> 00:02:36,485
another analogy
that is appropriate

71
00:02:36,485 --> 00:02:38,405
here, which is that AI was not

72
00:02:38,405 --> 00:02:40,085
only divided as two
towers, but maybe,

73
00:02:40,085 --> 00:02:42,300
you know, people even had sort

74
00:02:42,300 --> 00:02:43,580
of different religions about

75
00:02:43,580 --> 00:02:44,720
what AI should be.

76
00:02:44,940 --> 00:02:46,400
You could either be
of the statistical

77
00:02:46,620 --> 00:02:48,300
AI religion, in which case you

78
00:02:48,300 --> 00:02:51,055
would build neural
networks, and train,

79
00:02:52,155 --> 00:02:53,375
machine learning programs,

80
00:02:53,595 --> 00:02:55,375
or you were of
the symbolic AI,

81
00:02:56,475 --> 00:02:57,835
religion, in which case you

82
00:02:57,835 --> 00:02:59,035
would build knowledge bases,

83
00:02:59,035 --> 00:03:00,540
you would build
very large large

84
00:03:00,540 --> 00:03:01,660
models graphs, and you do

85
00:03:01,660 --> 00:03:02,720
inference over them.

86
00:03:03,020 --> 00:03:05,740
And just as with
religions, you know,

87
00:03:05,740 --> 00:03:07,420
statistical AI
and symbolic AI,

88
00:03:07,420 --> 00:03:08,355
they had their own books,

89
00:03:08,355 --> 00:03:09,315
they had their own meetings,

90
00:03:09,315 --> 00:03:10,355
and you didn't really need to

91
00:03:10,355 --> 00:03:11,875
talk to each other
because, you know,

92
00:03:11,875 --> 00:03:13,415
the other people
were wrong anyway.

93
00:03:14,835 --> 00:03:15,555
And fortunately,

94
00:03:15,555 --> 00:03:16,960
I I think in
the last few years,

95
00:03:16,960 --> 00:03:19,040
we are beginning to see in AI

96
00:03:19,040 --> 00:03:21,480
an increasing
movement that these,

97
00:03:21,920 --> 00:03:24,260
these two different
streams in AI,

98
00:03:24,505 --> 00:03:25,545
they are beginning to talk to

99
00:03:25,545 --> 00:03:26,585
each other, and
they are beginning

100
00:03:26,585 --> 00:03:27,245
to understand,

101
00:03:28,425 --> 00:03:30,045
that we actually
need them both

102
00:03:30,185 --> 00:03:32,740
because our brain
uses both. Right?

103
00:03:32,740 --> 00:03:35,780
Our brain does
both the the stuff

104
00:03:35,780 --> 00:03:37,620
that that machine
learning is good at,

105
00:03:37,620 --> 00:03:38,660
and it does the stuff that

106
00:03:38,660 --> 00:03:40,285
knowledge representation
is good at.

107
00:03:41,645 --> 00:03:44,125
So here is, a very
rough sketch

108
00:03:44,125 --> 00:03:45,645
of what's going
on in our brain

109
00:03:45,645 --> 00:03:47,485
when we look at
an image. Right?

110
00:03:47,485 --> 00:03:49,440
So here's a a cross cutting of

111
00:03:49,440 --> 00:03:50,080
somebody's brain.

112
00:03:50,080 --> 00:03:51,840
They're looking out
towards the right.

113
00:03:51,840 --> 00:03:52,880
It's their eye.

114
00:03:52,880 --> 00:03:54,100
So what happens when,

115
00:03:54,640 --> 00:03:55,940
light hits the retina?

116
00:03:56,055 --> 00:03:57,415
Well, when light
hits the retina,

117
00:03:57,415 --> 00:03:58,535
of course, there
is the optical

118
00:03:58,535 --> 00:04:00,875
nerve that go to
the visual cortex.

119
00:04:00,935 --> 00:04:03,015
Right? We call this
the the bottom

120
00:04:03,015 --> 00:04:04,610
up signal. Right?

121
00:04:04,610 --> 00:04:06,050
And this this
bottom up signal,

122
00:04:06,050 --> 00:04:07,510
when it hits
the visual cortex,

123
00:04:07,730 --> 00:04:10,530
the visual cortex
analyzes, forms,

124
00:04:10,530 --> 00:04:12,370
shapes. It it
recognizes separate

125
00:04:12,370 --> 00:04:14,070
objects. It
recognizes motion.

126
00:04:14,435 --> 00:04:16,295
It recognizes object
of conclusion,

127
00:04:16,995 --> 00:04:19,095
and, it interprets the scene.

128
00:04:19,315 --> 00:04:21,235
And these signals
then go to our

129
00:04:21,235 --> 00:04:23,960
prefrontal cortex,
where we have,

130
00:04:24,280 --> 00:04:25,800
memory, where we do planning,

131
00:04:25,800 --> 00:04:27,000
where we do problem solving.

132
00:04:28,600 --> 00:04:31,580
But interestingly
enough, in our brain,

133
00:04:32,035 --> 00:04:34,855
there is also
a downstream signal.

134
00:04:35,075 --> 00:04:37,575
Namely, the prefrontal cortex

135
00:04:37,635 --> 00:04:39,395
is continuously
telling the visual

136
00:04:39,395 --> 00:04:41,095
cortex what to expect.

137
00:04:41,620 --> 00:04:43,060
So it's not just a matter of

138
00:04:43,060 --> 00:04:44,660
the pixels feeding
the symbolic

139
00:04:44,660 --> 00:04:46,900
representation,
it's also a matter

140
00:04:46,900 --> 00:04:48,280
of the symbolic representation

141
00:04:49,265 --> 00:04:51,125
telling the pixel processors,

142
00:04:51,985 --> 00:04:53,265
what to expect and how to

143
00:04:53,265 --> 00:04:54,225
interpret all these pixels.

144
00:04:54,225 --> 00:04:56,725
And in fact, without
such a downstream

145
00:04:56,865 --> 00:04:58,330
signal, our visual
cortex would

146
00:04:58,330 --> 00:05:00,650
never be fast
enough to interpret

147
00:05:00,650 --> 00:05:02,350
all the visual signals
that come in.

148
00:05:03,370 --> 00:05:05,050
And, and actually,

149
00:05:05,050 --> 00:05:06,430
the downstream nerves,

150
00:05:07,505 --> 00:05:09,925
are actually larger
than the upstream.

151
00:05:10,145 --> 00:05:12,465
So there is
a a constant traffic

152
00:05:12,465 --> 00:05:14,965
up and down between
the symbolic

153
00:05:15,025 --> 00:05:17,890
and the statistical
parts of our brain,

154
00:05:17,890 --> 00:05:21,110
if you allow me that,
that freedom.

155
00:05:21,890 --> 00:05:23,730
So now we could
call the upstream

156
00:05:23,730 --> 00:05:24,930
signal data driven,

157
00:05:24,930 --> 00:05:27,735
as in neural networks,
machine learning,

158
00:05:27,735 --> 00:05:29,755
and we call
the the downstream,

159
00:05:30,855 --> 00:05:32,555
signal knowledge driven.

160
00:05:34,810 --> 00:05:36,090
And, actually, the history of

161
00:05:36,090 --> 00:05:37,370
AI also shows this.

162
00:05:37,370 --> 00:05:40,010
It it is not the case
that the history

163
00:05:40,010 --> 00:05:41,130
of AI in the past,

164
00:05:41,130 --> 00:05:42,465
we did symbolic stuff,

165
00:05:42,465 --> 00:05:44,305
and now we realize
that the symbolic

166
00:05:44,305 --> 00:05:46,885
stuff was, wrong or
somehow mistaken.

167
00:05:47,345 --> 00:05:48,945
And now we are
seeing the light

168
00:05:48,945 --> 00:05:50,945
and we're doing neural
networks and and,

169
00:05:51,185 --> 00:05:52,405
we're making good progress.

170
00:05:53,730 --> 00:05:55,090
The actual history of AI has

171
00:05:55,090 --> 00:05:56,690
been a constant
pendulum between

172
00:05:56,690 --> 00:05:57,570
these two streams,

173
00:05:57,570 --> 00:05:59,010
and frequency of this pendulum

174
00:05:59,010 --> 00:05:59,990
is about a decade.

175
00:06:01,195 --> 00:06:03,835
And, and certainly
in the last decade,

176
00:06:03,835 --> 00:06:05,915
we have seen large major

177
00:06:05,915 --> 00:06:08,415
breakthroughs in
the the the connectionist

178
00:06:08,880 --> 00:06:10,480
data driven
statistical machine

179
00:06:10,480 --> 00:06:12,500
learning, part of AI.

180
00:06:13,600 --> 00:06:15,380
But we have also
seen important,

181
00:06:16,960 --> 00:06:19,635
scale up, in
the the symbolic,

182
00:06:20,255 --> 00:06:22,015
and knowledge
based logic driven

183
00:06:22,015 --> 00:06:23,395
and reasoning part of AI.

184
00:06:23,775 --> 00:06:25,555
And, we are now
seeing the pendulum

185
00:06:25,695 --> 00:06:27,490
swinging back to the middle of

186
00:06:27,490 --> 00:06:28,950
this spectrum,
and, hopefully,

187
00:06:29,010 --> 00:06:30,130
we can this time,

188
00:06:30,130 --> 00:06:31,650
we managed to
stop the pendulum

189
00:06:31,650 --> 00:06:32,610
somewhere in
the middle so that

190
00:06:32,610 --> 00:06:33,910
we can combine these two.

191
00:06:35,145 --> 00:06:36,585
Now to put a little bit more

192
00:06:36,585 --> 00:06:38,125
flesh on this comparison,

193
00:06:38,825 --> 00:06:39,725
now let's compare,

194
00:06:40,825 --> 00:06:42,425
these two streams of AI,

195
00:06:42,425 --> 00:06:45,750
and and here is a a table that

196
00:06:45,750 --> 00:06:47,670
that very briefly
compares the strength

197
00:06:47,670 --> 00:06:49,030
and and weaknesses of AI.

198
00:06:49,030 --> 00:06:50,810
So let me go through
this table.

199
00:06:51,325 --> 00:06:52,925
So first of all,

200
00:06:52,925 --> 00:06:55,245
the the construction
costs. Right?

201
00:06:55,245 --> 00:06:57,105
So as we know,

202
00:06:58,270 --> 00:07:02,130
symbolic AI and and
for this, audience,

203
00:07:02,670 --> 00:07:04,190
you are all very familiar with

204
00:07:04,190 --> 00:07:05,730
with very large model graphs.

205
00:07:06,075 --> 00:07:07,435
These very large
knowledge graphs,

206
00:07:07,435 --> 00:07:09,935
they are, not they are large.

207
00:07:09,995 --> 00:07:11,915
They contain billions of facts

208
00:07:11,915 --> 00:07:12,575
and rules,

209
00:07:13,140 --> 00:07:14,900
but they are
expensive to build

210
00:07:14,900 --> 00:07:16,120
and expensive to maintain.

211
00:07:16,900 --> 00:07:18,200
So either
through crowdsourcing

212
00:07:19,060 --> 00:07:22,040
or through corporate,
investments.

213
00:07:22,595 --> 00:07:24,115
Right, but they are expensive

214
00:07:24,115 --> 00:07:27,255
to build at midday.

215
00:07:27,315 --> 00:07:29,395
But the connectionist approach

216
00:07:29,395 --> 00:07:31,015
also has its
construction costs

217
00:07:31,200 --> 00:07:32,480
and here the construction cost

218
00:07:32,480 --> 00:07:33,700
is called data hunger.

219
00:07:34,800 --> 00:07:36,800
So many of you
will be familiar

220
00:07:36,800 --> 00:07:38,640
with the Nvidia
benchmark where

221
00:07:38,640 --> 00:07:41,355
Nvidia scraped, millions of,

222
00:07:41,755 --> 00:07:43,615
faces of people
from the Internet

223
00:07:43,995 --> 00:07:45,275
and trained the neural network

224
00:07:45,275 --> 00:07:47,615
to generate new faces. Right?

225
00:07:47,720 --> 00:07:49,000
Now the neural network is so

226
00:07:49,000 --> 00:07:50,600
good that that humans can no

227
00:07:50,600 --> 00:07:52,440
longer distinguish
between real

228
00:07:52,440 --> 00:07:54,140
faces and and
generated faces,

229
00:07:54,735 --> 00:07:56,255
but it took ten
million training

230
00:07:56,255 --> 00:07:58,355
samples to train
the network for this.

231
00:07:58,495 --> 00:07:59,055
And, of course,

232
00:07:59,055 --> 00:08:01,135
NVIDIA was very
clever in choosing

233
00:08:01,135 --> 00:08:03,470
this domain because
for human faces,

234
00:08:03,470 --> 00:08:05,310
we can actually
scrape ten million

235
00:08:05,310 --> 00:08:06,850
training examples
from the web,

236
00:08:07,310 --> 00:08:09,090
but now try to do
this for, say,

237
00:08:09,765 --> 00:08:11,765
rare cancer tumors. Right?

238
00:08:11,765 --> 00:08:13,545
So images of rare tumors.

239
00:08:13,845 --> 00:08:15,285
You cannot obtain ten million

240
00:08:15,285 --> 00:08:16,745
ten million training sample.

241
00:08:17,500 --> 00:08:19,360
The same holds
for for AlphaGo.

242
00:08:20,060 --> 00:08:21,020
You know, the famous,

243
00:08:21,660 --> 00:08:22,780
DeepMind program that,

244
00:08:23,020 --> 00:08:23,980
that beat the best,

245
00:08:25,155 --> 00:08:26,775
human Go player in the world,

246
00:08:27,475 --> 00:08:29,235
it took four point
eight million

247
00:08:29,235 --> 00:08:30,135
training games,

248
00:08:30,355 --> 00:08:33,015
mostly AlphaGo training
against itself.

249
00:08:33,120 --> 00:08:34,960
And, again, game
playing is a domain

250
00:08:34,960 --> 00:08:36,640
where you can basically,

251
00:08:36,640 --> 00:08:37,840
you have infinite amounts of

252
00:08:37,840 --> 00:08:38,740
training material.

253
00:08:39,360 --> 00:08:40,720
And, again, this
is not true in

254
00:08:40,720 --> 00:08:42,820
in most of
the the business cases,

255
00:08:43,245 --> 00:08:44,625
that you would
meet in practice.

256
00:08:45,485 --> 00:08:47,245
So I'm always a little
bit annoyed when,

257
00:08:47,565 --> 00:08:49,005
machine learning people tell

258
00:08:49,005 --> 00:08:49,725
their customers, well,

259
00:08:49,725 --> 00:08:50,845
we can't really
help you because

260
00:08:50,845 --> 00:08:52,145
you don't have enough data.

261
00:08:52,550 --> 00:08:54,150
Well, it's not the case
of the customer

262
00:08:54,150 --> 00:08:55,370
not having enough data.

263
00:08:55,670 --> 00:08:56,870
The problem is
that the machine

264
00:08:56,870 --> 00:08:58,810
learning algorithms
need too much data.

265
00:08:59,405 --> 00:09:00,525
So you see that,

266
00:09:00,925 --> 00:09:02,305
they have sort
of complementary

267
00:09:02,525 --> 00:09:03,985
strengths and
weaknesses here.

268
00:09:05,805 --> 00:09:08,760
And, as we know, these
symbolic methods,

269
00:09:08,760 --> 00:09:10,060
they suffer from
the combinatorial

270
00:09:10,200 --> 00:09:11,480
explosion. Right?

271
00:09:11,480 --> 00:09:14,140
So they they get worse
with more data.

272
00:09:14,360 --> 00:09:15,660
Right? This is called
the combinatorial

273
00:09:15,800 --> 00:09:17,425
explosion. But the connection

274
00:09:17,425 --> 00:09:18,865
is the neural
network approaches,

275
00:09:18,865 --> 00:09:20,405
they get worse
with less data.

276
00:09:20,945 --> 00:09:22,945
Right? So, they
they suffer from

277
00:09:22,945 --> 00:09:23,905
this data hunger.

278
00:09:23,905 --> 00:09:25,285
So again, very complimentary

279
00:09:25,425 --> 00:09:26,910
strength and weaknesses.

280
00:09:28,970 --> 00:09:30,430
Another, you know,

281
00:09:30,570 --> 00:09:32,350
by now well
known complementary

282
00:09:32,490 --> 00:09:34,010
strength and
weakness of the two

283
00:09:34,010 --> 00:09:35,875
systems are their
explainability.

284
00:09:36,575 --> 00:09:37,795
These symbolic systems,

285
00:09:38,175 --> 00:09:39,715
they have the advantage that

286
00:09:39,935 --> 00:09:41,855
their vocabulary is very close

287
00:09:41,855 --> 00:09:43,475
to the vocabulary
that people,

288
00:09:43,940 --> 00:09:46,500
everyday people
or experts, use.

289
00:09:46,500 --> 00:09:49,240
So here is a rule
about a particular

290
00:09:49,300 --> 00:09:52,040
medical system, sim
a medical symptom,

291
00:09:52,260 --> 00:09:56,965
dysphagia, which,
then causes,

292
00:09:58,865 --> 00:10:00,625
some, a particular
conclusion,

293
00:10:00,625 --> 00:10:02,440
namely a medical
diagnosis. Right?

294
00:10:02,440 --> 00:10:03,320
So we have a variable,

295
00:10:03,320 --> 00:10:04,140
we have a condition,

296
00:10:04,520 --> 00:10:05,420
we have a conclusion,

297
00:10:05,720 --> 00:10:07,660
and this is in
an understandable format.

298
00:10:08,120 --> 00:10:09,640
And, as we all know,

299
00:10:09,640 --> 00:10:11,405
these neural networks
don't have this.

300
00:10:11,565 --> 00:10:13,725
Here's a famous example from

301
00:10:13,725 --> 00:10:15,825
the literature
where researchers

302
00:10:15,885 --> 00:10:17,425
took a neural network that,

303
00:10:18,125 --> 00:10:19,405
with reasonable confidence,

304
00:10:19,405 --> 00:10:21,185
recognized this
picture as a panda,

305
00:10:21,870 --> 00:10:23,790
and then they added noise to

306
00:10:23,790 --> 00:10:25,310
the picture, noise that is

307
00:10:25,310 --> 00:10:27,010
invisible to the human eye,

308
00:10:27,470 --> 00:10:28,290
and suddenly,

309
00:10:28,830 --> 00:10:30,905
the picture
the the neural network

310
00:10:30,905 --> 00:10:32,525
recognized the picture
as a given.

311
00:10:33,625 --> 00:10:36,025
Now you would
want to know what

312
00:10:36,025 --> 00:10:37,465
went wrong, what
happened between

313
00:10:37,465 --> 00:10:38,910
this one picture and the other

314
00:10:38,910 --> 00:10:40,110
picture when we can't even see

315
00:10:40,110 --> 00:10:40,510
the difference.

316
00:10:40,510 --> 00:10:42,910
Now what
the the neural network

317
00:10:42,910 --> 00:10:44,610
engineers did is
they carefully

318
00:10:44,670 --> 00:10:47,090
added noise from
the picture of a given,

319
00:10:47,515 --> 00:10:50,655
and they carefully
drove the network

320
00:10:50,715 --> 00:10:53,375
down into another
local minimum

321
00:10:53,995 --> 00:10:55,630
in the high dimensional,

322
00:10:57,210 --> 00:10:59,950
fitness landscape
where the network

323
00:11:00,010 --> 00:11:01,950
training does
gradient descent.

324
00:11:02,405 --> 00:11:04,485
Okay. Now that's clearly not

325
00:11:04,485 --> 00:11:06,485
an explanation
that you can give

326
00:11:06,485 --> 00:11:08,085
to to any reasonable user of

327
00:11:08,085 --> 00:11:09,765
such a network of
of such a neural

328
00:11:09,765 --> 00:11:10,885
network. So this is known as

329
00:11:10,885 --> 00:11:11,945
the black box problem.

330
00:11:13,650 --> 00:11:15,810
And finally, as we well know,

331
00:11:15,810 --> 00:11:17,410
symbolic systems suffer from

332
00:11:17,410 --> 00:11:19,110
what's called
the performance cliff.

333
00:11:19,935 --> 00:11:21,295
Think again of
a knowledge graph.

334
00:11:21,295 --> 00:11:23,215
If you query
the knowledge graph

335
00:11:23,215 --> 00:11:24,735
for facts that are
in the knowledge

336
00:11:24,735 --> 00:11:26,515
graph, you get very
high quality,

337
00:11:26,815 --> 00:11:28,595
you know, both
precision and recall.

338
00:11:29,060 --> 00:11:31,140
But if you start
querying it for

339
00:11:31,140 --> 00:11:32,820
stuff that is outside
the knowns graph,

340
00:11:32,820 --> 00:11:34,500
basically, you get
no answer. Right?

341
00:11:34,500 --> 00:11:36,040
So there's a very
steep performance

342
00:11:36,100 --> 00:11:39,605
cliff. But, also,

343
00:11:39,605 --> 00:11:41,065
these connectionist
approaches,

344
00:11:41,445 --> 00:11:44,105
they suffer from
a a performance cliff.

345
00:11:44,250 --> 00:11:46,270
Right? Here's a famous
example from,

346
00:11:47,770 --> 00:11:50,090
an an an image
labeling competition

347
00:11:50,090 --> 00:11:51,770
a few years ago, and
the question was,

348
00:11:51,770 --> 00:11:53,950
what is this lady
wearing on our head?

349
00:11:54,175 --> 00:11:56,255
And the answer was with near

350
00:11:56,255 --> 00:11:57,315
hundred percent certainty,

351
00:11:57,375 --> 00:11:58,915
she's wearing a shower cap.

352
00:12:00,255 --> 00:12:01,775
Now, we all know that this is

353
00:12:01,775 --> 00:12:02,835
not a shower cap,

354
00:12:03,630 --> 00:12:05,150
because we recognize this lady

355
00:12:05,150 --> 00:12:07,010
and we know that
she's the queen,

356
00:12:07,390 --> 00:12:09,070
and we know what
queens do with

357
00:12:09,070 --> 00:12:10,350
shower caps, they don't wear

358
00:12:10,350 --> 00:12:11,170
them in public,

359
00:12:11,230 --> 00:12:12,535
so so this cannot possibly be

360
00:12:12,535 --> 00:12:13,895
a shower cap. Why
does the system

361
00:12:13,895 --> 00:12:15,435
think this is a shower cap?

362
00:12:15,575 --> 00:12:18,075
Well, probably in
the training set,

363
00:12:18,510 --> 00:12:19,810
there were not very many,

364
00:12:20,350 --> 00:12:22,030
training examples of ladies

365
00:12:22,030 --> 00:12:24,130
wearing tiaras,
wearing crowns.

366
00:12:24,830 --> 00:12:26,370
And maybe there were examples

367
00:12:26,430 --> 00:12:28,335
of of people wearing
shower caps.

368
00:12:29,295 --> 00:12:30,895
So this is a typical case of

369
00:12:30,895 --> 00:12:33,135
an out of sample very poor out

370
00:12:33,135 --> 00:12:34,035
of sample generalizability.

371
00:12:35,215 --> 00:12:36,575
That's the performance
cliff of

372
00:12:36,575 --> 00:12:37,555
connection systems.

373
00:12:38,480 --> 00:12:40,560
So if we then see that these

374
00:12:40,560 --> 00:12:41,700
systems have complementary

375
00:12:41,840 --> 00:12:42,740
strengths and weaknesses,

376
00:12:43,600 --> 00:12:46,260
can we somehow get
them to collaborate?

377
00:12:47,315 --> 00:12:49,655
And and just to
emphasize, you know,

378
00:12:49,715 --> 00:12:51,075
this is this performance cliff

379
00:12:51,075 --> 00:12:53,575
is is not an an an artificial
example.

380
00:12:54,090 --> 00:12:56,010
Here are all reasonable stop

381
00:12:56,010 --> 00:12:57,770
signs as you would
find them in

382
00:12:57,770 --> 00:13:00,490
practice. Some
funny guy has put

383
00:13:00,490 --> 00:13:01,855
a sticker on it or there is

384
00:13:01,855 --> 00:13:03,295
funny shape shadows on it,

385
00:13:03,295 --> 00:13:04,495
and these are all
recognized as

386
00:13:04,495 --> 00:13:06,035
a maximum speed limit sign.

387
00:13:06,415 --> 00:13:08,335
So this is clearly
a realistic problem.

388
00:13:08,335 --> 00:13:10,160
So can we solve such realistic

389
00:13:10,160 --> 00:13:12,080
problems with
the machine learning

390
00:13:12,080 --> 00:13:14,560
systems by getting them to

391
00:13:14,560 --> 00:13:16,560
collaborate with
the symbolic systems?

392
00:13:16,560 --> 00:13:17,905
Right? That's what
what the rest

393
00:13:17,905 --> 00:13:19,345
of the talk is
going to be about.

394
00:13:19,345 --> 00:13:22,165
Can we get
the symbolic systems,

395
00:13:22,625 --> 00:13:23,925
the systems that reason,

396
00:13:24,680 --> 00:13:26,360
and the subsymbolic systems,

397
00:13:26,360 --> 00:13:27,660
the systems that learn,

398
00:13:27,880 --> 00:13:28,780
can we collaborate,

399
00:13:28,920 --> 00:13:30,120
can we get them to collaborate

400
00:13:30,120 --> 00:13:32,700
in a system that both
learn and reasons?

401
00:13:33,725 --> 00:13:35,165
And I will give
you a number of

402
00:13:35,165 --> 00:13:37,645
examples of systems
that do such

403
00:13:37,645 --> 00:13:38,225
a collaboration.

404
00:13:40,525 --> 00:13:42,305
So maybe to this community,

405
00:13:43,120 --> 00:13:44,260
the best example,

406
00:13:44,640 --> 00:13:47,840
the easiest example
is using a learning

407
00:13:47,840 --> 00:13:49,680
system to enrich
a knowledge graph.

408
00:13:49,680 --> 00:13:51,200
This is often called knowledge

409
00:13:51,200 --> 00:13:51,940
graph completion.

410
00:13:53,825 --> 00:13:55,265
So imagine that we
have a knowledge

411
00:13:55,265 --> 00:13:56,405
graph about music,

412
00:13:57,025 --> 00:13:58,545
and we have many links between

413
00:13:58,545 --> 00:13:59,605
artists and songs.

414
00:13:59,745 --> 00:14:01,880
We know that, Michael Jackson

415
00:14:01,880 --> 00:14:03,020
published Beat It,

416
00:14:03,080 --> 00:14:04,200
and we know that the Beatles

417
00:14:04,200 --> 00:14:05,180
published Yesterday,

418
00:14:05,640 --> 00:14:06,780
and we know etcetera.

419
00:14:06,840 --> 00:14:08,680
So we have many links between

420
00:14:08,680 --> 00:14:11,365
artists and, and their songs,

421
00:14:11,425 --> 00:14:13,505
and we that that has
a particular label,

422
00:14:13,505 --> 00:14:14,705
namely that that artist has

423
00:14:14,705 --> 00:14:15,765
published that song.

424
00:14:17,025 --> 00:14:18,465
Now if we take this knowledge

425
00:14:18,465 --> 00:14:19,820
graph and we,

426
00:14:21,160 --> 00:14:23,000
somehow transform
this knowledge

427
00:14:23,000 --> 00:14:25,100
graph into a high dimensional

428
00:14:25,160 --> 00:14:27,100
vector space where,

429
00:14:29,225 --> 00:14:30,425
similarity in the knowledge

430
00:14:30,425 --> 00:14:31,965
graph corresponds
to similarity

431
00:14:32,425 --> 00:14:33,805
in the vector space,

432
00:14:34,425 --> 00:14:35,785
then Michael Jackson
would become

433
00:14:35,785 --> 00:14:37,785
a vector. The song
Beat It would

434
00:14:37,785 --> 00:14:38,685
become a vector.

435
00:14:39,050 --> 00:14:40,330
And the relationship between

436
00:14:40,330 --> 00:14:42,170
Michael Jackson and beat it,

437
00:14:42,170 --> 00:14:43,790
namely the relationship
publish,

438
00:14:44,090 --> 00:14:45,230
is also a vector,

439
00:14:45,930 --> 00:14:47,550
from the between
the two endpoints.

440
00:14:48,365 --> 00:14:50,525
And now we might
recognize that

441
00:14:50,525 --> 00:14:51,965
if we have a vector
for the Rolling

442
00:14:51,965 --> 00:14:54,465
Stones and a vector
for Angie,

443
00:14:55,005 --> 00:14:57,040
that the distance
between the Rolling

444
00:14:57,040 --> 00:14:59,460
Stones and Angie
is very similar

445
00:14:59,520 --> 00:15:00,880
to the distance
between Michael

446
00:15:00,880 --> 00:15:01,940
Jackson and Beatit.

447
00:15:02,560 --> 00:15:06,655
So this may cause
us to learn that,

448
00:15:07,915 --> 00:15:09,275
the relationship
between Rolling

449
00:15:09,275 --> 00:15:11,115
Stones and Angie
is the same as

450
00:15:11,115 --> 00:15:13,280
between Michael
Jackson and Beat It,

451
00:15:13,280 --> 00:15:14,740
namely, it's the relation

452
00:15:15,120 --> 00:15:16,560
published this all. Right?

453
00:15:16,560 --> 00:15:17,760
So in this way,

454
00:15:17,760 --> 00:15:20,240
we can learn new facts to add

455
00:15:20,240 --> 00:15:22,325
to another graph
by using machine

456
00:15:22,325 --> 00:15:23,845
learning methods in this high

457
00:15:23,845 --> 00:15:25,065
dimensional vector space.

458
00:15:26,485 --> 00:15:27,385
So, essentially,

459
00:15:27,525 --> 00:15:28,885
now what we are doing here,

460
00:15:28,885 --> 00:15:30,325
we are are taking a graph

461
00:15:30,325 --> 00:15:32,310
representation. We are turning

462
00:15:32,310 --> 00:15:33,930
it into a real vector
representation,

463
00:15:34,550 --> 00:15:35,370
a high dimensional,

464
00:15:36,070 --> 00:15:38,010
real real number vector
representation.

465
00:15:38,835 --> 00:15:41,155
We do machine learning
in the vector

466
00:15:41,155 --> 00:15:44,115
space, which leads to new

467
00:15:44,115 --> 00:15:45,075
predictions of links,

468
00:15:45,075 --> 00:15:47,315
and we translate
these new links

469
00:15:47,315 --> 00:15:50,510
back to the, to
the symbolic space.

470
00:15:50,810 --> 00:15:53,130
Right? So sometimes
we call this

471
00:15:53,130 --> 00:15:54,090
this this pattern,

472
00:15:54,090 --> 00:15:56,170
we call it from
symbols to data

473
00:15:56,170 --> 00:15:57,045
and back again.

474
00:15:57,045 --> 00:15:58,485
So we started with symbols,

475
00:15:58,485 --> 00:15:59,705
the the knowledge graph.

476
00:16:00,085 --> 00:16:01,605
We produced some data space.

477
00:16:01,605 --> 00:16:03,125
We did machine
learning on the data

478
00:16:03,125 --> 00:16:04,965
space, and we
translated it back

479
00:16:04,965 --> 00:16:06,265
to the symbolic space.

480
00:16:07,390 --> 00:16:09,310
So this is one
combination where

481
00:16:09,310 --> 00:16:12,610
we use learning
systems to improve

482
00:16:13,470 --> 00:16:15,330
the symbolic systems.

483
00:16:17,905 --> 00:16:19,445
So there, we were using,

484
00:16:19,905 --> 00:16:21,925
learning systems to
rule only facts.

485
00:16:21,985 --> 00:16:23,765
Right? So we could
learn new facts,

486
00:16:23,870 --> 00:16:25,390
but there are also
systems where

487
00:16:25,390 --> 00:16:26,690
we learn new rules.

488
00:16:27,950 --> 00:16:30,270
And these, learning
systems are

489
00:16:30,270 --> 00:16:31,710
called inductive
logic programming

490
00:16:31,710 --> 00:16:33,570
systems or rule
mining systems.

491
00:16:34,305 --> 00:16:36,705
So, here's an example from

492
00:16:36,705 --> 00:16:37,925
inductive logic programming.

493
00:16:37,985 --> 00:16:39,605
Suppose that we have
a knowledge base,

494
00:16:39,905 --> 00:16:41,505
a knowledge base
in symbolic form,

495
00:16:41,505 --> 00:16:42,705
this could be
a knowledge graph

496
00:16:42,705 --> 00:16:44,010
about parental relationships.

497
00:16:46,230 --> 00:16:49,450
And we know that,
and we can learn,

498
00:16:51,325 --> 00:16:53,485
from this parent
and this parent,

499
00:16:53,485 --> 00:16:54,785
father, and mother
relationships.

500
00:16:55,005 --> 00:16:56,865
From this, we can
learn the rule

501
00:16:56,925 --> 00:16:59,580
that when that
somebody is a parent,

502
00:16:59,960 --> 00:17:01,560
if somebody is
either the father

503
00:17:01,560 --> 00:17:03,480
or the mother of
that person. Right?

504
00:17:03,480 --> 00:17:05,480
So parent x y if either mother

505
00:17:05,480 --> 00:17:07,100
x y or father x y.

506
00:17:07,705 --> 00:17:09,965
So we can learn
these new rules.

507
00:17:10,425 --> 00:17:12,105
Now we can confront the system

508
00:17:12,105 --> 00:17:13,805
with a new fact,
namely father,

509
00:17:14,585 --> 00:17:15,565
Carrie, Andy.

510
00:17:17,050 --> 00:17:18,250
And together with,

511
00:17:18,650 --> 00:17:19,530
this learned knowledge,

512
00:17:19,530 --> 00:17:21,850
we can now derive
that not only

513
00:17:21,850 --> 00:17:24,445
is Carrie the father
of Andy, but,

514
00:17:25,465 --> 00:17:28,205
Carrie must also be
the parent of Andy.

515
00:17:29,545 --> 00:17:31,145
And this can also
be done on on

516
00:17:31,145 --> 00:17:31,965
knowledge graphs.

517
00:17:32,880 --> 00:17:34,315
AnyBurl, from, Manheim,

518
00:17:34,380 --> 00:17:35,460
is a system that, learns,

519
00:17:36,320 --> 00:17:41,165
rules over knowledge graphs

520
00:17:41,165 --> 00:17:42,625
rather than just
simple facts.

521
00:17:43,405 --> 00:17:44,845
And this doesn't
only work on,

522
00:17:45,165 --> 00:17:46,685
toy examples like the one that

523
00:17:46,685 --> 00:17:47,620
I'm showing you here,

524
00:17:47,620 --> 00:17:49,060
but this has also
been shown to

525
00:17:49,060 --> 00:17:51,080
work on realistic
examples where

526
00:17:51,300 --> 00:17:53,380
we take a, knowledge
graph about

527
00:17:53,380 --> 00:17:55,480
chemical facts,
biochemical facts,

528
00:17:56,065 --> 00:17:57,345
and the scientists
this is an example

529
00:17:57,345 --> 00:17:58,805
from University of Leuven,

530
00:17:59,265 --> 00:18:00,405
where the scientists,

531
00:18:00,545 --> 00:18:02,405
the biochemists wanted to know

532
00:18:02,545 --> 00:18:04,145
which parts of a chemical

533
00:18:04,145 --> 00:18:06,120
structure makes a,

534
00:18:06,440 --> 00:18:09,100
a molecule biologically
active or not.

535
00:18:09,560 --> 00:18:11,640
And so some molecules are

536
00:18:11,640 --> 00:18:13,660
biologically active, like,

537
00:18:14,825 --> 00:18:15,885
and some are not.

538
00:18:16,425 --> 00:18:17,805
So, for example,

539
00:18:22,800 --> 00:18:25,300
Petrol is
biologically active,

540
00:18:25,680 --> 00:18:28,000
but plastic is
biologically very

541
00:18:28,000 --> 00:18:30,640
inactive. But they
are both made

542
00:18:30,640 --> 00:18:35,105
of very similar, molecules.

543
00:18:35,105 --> 00:18:37,105
And by feeding
the system examples

544
00:18:37,105 --> 00:18:39,125
of molecules and labeling them

545
00:18:39,425 --> 00:18:41,105
as biologically
active as as in

546
00:18:41,265 --> 00:18:42,950
and inactive,
according to what

547
00:18:42,950 --> 00:18:43,930
chemists know,

548
00:18:44,710 --> 00:18:46,310
the system could
learn the rule

549
00:18:46,310 --> 00:18:47,670
that this
substructure that you

550
00:18:47,670 --> 00:18:48,790
see here on the right,

551
00:18:48,790 --> 00:18:50,730
this substructure
is responsible

552
00:18:51,110 --> 00:18:53,725
for a a a molecule being

553
00:18:53,725 --> 00:18:55,345
biologically active or not.

554
00:18:57,005 --> 00:18:59,085
So in all of
the examples we've

555
00:18:59,085 --> 00:19:01,070
seen so far are examples of

556
00:19:01,070 --> 00:19:03,410
where a learning
system improves

557
00:19:03,630 --> 00:19:04,770
a symbolic system.

558
00:19:04,990 --> 00:19:06,590
But we can also
turn this the other

559
00:19:06,590 --> 00:19:07,250
way around.

560
00:19:09,825 --> 00:19:12,305
So we can also use a knowledge

561
00:19:12,305 --> 00:19:14,245
system to improve
a learning system.

562
00:19:15,800 --> 00:19:16,680
Here's an example.

563
00:19:16,680 --> 00:19:18,200
Let let's take
the previous example.

564
00:19:18,200 --> 00:19:20,460
Now where now why
is this a crown?

565
00:19:20,840 --> 00:19:23,320
Right? Why is this
a and and not

566
00:19:23,320 --> 00:19:25,795
a a shower cap? K?

567
00:19:26,175 --> 00:19:27,795
Now if we have
a neural network,

568
00:19:28,255 --> 00:19:30,595
that, neural network
will generate

569
00:19:30,655 --> 00:19:31,875
a whole set of hypotheses,

570
00:19:33,340 --> 00:19:34,560
ranked with confidence.

571
00:19:35,820 --> 00:19:38,080
And because of bad,
out of training,

572
00:19:38,860 --> 00:19:40,080
set, generalizability,

573
00:19:41,635 --> 00:19:43,315
the shower cap ended up with

574
00:19:43,315 --> 00:19:44,535
the highest probability.

575
00:19:45,395 --> 00:19:48,055
But if we now feed all these,

576
00:19:49,120 --> 00:19:50,400
hypotheses, these possible

577
00:19:50,400 --> 00:19:52,740
predictions into
a knowledge graph,

578
00:19:53,280 --> 00:19:54,640
and the knowledge
graph can tell

579
00:19:54,640 --> 00:19:56,320
us that there's a very close

580
00:19:56,320 --> 00:19:57,760
relationship between queen and

581
00:19:57,760 --> 00:19:59,825
crown with a very
long distance

582
00:19:59,825 --> 00:20:01,265
relationship between queen and

583
00:20:01,265 --> 00:20:03,265
shower cap, then the knowledge

584
00:20:03,265 --> 00:20:04,945
graph will help us to select

585
00:20:04,945 --> 00:20:06,705
the right hypothesis
and tell us that,

586
00:20:06,705 --> 00:20:09,310
well, if we have to
choose between,

587
00:20:09,770 --> 00:20:11,390
a crown and a shower cap,

588
00:20:11,450 --> 00:20:13,230
then because this
is the queen,

589
00:20:13,530 --> 00:20:15,130
it's more likely that this is

590
00:20:15,130 --> 00:20:16,815
a crown and not a shower cap.

591
00:20:17,135 --> 00:20:19,055
So here, we are
using a knowledge

592
00:20:19,055 --> 00:20:21,475
based system to improve
the performance

593
00:20:21,935 --> 00:20:23,555
of a machine learning system.

594
00:20:24,930 --> 00:20:26,770
And we can use
almost the same,

595
00:20:27,170 --> 00:20:29,350
setup, not only to
improve the output,

596
00:20:29,890 --> 00:20:31,750
but also to improve
the explanations.

597
00:20:32,645 --> 00:20:34,165
So suppose that by, you know,

598
00:20:34,165 --> 00:20:35,605
whatever improvement we have

599
00:20:35,605 --> 00:20:38,105
managed to get
the right output,

600
00:20:38,725 --> 00:20:39,945
why is this a crown?

601
00:20:40,340 --> 00:20:41,340
Hard for an image
labeling neural

602
00:20:41,340 --> 00:20:42,836
network to explain
why this is a crown.

603
00:20:42,836 --> 00:20:44,500
Right? This is just
a a large box,

604
00:20:44,500 --> 00:20:45,720
a black box of neurons,

605
00:20:52,725 --> 00:20:54,085
adding up to
the conclusion that

606
00:20:54,085 --> 00:20:54,985
this is a crown.

607
00:20:55,525 --> 00:20:57,365
So maybe we cannot give a real

608
00:20:57,365 --> 00:20:59,250
explanation about the content

609
00:20:59,250 --> 00:21:00,210
of the neural network,

610
00:21:00,210 --> 00:21:01,430
why this is a crown,

611
00:21:01,970 --> 00:21:03,990
but we can come up
with a reasonable

612
00:21:04,050 --> 00:21:06,225
justification by using
an honest graph.

613
00:21:06,385 --> 00:21:07,905
Right. Well, because
this is a queen,

614
00:21:07,905 --> 00:21:09,025
what she's wearing on her head

615
00:21:09,025 --> 00:21:11,285
is most likely
a crown. Right.

616
00:21:11,425 --> 00:21:13,445
So we can use
a knowledge graph

617
00:21:13,745 --> 00:21:17,280
to come up with
a justification for why,

618
00:21:17,680 --> 00:21:19,460
machine learning
neural network,

619
00:21:20,000 --> 00:21:21,460
produced a certain element.

620
00:21:24,815 --> 00:21:26,195
Let me give you
another example.

621
00:21:26,655 --> 00:21:27,875
Well, look at this picture.

622
00:21:29,215 --> 00:21:30,595
What do you see here?

623
00:21:30,680 --> 00:21:32,520
Now if you are
an image labeling

624
00:21:32,520 --> 00:21:33,340
neural network,

625
00:21:33,400 --> 00:21:34,940
how would you
label this image?

626
00:21:35,240 --> 00:21:37,980
Well, you would say,
this is a flower.

627
00:21:38,120 --> 00:21:39,740
Maybe you would
say it's a rose.

628
00:21:40,065 --> 00:21:41,585
K? Well, actually,

629
00:21:41,585 --> 00:21:42,805
you would have been wrong,

630
00:21:44,385 --> 00:21:45,985
because if you would
know the context

631
00:21:45,985 --> 00:21:46,705
of this picture,

632
00:21:46,705 --> 00:21:48,145
you would see that
it's not a flower

633
00:21:48,145 --> 00:21:49,730
or a rose. It's
actually a cushion.

634
00:21:49,970 --> 00:21:51,430
Right? It's a cushion
on a chair.

635
00:21:51,810 --> 00:21:53,910
So it's the context
that matters here.

636
00:21:54,370 --> 00:21:56,770
Right? So what we can do is we

637
00:21:56,770 --> 00:21:58,310
can take this picture.

638
00:21:58,595 --> 00:22:00,035
Now let's assume that we have

639
00:22:00,035 --> 00:22:01,555
already classified the object

640
00:22:01,555 --> 00:22:02,915
in the blue bounding box,

641
00:22:02,915 --> 00:22:04,695
namely that it's a chair.

642
00:22:05,790 --> 00:22:07,150
Then we can inject
a little bit

643
00:22:07,150 --> 00:22:08,450
of ontological knowledge.

644
00:22:08,510 --> 00:22:10,530
The ontological
knowledge will tell us,

645
00:22:10,670 --> 00:22:12,990
well, a chair is
made up out of

646
00:22:12,990 --> 00:22:15,015
cushions and
an armrest. Right?

647
00:22:15,015 --> 00:22:17,415
So, this is a simple bit of of

648
00:22:17,415 --> 00:22:18,555
ontological knowledge.

649
00:22:19,175 --> 00:22:21,175
If x is a chair and
y is part of x,

650
00:22:21,175 --> 00:22:22,455
then y is either a cushion or

651
00:22:22,455 --> 00:22:23,910
an armrest. Right?

652
00:22:24,210 --> 00:22:25,750
Now given this bit
of ontological

653
00:22:25,890 --> 00:22:27,090
knowledge plus the fact that

654
00:22:27,090 --> 00:22:29,110
the blue bounding box
contains a chair,

655
00:22:29,730 --> 00:22:31,835
that suddenly
increases the the

656
00:22:31,835 --> 00:22:33,775
prior probability
of the cushion

657
00:22:33,915 --> 00:22:35,695
as a as a an output,

658
00:22:36,715 --> 00:22:38,735
and reduces
the prior probability

659
00:22:38,875 --> 00:22:40,100
of flower as
an output. Output.

660
00:22:40,100 --> 00:22:41,540
So the the prior
probability of

661
00:22:41,540 --> 00:22:43,860
cushion given a chair is much

662
00:22:43,860 --> 00:22:45,140
higher than
the prior probability

663
00:22:45,140 --> 00:22:46,260
of a flower given a chair.

664
00:22:46,260 --> 00:22:47,880
I mean, a flower is
not impossible.

665
00:22:48,020 --> 00:22:49,335
It could still be
a flower lying

666
00:22:49,335 --> 00:22:51,035
on the chair, but it's
much less likely.

667
00:22:51,895 --> 00:22:54,215
So here, we are using a bit of

668
00:22:54,215 --> 00:22:56,855
ontological knowledge to give

669
00:22:56,855 --> 00:22:59,040
symbolic priors to
a subsymbolic,

670
00:22:59,500 --> 00:23:01,360
object recognition, system.

671
00:23:03,340 --> 00:23:04,220
And and, actually,

672
00:23:04,220 --> 00:23:06,220
this is not
a a a a rare example.

673
00:23:06,220 --> 00:23:08,645
There is a a very
good survey paper,

674
00:23:08,885 --> 00:23:10,485
by, colleagues in two thousand

675
00:23:10,485 --> 00:23:12,185
nineteen who,

676
00:23:12,725 --> 00:23:14,345
surveyed more than a hundred,

677
00:23:14,980 --> 00:23:16,580
different machine
learning systems

678
00:23:16,580 --> 00:23:19,560
that use symbolic
priors to improve,

679
00:23:20,180 --> 00:23:22,100
the behavior of
a machine learning

680
00:23:22,100 --> 00:23:23,925
system. Now this is also known

681
00:23:23,925 --> 00:23:25,465
as a symbolic loss function.

682
00:23:25,685 --> 00:23:27,045
So so what is
a loss function?

683
00:23:27,045 --> 00:23:28,245
A loss function
is the function

684
00:23:28,245 --> 00:23:29,605
that you try to
minimize during

685
00:23:29,605 --> 00:23:31,530
machine learning
training. Right?

686
00:23:31,530 --> 00:23:33,770
It's the difference
between your

687
00:23:33,770 --> 00:23:35,210
output and what your neural

688
00:23:35,210 --> 00:23:36,270
network tells you.

689
00:23:36,330 --> 00:23:38,010
And that difference between

690
00:23:38,010 --> 00:23:39,845
the the between the desired

691
00:23:39,845 --> 00:23:41,205
output and what your neural

692
00:23:41,205 --> 00:23:42,345
system tells you,

693
00:23:42,565 --> 00:23:44,325
you're trying to
minimize the difference

694
00:23:44,325 --> 00:23:45,685
between the desired output and

695
00:23:45,685 --> 00:23:46,665
the actual output.

696
00:23:47,650 --> 00:23:49,490
Now it's part of the black art

697
00:23:49,490 --> 00:23:51,030
of machine learning
to formulate

698
00:23:51,650 --> 00:23:53,270
a correct loss function.

699
00:23:53,875 --> 00:23:55,315
And there are many of these

700
00:23:55,315 --> 00:23:57,635
systems in this
survey paper that,

701
00:23:58,275 --> 00:23:59,715
use semantic loss functions.

702
00:23:59,715 --> 00:24:01,235
So you write down
what you know

703
00:24:01,235 --> 00:24:02,615
to be true about the world,

704
00:24:02,835 --> 00:24:05,130
in this case, or
the parts of a chair,

705
00:24:05,830 --> 00:24:07,510
and you are training
your system

706
00:24:07,510 --> 00:24:09,510
so that it minimizes
the violation

707
00:24:09,510 --> 00:24:10,730
of this background knowledge.

708
00:24:11,035 --> 00:24:14,635
It minimizes
the conflicts between

709
00:24:14,635 --> 00:24:16,635
what your system
says as output

710
00:24:16,635 --> 00:24:18,235
and what you know is likely in

711
00:24:18,235 --> 00:24:20,030
the world. So these semantic

712
00:24:20,030 --> 00:24:21,490
loss functions
are a great help

713
00:24:21,790 --> 00:24:23,250
to machine learning systems.

714
00:24:24,830 --> 00:24:26,915
Here's another
nice example of,

715
00:24:27,075 --> 00:24:29,635
of of the combination
of symbolic and,

716
00:24:30,035 --> 00:24:31,335
and machine learning systems.

717
00:24:31,715 --> 00:24:33,395
So this is an an exercise we

718
00:24:33,395 --> 00:24:34,595
give to our first year machine

719
00:24:34,595 --> 00:24:36,370
learning students. Right?

720
00:24:36,670 --> 00:24:38,110
Train a neural network so that

721
00:24:38,110 --> 00:24:39,390
it can read digits and then

722
00:24:39,390 --> 00:24:40,670
produce the sum of the two

723
00:24:40,670 --> 00:24:41,570
handwritten digits.

724
00:24:41,710 --> 00:24:43,490
And you can do this
end to end training.

725
00:24:43,705 --> 00:24:45,625
But somehow this is
not how we end up,

726
00:24:45,625 --> 00:24:48,605
how we as humans
add up in, digits.

727
00:24:49,065 --> 00:24:51,485
We don't add up
the visual images.

728
00:24:51,740 --> 00:24:53,360
We abstract the visual images

729
00:24:53,740 --> 00:24:55,120
into a symbolic
representation,

730
00:24:55,260 --> 00:24:55,980
namely a number,

731
00:24:55,980 --> 00:24:57,280
and then we add the numbers.

732
00:24:57,900 --> 00:24:59,500
And, again,
an example from our

733
00:24:59,500 --> 00:25:01,120
colleagues in
Leuven, in Leuven,

734
00:25:01,805 --> 00:25:02,845
this is what they do.

735
00:25:02,845 --> 00:25:05,405
Instead of adding up the two,

736
00:25:05,965 --> 00:25:06,945
handwritten digits,

737
00:25:07,645 --> 00:25:10,110
they first abstract
the handwritten

738
00:25:10,110 --> 00:25:11,970
digits into a symbolic
representation,

739
00:25:12,670 --> 00:25:14,030
namely, in this case,

740
00:25:14,030 --> 00:25:15,170
the three and the five,

741
00:25:15,310 --> 00:25:16,930
and then they add
the symbols,

742
00:25:17,335 --> 00:25:18,855
rather than
training the system

743
00:25:18,855 --> 00:25:21,175
to add up the how to add up to

744
00:25:21,175 --> 00:25:22,235
handwritten digits.

745
00:25:23,575 --> 00:25:24,855
So, yeah, this
is really cool,

746
00:25:24,855 --> 00:25:31,330
and it colleagues
in London from,

747
00:25:31,890 --> 00:25:32,850
UCL and,

748
00:25:33,170 --> 00:25:36,465
and Google DeepMind to
train a reinforcement

749
00:25:36,525 --> 00:25:37,985
learning agent in a very,

750
00:25:38,765 --> 00:25:39,825
artificial world.

751
00:25:40,205 --> 00:25:44,130
So in the the the agent was

752
00:25:44,450 --> 00:25:46,470
moving around in
a world of objects,

753
00:25:47,090 --> 00:25:48,690
but rather than making it move

754
00:25:48,690 --> 00:25:50,690
in a world of pixels that are

755
00:25:50,690 --> 00:25:52,230
perceived by
a neural network,

756
00:25:52,735 --> 00:25:54,735
these pixels are
abstracted into

757
00:25:54,735 --> 00:25:56,975
objects and then
the agent moves

758
00:25:56,975 --> 00:25:58,435
around in this
world of objects,

759
00:25:59,775 --> 00:26:01,430
rather than in this
world of pixels.

760
00:26:01,990 --> 00:26:03,670
And what happened in
their experiments?

761
00:26:03,670 --> 00:26:04,870
Well, this was a very simple

762
00:26:04,870 --> 00:26:06,150
world where, you know,

763
00:26:06,150 --> 00:26:08,070
the the the big
symbol in the middle

764
00:26:08,070 --> 00:26:09,350
there, the plus,
is the agent,

765
00:26:09,350 --> 00:26:10,470
and it had to move around in

766
00:26:10,470 --> 00:26:12,465
this rectangle, this
grid like world.

767
00:26:12,765 --> 00:26:14,145
It had to collect the crosses

768
00:26:14,205 --> 00:26:16,465
and avoid the zeros. Right?

769
00:26:17,645 --> 00:26:20,760
And, a reinforcement
learning agent,

770
00:26:20,760 --> 00:26:23,080
the blue line, could could

771
00:26:23,080 --> 00:26:24,520
perfectly learn this task in

772
00:26:24,520 --> 00:26:25,820
this rectangular world.

773
00:26:27,985 --> 00:26:30,065
And they also
trained an an agent

774
00:26:30,065 --> 00:26:32,065
that moved around
in a world of

775
00:26:32,145 --> 00:26:33,845
not in pixels, but abstracting

776
00:26:33,905 --> 00:26:35,525
these crosses and nodes into

777
00:26:35,585 --> 00:26:37,050
objects and then
move around in

778
00:26:37,050 --> 00:26:38,030
the world of objects.

779
00:26:38,250 --> 00:26:40,430
And that agent didn't
quite do so well.

780
00:26:40,810 --> 00:26:42,330
But then they did
something interesting.

781
00:26:42,330 --> 00:26:44,830
Then they they
changed the world.

782
00:26:45,255 --> 00:26:45,895
They said, well,

783
00:26:45,895 --> 00:26:47,415
now these objects
no longer live

784
00:26:47,415 --> 00:26:48,215
on the grid world,

785
00:26:48,215 --> 00:26:49,335
but these objects can live

786
00:26:49,335 --> 00:26:50,395
anywhere in the world.

787
00:26:50,935 --> 00:26:52,630
And then the performance of

788
00:26:52,630 --> 00:26:54,070
the agent that was trained to

789
00:26:54,070 --> 00:26:55,690
move around in
a world of pixels

790
00:26:56,390 --> 00:26:57,270
completely degraded.

791
00:26:57,270 --> 00:26:58,790
It it fell from
a hundred percent

792
00:26:58,790 --> 00:27:01,415
to fifty percent
or less. Right?

793
00:27:01,635 --> 00:27:03,315
But the agent that was moving

794
00:27:03,315 --> 00:27:04,935
around in a world of objects,

795
00:27:05,795 --> 00:27:07,735
it was stable in
its performance.

796
00:27:07,795 --> 00:27:10,050
Now it could,
adjust to the fact

797
00:27:10,050 --> 00:27:11,490
that these objects no longer

798
00:27:11,490 --> 00:27:12,370
lived in a grid world,

799
00:27:12,370 --> 00:27:13,970
but that these
objects could be

800
00:27:13,970 --> 00:27:15,030
anywhere in the space,

801
00:27:15,410 --> 00:27:17,670
and it was much more
robust to learning,

802
00:27:17,815 --> 00:27:19,675
to adapting to
this new world.

803
00:27:19,735 --> 00:27:20,715
Right? So, again,

804
00:27:20,935 --> 00:27:24,155
a combination of
machine learning

805
00:27:24,295 --> 00:27:25,835
and a symbolic representation

806
00:27:25,975 --> 00:27:26,795
about the world.

807
00:27:27,090 --> 00:27:28,690
Just as we don't
move around in

808
00:27:28,690 --> 00:27:29,490
a world of pixels,

809
00:27:29,490 --> 00:27:31,250
we we move around
in a world of

810
00:27:31,250 --> 00:27:33,430
abstract objects
that we construct

811
00:27:33,570 --> 00:27:34,550
out of the pixels.

812
00:27:38,315 --> 00:27:40,555
The final example is about,

813
00:27:41,115 --> 00:27:41,935
rule learning,

814
00:27:42,235 --> 00:27:44,255
where in
the traditional world,

815
00:27:44,780 --> 00:27:45,440
we would,

816
00:27:46,620 --> 00:27:48,220
this is in a medical example

817
00:27:48,220 --> 00:27:49,820
where we would feed patient

818
00:27:49,820 --> 00:27:51,580
features about age and and,

819
00:27:51,820 --> 00:27:53,260
and body mass index and blood

820
00:27:53,260 --> 00:27:54,285
pressure and so on,

821
00:27:54,365 --> 00:27:56,945
and then try to
predict, diabetes.

822
00:27:57,565 --> 00:27:58,845
You could do this with,

823
00:27:59,005 --> 00:28:00,385
with a a learning system,

824
00:28:00,685 --> 00:28:01,885
and then the system would come

825
00:28:01,885 --> 00:28:03,920
up with rules that
are are very good,

826
00:28:03,920 --> 00:28:05,040
almost hundred
percent correct,

827
00:28:05,040 --> 00:28:06,720
but that will be totally non

828
00:28:06,720 --> 00:28:08,340
understandable by
medical experts.

829
00:28:08,880 --> 00:28:09,840
And as a result,

830
00:28:09,840 --> 00:28:12,020
even be though these
rules were correct,

831
00:28:12,295 --> 00:28:13,895
the medical experts
don't really

832
00:28:13,895 --> 00:28:15,175
like these systems
because they

833
00:28:15,175 --> 00:28:16,715
can't understand
what they do.

834
00:28:17,095 --> 00:28:19,415
So instead, what we
did in an experiment

835
00:28:19,415 --> 00:28:22,590
jointly with,
University of Munich,

836
00:28:23,370 --> 00:28:27,790
we injected, not only
data driven rules,

837
00:28:28,010 --> 00:28:31,705
but we injected rules that we

838
00:28:31,705 --> 00:28:33,225
obtained from experts and from

839
00:28:33,225 --> 00:28:35,065
textbooks. And
these rules weren't

840
00:28:35,065 --> 00:28:36,265
very difficult to, obtain.

841
00:28:36,265 --> 00:28:37,225
We talked to experts.

842
00:28:37,225 --> 00:28:38,285
We read some textbooks.

843
00:28:38,345 --> 00:28:39,680
We read some medical
guidelines.

844
00:28:40,300 --> 00:28:42,460
And the corresponding rule set

845
00:28:42,460 --> 00:28:44,000
that you get out of combining

846
00:28:44,220 --> 00:28:45,980
the human expert
knowledge with

847
00:28:45,980 --> 00:28:49,585
the data driven rules
is almost as good,

848
00:28:50,525 --> 00:28:52,125
interestingly enough,
not quite as good,

849
00:28:52,125 --> 00:28:53,965
but almost as good
as the purely

850
00:28:53,965 --> 00:28:55,105
data driven rules,

851
00:28:55,660 --> 00:28:57,340
but the rules had became much

852
00:28:57,340 --> 00:28:58,400
more human understandable.

853
00:28:59,180 --> 00:29:01,020
So instead of a perfect system

854
00:29:01,020 --> 00:29:02,080
that nobody uses,

855
00:29:02,465 --> 00:29:04,145
you now have a slightly less

856
00:29:04,145 --> 00:29:04,965
perfect system,

857
00:29:05,105 --> 00:29:07,125
but that experts are
willing to use.

858
00:29:09,560 --> 00:29:11,080
Let me for the sake of time,

859
00:29:11,080 --> 00:29:13,980
I will skip
the the mathematics of this.

860
00:29:14,840 --> 00:29:17,240
Right. So in the last
minute, my,

861
00:29:17,560 --> 00:29:18,620
concluding remarks.

862
00:29:18,875 --> 00:29:22,075
So what I have
tried to convince

863
00:29:22,075 --> 00:29:24,875
you of is that
machine learning

864
00:29:24,875 --> 00:29:27,035
systems can really
benefit from

865
00:29:27,035 --> 00:29:29,200
injecting symbolic
knowledge in

866
00:29:29,660 --> 00:29:30,620
in in many cases,

867
00:29:30,620 --> 00:29:31,740
symbolic knowledge in the form

868
00:29:31,740 --> 00:29:33,420
of knowledge graphs. Right?

869
00:29:33,420 --> 00:29:35,280
We can produce better
explanations.

870
00:29:35,945 --> 00:29:37,565
We can better
rank hypotheses.

871
00:29:37,705 --> 00:29:39,485
We can do transfer learning.

872
00:29:39,865 --> 00:29:41,945
We can get a better
sample efficiency,

873
00:29:41,945 --> 00:29:43,565
so learn from fewer data.

874
00:29:43,800 --> 00:29:45,080
And we can also
do this the other

875
00:29:45,080 --> 00:29:46,280
way around. So we can have our

876
00:29:46,280 --> 00:29:48,040
knowledge based
systems benefit

877
00:29:48,040 --> 00:29:49,420
from machine
learning systems.

878
00:29:49,800 --> 00:29:51,160
And the required symbolic

879
00:29:51,160 --> 00:29:52,520
knowledge is available at very

880
00:29:52,520 --> 00:29:54,025
large scale. Right?

881
00:29:54,025 --> 00:29:56,425
It is no longer
true that symbolic

882
00:29:56,425 --> 00:29:58,105
knowledge is expensive and we

883
00:29:58,105 --> 00:29:59,245
cannot obtain it.

884
00:29:59,785 --> 00:30:01,465
All the very large linked data

885
00:30:01,465 --> 00:30:03,260
knowledge graphs are a witness

886
00:30:03,260 --> 00:30:05,100
to the fact that this symbolic

887
00:30:05,100 --> 00:30:06,640
knowledge is very
well available.

888
00:30:07,420 --> 00:30:08,800
So it is no longer,

889
00:30:09,420 --> 00:30:10,700
necessary to learn what you

890
00:30:10,700 --> 00:30:12,505
already know. We can inject

891
00:30:12,565 --> 00:30:14,105
the stuff that we already know

892
00:30:14,405 --> 00:30:16,105
into our machine
learning systems,

893
00:30:16,245 --> 00:30:17,925
and by combining
these two types

894
00:30:17,925 --> 00:30:21,300
of systems, produce
much more robust,

895
00:30:21,600 --> 00:30:22,580
much more efficient,

896
00:30:22,880 --> 00:30:24,980
and much more
explainable systems.

897
00:30:27,335 --> 00:30:28,475
Thank you very much.


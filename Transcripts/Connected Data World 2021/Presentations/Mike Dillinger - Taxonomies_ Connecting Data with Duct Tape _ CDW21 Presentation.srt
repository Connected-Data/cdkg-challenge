1
00:00:03,540 --> 00:00:05,620
Hi. I'm Mike, and I wanna talk

2
00:00:05,620 --> 00:00:07,220
about how a lot
of us are using

3
00:00:07,220 --> 00:00:09,080
taxonomies to connect data.

4
00:00:09,700 --> 00:00:12,040
A very special kind
of data, knowledge,

5
00:00:12,585 --> 00:00:13,965
usually based on language,

6
00:00:14,265 --> 00:00:15,165
not on numbers.

7
00:00:16,105 --> 00:00:17,785
We still have a lot left to do

8
00:00:17,785 --> 00:00:19,405
if we're going to
build the foundations

9
00:00:19,465 --> 00:00:21,305
for a new generation
of semantic

10
00:00:21,305 --> 00:00:24,733
technologies and artificial

11
00:00:24,733 --> 00:00:25,960
intelligence. I
haven't presented

12
00:00:25,960 --> 00:00:27,480
to a connected data
world audience

13
00:00:27,480 --> 00:00:29,340
before, so let me
introduce myself.

14
00:00:30,035 --> 00:00:31,895
I have an unusual background,

15
00:00:32,595 --> 00:00:34,115
including
professional tours of

16
00:00:34,115 --> 00:00:37,095
duty as a scholar,
laboratory scientist,

17
00:00:37,395 --> 00:00:39,670
management consultant,
and technologist,

18
00:00:40,610 --> 00:00:42,050
which seems to baffle many of

19
00:00:42,050 --> 00:00:42,790
my colleagues.

20
00:00:44,370 --> 00:00:45,890
At this point,
I've been working

21
00:00:45,890 --> 00:00:47,830
in AI for more than
twenty years.

22
00:00:48,585 --> 00:00:50,105
And now I've been
tech lead for

23
00:00:50,105 --> 00:00:51,545
knowledge graphs
at LinkedIn for

24
00:00:51,545 --> 00:00:54,025
several years.
Tech lead simply

25
00:00:54,025 --> 00:00:55,145
means that when no one else

26
00:00:55,145 --> 00:00:56,585
knows what to do
some how to do

27
00:00:56,585 --> 00:00:58,140
something, you have to come up

28
00:00:58,140 --> 00:01:00,560
with a solution as
soon as possible.

29
00:01:01,420 --> 00:01:03,120
I wouldn't have
any other role.

30
00:01:04,140 --> 00:01:06,240
And there's a theme
to my varied career.

31
00:01:06,405 --> 00:01:08,325
It's all about
connecting language

32
00:01:08,325 --> 00:01:10,565
and knowledge in wonderful and

33
00:01:10,565 --> 00:01:11,625
scalable ways.

34
00:01:12,885 --> 00:01:14,405
So it's fitting that I work in

35
00:01:14,405 --> 00:01:16,580
cognitive computing
at the intersection

36
00:01:16,580 --> 00:01:18,680
of human expertise and machine

37
00:01:18,740 --> 00:01:20,980
intelligence. Drawing on this

38
00:01:20,980 --> 00:01:21,800
very background,

39
00:01:22,180 --> 00:01:23,625
I have extensive experience

40
00:01:23,625 --> 00:01:25,305
looking at how both humans and

41
00:01:25,305 --> 00:01:27,625
machines perform
the same language

42
00:01:27,625 --> 00:01:29,405
and knowledge related tasks.

43
00:01:31,580 --> 00:01:33,920
The title of this talk
alludes to Perl,

44
00:01:34,060 --> 00:01:35,340
the programming language that

45
00:01:35,340 --> 00:01:37,500
was often referred
to as the duct

46
00:01:37,500 --> 00:01:38,825
tape of the Internet.

47
00:01:39,685 --> 00:01:41,285
Duct tape is good because it's

48
00:01:41,285 --> 00:01:42,905
flexible and easy to use,

49
00:01:43,285 --> 00:01:44,905
but it tends to hide problems

50
00:01:45,045 --> 00:01:46,260
rather than fix them,

51
00:01:46,420 --> 00:01:48,120
and it's difficult
to troubleshoot

52
00:01:48,340 --> 00:01:49,080
and extend.

53
00:01:50,260 --> 00:01:51,860
I'm seeing lots
of teams trying

54
00:01:51,860 --> 00:01:53,480
to connect data
using taxonomies

55
00:01:53,700 --> 00:01:56,005
as duct tape with predictably

56
00:01:56,225 --> 00:01:57,525
unreliable results.

57
00:01:58,385 --> 00:02:00,085
And this is
particularly important

58
00:02:00,225 --> 00:02:01,825
because I see
a dramatic increase

59
00:02:01,825 --> 00:02:03,445
in work on
developing taxonomies

60
00:02:03,825 --> 00:02:04,850
at leading companies.

61
00:02:06,610 --> 00:02:07,990
If, as the saying goes,

62
00:02:08,050 --> 00:02:09,650
experience is a fancy name for

63
00:02:09,650 --> 00:02:11,270
all the errors that
you've committed,

64
00:02:11,570 --> 00:02:13,110
then I have a lot
of experience

65
00:02:13,170 --> 00:02:15,315
to talk about.
I'd like to tell

66
00:02:15,315 --> 00:02:16,935
you about some of
my misadventures

67
00:02:17,155 --> 00:02:18,215
in knowledge organization.

68
00:02:19,315 --> 00:02:20,675
We're all familiar with simple

69
00:02:20,675 --> 00:02:23,160
taxonomies. I see
more and more

70
00:02:23,160 --> 00:02:24,520
investment in developing them

71
00:02:24,520 --> 00:02:26,120
for industrial purposes with

72
00:02:26,120 --> 00:02:27,420
each passing year.

73
00:02:27,560 --> 00:02:29,000
I see more publications on

74
00:02:29,000 --> 00:02:31,025
taxonomies and
more job postings

75
00:02:31,025 --> 00:02:31,685
for taxonomists.

76
00:02:32,625 --> 00:02:34,385
I hear of more new teams and

77
00:02:34,385 --> 00:02:35,925
field more and more questions

78
00:02:36,225 --> 00:02:38,325
about how to start
building a taxonomy

79
00:02:38,465 --> 00:02:41,310
team. But are
taxonomies the best

80
00:02:41,310 --> 00:02:42,450
use of our time?

81
00:02:44,590 --> 00:02:45,950
Most of us have heard about

82
00:02:45,950 --> 00:02:48,215
taxonomies since biology class

83
00:02:48,215 --> 00:02:49,355
in sixth grade.

84
00:02:49,655 --> 00:02:51,575
We assume that
they're important

85
00:02:51,575 --> 00:02:53,415
and useful even when we don't

86
00:02:53,415 --> 00:02:55,335
have a very clear idea of what

87
00:02:55,335 --> 00:02:56,540
the details are.

88
00:02:58,380 --> 00:03:00,380
So what I frequently
see is that

89
00:03:00,380 --> 00:03:01,660
teams who face challenges of

90
00:03:01,660 --> 00:03:03,660
knowledge organization turn to

91
00:03:03,660 --> 00:03:05,520
taxonomies as their
first choice.

92
00:03:07,035 --> 00:03:08,875
Unfortunately, taxonomies are

93
00:03:08,875 --> 00:03:10,255
rather murky territory.

94
00:03:11,195 --> 00:03:13,135
There's no explicit definition

95
00:03:13,355 --> 00:03:15,455
of them that's
easily findable.

96
00:03:15,900 --> 00:03:17,360
There are no best practices.

97
00:03:18,300 --> 00:03:19,900
There are few
experienced people

98
00:03:19,900 --> 00:03:21,200
who know how to build them.

99
00:03:22,380 --> 00:03:23,920
There are no
reliable evaluation

100
00:03:24,060 --> 00:03:26,255
methods and
essentially no notion

101
00:03:26,255 --> 00:03:27,075
of done.

102
00:03:27,855 --> 00:03:29,295
And since there's almost no

103
00:03:29,295 --> 00:03:31,075
reliable
reliable documentation

104
00:03:31,295 --> 00:03:32,435
to fall back on,

105
00:03:32,680 --> 00:03:34,520
we essentially have to rely on

106
00:03:34,520 --> 00:03:36,140
what we remember from biology

107
00:03:36,200 --> 00:03:38,220
class and hope for the best.

108
00:03:39,000 --> 00:03:40,940
But that's not a lot
to work with.

109
00:03:42,655 --> 00:03:44,495
So this is a classic duct tape

110
00:03:44,495 --> 00:03:47,155
situation. It's
almost guaranteed

111
00:03:47,535 --> 00:03:50,150
to produce flawed
results at a high

112
00:03:50,150 --> 00:03:53,690
cost. But we forge ahead.

113
00:03:53,910 --> 00:03:55,450
We build a tech a taxonomy.

114
00:03:55,990 --> 00:03:57,670
And it seems like
every time we

115
00:03:57,670 --> 00:03:58,490
build a taxonomy,

116
00:03:58,895 --> 00:04:00,355
the same thing happens.

117
00:04:00,975 --> 00:04:02,255
We put a lot of effort into

118
00:04:02,255 --> 00:04:04,035
making it correct
and coherent,

119
00:04:04,415 --> 00:04:06,435
then get sign off from
key stakeholders.

120
00:04:07,240 --> 00:04:09,100
Things look like
they're going well.

121
00:04:09,960 --> 00:04:11,720
It's almost time to move on to

122
00:04:11,720 --> 00:04:12,620
the next project,

123
00:04:13,080 --> 00:04:14,760
and there are so many of them

124
00:04:14,760 --> 00:04:16,700
as more people
start to understand

125
00:04:16,760 --> 00:04:18,445
the importance of our work.

126
00:04:20,905 --> 00:04:22,825
But when we try to get buy in

127
00:04:22,825 --> 00:04:23,965
from product partners,

128
00:04:24,760 --> 00:04:26,600
dozens of questions
come up crop

129
00:04:26,600 --> 00:04:29,160
up from the CEO sometimes all

130
00:04:29,160 --> 00:04:30,540
the way on down the line.

131
00:04:32,345 --> 00:04:33,965
There are a wide
range of questions,

132
00:04:34,665 --> 00:04:36,505
and all of them
seem to be theme

133
00:04:36,505 --> 00:04:38,905
and variations on this doesn't

134
00:04:38,905 --> 00:04:39,965
meet our requirements.

135
00:04:41,530 --> 00:04:43,150
What did we do wrong?

136
00:04:45,050 --> 00:04:46,570
Oh, and if this
hasn't happened

137
00:04:46,570 --> 00:04:50,085
to you yet, it
will. Believe me.

138
00:04:50,785 --> 00:04:52,385
And when the CEO and product

139
00:04:52,385 --> 00:04:54,165
leaders are breathing
down your neck,

140
00:04:54,385 --> 00:04:55,445
it gets uncomfortable.

141
00:04:57,390 --> 00:04:59,150
So this situation
really wreaks

142
00:04:59,150 --> 00:05:01,790
havoc with our
schedule and with

143
00:05:01,790 --> 00:05:03,870
our morale too because we have

144
00:05:03,870 --> 00:05:06,050
so much explaining
and rework to do.

145
00:05:07,055 --> 00:05:09,215
So part of my job
is to understand

146
00:05:09,215 --> 00:05:11,555
what's going on and
to fix it somehow.

147
00:05:13,455 --> 00:05:15,635
This is the classic
tech lead question,

148
00:05:15,930 --> 00:05:17,230
why did this happen?

149
00:05:18,090 --> 00:05:19,770
And I find it very valuable to

150
00:05:19,770 --> 00:05:21,950
listen first and
very carefully,

151
00:05:22,490 --> 00:05:24,170
to spend time
understanding how

152
00:05:24,170 --> 00:05:26,925
stakeholders think
about our very nerdy,

153
00:05:26,985 --> 00:05:28,445
very technical issues.

154
00:05:30,025 --> 00:05:31,465
The stakeholders make it sound

155
00:05:31,465 --> 00:05:33,385
like a taxonomy
really does not

156
00:05:33,385 --> 00:05:36,550
meet our needs and
that we screwed up.

157
00:05:37,650 --> 00:05:39,090
So let's look at the kinds of

158
00:05:39,090 --> 00:05:40,850
issues that stakeholders raise

159
00:05:40,850 --> 00:05:42,150
when faced with a taxonomy.

160
00:05:44,485 --> 00:05:45,685
I don't have to tell you that

161
00:05:45,685 --> 00:05:47,945
product managers ask
lots of questions.

162
00:05:48,405 --> 00:05:49,605
They're usually worried that

163
00:05:49,605 --> 00:05:51,285
rolling out a new
taxonomy will

164
00:05:51,285 --> 00:05:52,265
wreck their products,

165
00:05:52,910 --> 00:05:54,350
even if right now
they're using

166
00:05:54,350 --> 00:05:55,490
very messy data.

167
00:05:56,510 --> 00:05:58,510
Their questions often focus on

168
00:05:58,510 --> 00:06:00,210
other related entities,

169
00:06:00,955 --> 00:06:03,055
like dog houses
and dog shampoo

170
00:06:03,435 --> 00:06:05,455
and veterinarians
and pedigrees.

171
00:06:06,635 --> 00:06:08,670
They sense pretty quickly that

172
00:06:08,670 --> 00:06:11,070
taxonomies create issues of

173
00:06:11,070 --> 00:06:12,770
coverage of the domain.

174
00:06:14,190 --> 00:06:15,630
You probably don't
want to answer

175
00:06:15,630 --> 00:06:16,850
that this kind of information

176
00:06:16,910 --> 00:06:19,135
doesn't fit into taxonomy,

177
00:06:19,135 --> 00:06:20,355
even though that's true.

178
00:06:20,895 --> 00:06:21,935
You might mention, though,

179
00:06:21,935 --> 00:06:23,715
that there were
parts of the product

180
00:06:23,855 --> 00:06:26,355
requirements that
weren't so clear.

181
00:06:28,740 --> 00:06:30,580
The taxonomists
slaving away in

182
00:06:30,580 --> 00:06:32,740
the trenches also have lots of

183
00:06:32,740 --> 00:06:34,820
questions. Their
questions often

184
00:06:34,820 --> 00:06:35,780
focus on the many,

185
00:06:35,780 --> 00:06:38,075
many exceptions and edge cases

186
00:06:38,135 --> 00:06:39,195
of what's correct.

187
00:06:40,135 --> 00:06:41,575
They ask, where should I put

188
00:06:41,575 --> 00:06:44,635
mixed breed dogs
or service dogs

189
00:06:44,695 --> 00:06:46,810
of unknown breeds or hunting

190
00:06:46,810 --> 00:06:48,670
dogs that are also pets.

191
00:06:49,690 --> 00:06:51,930
They sense pretty quickly that

192
00:06:51,930 --> 00:06:54,090
taxonomies create issues or

193
00:06:54,090 --> 00:06:55,835
accuracy of the domain.

194
00:06:58,955 --> 00:07:01,055
Of course, managers
of all stripes

195
00:07:01,195 --> 00:07:03,055
have lots and lots
of questions.

196
00:07:03,590 --> 00:07:05,930
And their questions
often focus on more,

197
00:07:06,070 --> 00:07:07,770
better, faster, and cheaper.

198
00:07:09,270 --> 00:07:10,550
They'll ask, how will you make

199
00:07:10,550 --> 00:07:11,610
the process faster?

200
00:07:12,055 --> 00:07:14,555
How you expand to
new domains faster?

201
00:07:15,095 --> 00:07:17,435
How can we evaluate
the workers better?

202
00:07:18,295 --> 00:07:20,150
They sense pretty quickly that

203
00:07:20,150 --> 00:07:22,650
taxonomies create
issues of scalability.

204
00:07:26,150 --> 00:07:27,590
And the users, of course,

205
00:07:27,590 --> 00:07:29,130
also have lots of questions.

206
00:07:29,925 --> 00:07:31,765
Their questions
office focus on,

207
00:07:31,765 --> 00:07:33,945
why don't you say
it like I do?

208
00:07:36,005 --> 00:07:37,045
They ask things like,

209
00:07:37,045 --> 00:07:39,070
why do you call
them service dogs?

210
00:07:39,230 --> 00:07:40,850
I call them support dogs.

211
00:07:41,270 --> 00:07:42,910
And hunting dog,

212
00:07:42,910 --> 00:07:44,930
don't you actually
mean a sent out?

213
00:07:46,165 --> 00:07:47,285
And we can see pretty quickly

214
00:07:47,285 --> 00:07:49,045
that taxonomies create issues

215
00:07:49,045 --> 00:07:51,545
of communication of
the domain as well.

216
00:07:52,405 --> 00:07:54,085
Taxonomies rely crucially on

217
00:07:54,085 --> 00:07:56,030
the category labels
to communicate

218
00:07:56,170 --> 00:07:56,990
different concepts,

219
00:07:57,850 --> 00:07:59,690
but different people
use different

220
00:07:59,690 --> 00:08:00,190
terms.

221
00:08:02,925 --> 00:08:05,725
Given these many
limitations, at best,

222
00:08:05,725 --> 00:08:08,365
a taxonomy might be a patch or

223
00:08:08,365 --> 00:08:09,505
a short term workaround.

224
00:08:12,810 --> 00:08:14,670
So far, we've learned
a few things.

225
00:08:14,970 --> 00:08:17,210
Taxonomies create
a range of big

226
00:08:17,210 --> 00:08:19,285
problems: Problems
of coverage,

227
00:08:19,585 --> 00:08:20,725
problems of accuracy,

228
00:08:21,825 --> 00:08:23,525
problems of scalability,

229
00:08:24,305 --> 00:08:25,685
and problems of
communication.

230
00:08:29,340 --> 00:08:31,760
But why? Why aren't taxonomies

231
00:08:31,980 --> 00:08:32,940
working for us?

232
00:08:32,940 --> 00:08:35,475
If we don't understand why,

233
00:08:35,475 --> 00:08:37,335
we'll just keep
repeating our mistakes.

234
00:08:39,715 --> 00:08:41,575
But do we need to fix
our communication,

235
00:08:42,170 --> 00:08:43,790
or do we need to
fix taxonomies

236
00:08:44,170 --> 00:08:46,810
themselves? Stakeholders look

237
00:08:46,810 --> 00:08:48,910
at taxonomies as a black box.

238
00:08:49,435 --> 00:08:51,615
We need to open up
this black box.

239
00:08:52,875 --> 00:08:54,075
Let's go back to the beginning

240
00:08:54,075 --> 00:08:55,935
for a second. Is
this unexamined

241
00:08:56,235 --> 00:08:58,015
assumption a good one?

242
00:08:59,010 --> 00:09:01,030
It's starting to
look like it's not,

243
00:09:01,250 --> 00:09:03,270
and I can see two
possible reasons.

244
00:09:03,730 --> 00:09:05,410
Either we're not building them

245
00:09:05,410 --> 00:09:07,415
correctly, or we're building

246
00:09:07,635 --> 00:09:08,935
the wrong things.

247
00:09:09,875 --> 00:09:11,575
So we need to
understand taxonomies

248
00:09:11,795 --> 00:09:13,715
better to see how
well they will

249
00:09:13,715 --> 00:09:14,615
work for us.

250
00:09:17,430 --> 00:09:19,110
Taxonomies are
tools for knowledge

251
00:09:19,110 --> 00:09:20,570
organization. Okay.

252
00:09:20,950 --> 00:09:22,885
My key question
today though is

253
00:09:22,885 --> 00:09:24,565
how good are these tools for

254
00:09:24,565 --> 00:09:25,545
connecting data?

255
00:09:26,805 --> 00:09:28,245
It's surprisingly difficult to

256
00:09:28,245 --> 00:09:29,785
find definitions of taxonomy

257
00:09:30,240 --> 00:09:32,580
with clear explicit criteria.

258
00:09:33,360 --> 00:09:35,520
I really had to
dig to go beyond

259
00:09:35,520 --> 00:09:37,280
a system of
classification used

260
00:09:37,280 --> 00:09:39,060
in biology, blah blah blah.

261
00:09:39,645 --> 00:09:41,885
It turns out that
taxonomies are

262
00:09:41,885 --> 00:09:44,045
built with a very
specific formal

263
00:09:44,045 --> 00:09:46,925
framework that is based on set

264
00:09:46,925 --> 00:09:48,465
theory and formal logic.

265
00:09:49,760 --> 00:09:51,300
There's a system
of interrelated

266
00:09:51,440 --> 00:09:53,040
conventions like those listed

267
00:09:53,040 --> 00:09:54,960
here that essentially define

268
00:09:54,960 --> 00:09:56,500
what a taxonomy is.

269
00:09:57,305 --> 00:09:58,665
There are many
issues with these

270
00:09:58,665 --> 00:10:00,425
assumptions, but
for the moment,

271
00:10:00,425 --> 00:10:02,125
let's focus on some
of the practical

272
00:10:02,185 --> 00:10:04,265
consequences of assuming that

273
00:10:04,265 --> 00:10:05,085
they are useful.

274
00:10:07,130 --> 00:10:09,050
Taxonomies assume that there's

275
00:10:09,050 --> 00:10:11,470
only one kind of item
in each taxonomy,

276
00:10:11,770 --> 00:10:13,950
for example,
a taxonomy of dogs.

277
00:10:15,275 --> 00:10:16,815
This is just to say
that taxonomies

278
00:10:16,955 --> 00:10:18,955
are focused. We
don't find a single

279
00:10:18,955 --> 00:10:21,035
taxonomy that includes
dogs, houses,

280
00:10:21,035 --> 00:10:23,940
and shampoos. And
this makes sense.

281
00:10:24,320 --> 00:10:26,000
Taxonomies represent
degrees of

282
00:10:26,000 --> 00:10:28,240
similarity, and dogs, houses,

283
00:10:28,240 --> 00:10:30,580
and shampoo are not similar.

284
00:10:32,995 --> 00:10:34,595
But taxonomies
make it hard for

285
00:10:34,595 --> 00:10:37,175
us to describe other
related entities,

286
00:10:37,315 --> 00:10:39,235
like dog houses, dog shows,

287
00:10:39,235 --> 00:10:39,975
and veterinarians.

288
00:10:41,670 --> 00:10:43,510
And taxonomies
usually don't go

289
00:10:43,510 --> 00:10:45,530
beyond entities to
describe events,

290
00:10:45,670 --> 00:10:48,090
processes, states,
contingencies,

291
00:10:48,550 --> 00:10:49,530
or other things.

292
00:10:50,955 --> 00:10:52,715
I keep hearing
that we can simply

293
00:10:52,715 --> 00:10:54,715
use related terms to include

294
00:10:54,715 --> 00:10:55,535
other entities.

295
00:10:56,235 --> 00:10:58,495
But related terms,
as you see here,

296
00:10:58,770 --> 00:11:00,870
are subjective
and ill defined.

297
00:11:01,810 --> 00:11:03,650
The unclear semantics makes it

298
00:11:03,650 --> 00:11:05,350
very hard to guide
and validate

299
00:11:05,810 --> 00:11:08,550
consistent choices
of related terms.

300
00:11:11,285 --> 00:11:12,885
Taxonomies also assume that

301
00:11:12,885 --> 00:11:14,565
categories are
essentially labeled

302
00:11:14,565 --> 00:11:16,800
sets of items. For example,

303
00:11:16,800 --> 00:11:19,140
these are the items
in category X.

304
00:11:20,240 --> 00:11:22,080
And labels are
very often taken

305
00:11:22,080 --> 00:11:24,180
to be enough to
describe the semantics

306
00:11:24,240 --> 00:11:24,980
of a category.

307
00:11:26,995 --> 00:11:28,995
But labeled sets are the bane

308
00:11:28,995 --> 00:11:29,975
of our existence.

309
00:11:30,995 --> 00:11:32,755
When categories
have labels and

310
00:11:32,755 --> 00:11:34,055
no explicit semantics,

311
00:11:34,540 --> 00:11:36,540
it's nearly impossible
to annotate

312
00:11:36,540 --> 00:11:38,480
and validate their
members consistently.

313
00:11:39,660 --> 00:11:42,060
This is very,
very common in my

314
00:11:42,060 --> 00:11:44,625
experience. Annotators most

315
00:11:44,625 --> 00:11:46,865
often work from labels without

316
00:11:46,865 --> 00:11:48,625
explicit definitions or well

317
00:11:48,625 --> 00:11:49,765
documented guidelines.

318
00:11:50,840 --> 00:11:52,040
And that means that we can't

319
00:11:52,040 --> 00:11:54,040
describe exactly
why an item is

320
00:11:54,040 --> 00:11:56,200
in a category, or even what it

321
00:11:56,200 --> 00:11:58,060
means to be in a category,

322
00:11:58,975 --> 00:12:01,155
or how to validate
the placement

323
00:12:01,375 --> 00:12:02,835
of an item in a category.

324
00:12:05,775 --> 00:12:07,375
Taxonomies also assume that

325
00:12:07,375 --> 00:12:10,560
items are in one and
only one category.

326
00:12:11,660 --> 00:12:13,920
Like, final is
an example of a setter

327
00:12:14,380 --> 00:12:16,400
and is not in any
other category.

328
00:12:17,325 --> 00:12:18,365
This is the most frequent

329
00:12:18,365 --> 00:12:19,905
assumption for
standard taxonomies.

330
00:12:21,005 --> 00:12:22,765
Of course, permitting multiple

331
00:12:22,765 --> 00:12:24,865
categories or
parents is an option

332
00:12:25,005 --> 00:12:26,305
for extending our taxonomies.

333
00:12:27,230 --> 00:12:28,590
But what do we do then with

334
00:12:28,590 --> 00:12:29,410
double counting?

335
00:12:29,870 --> 00:12:31,230
If each item can appear in

336
00:12:31,230 --> 00:12:32,130
multiple categories,

337
00:12:32,430 --> 00:12:33,950
then their
occurrences will sum

338
00:12:33,950 --> 00:12:35,650
to more than one
hundred percent.

339
00:12:36,455 --> 00:12:38,475
And one key use
case for taxonomies

340
00:12:38,935 --> 00:12:41,115
is aggregating data
for insights.

341
00:12:45,050 --> 00:12:47,210
Besides, multiple
parents won't

342
00:12:47,210 --> 00:12:49,630
help with cases like
we don't know,

343
00:12:49,770 --> 00:12:51,310
where there's not
enough information,

344
00:12:52,105 --> 00:12:53,645
or there's a data error.

345
00:12:54,425 --> 00:12:56,905
If item x is in category y has

346
00:12:56,905 --> 00:12:59,645
to be entirely true
or entirely false,

347
00:13:00,180 --> 00:13:01,860
then a statement like nursery

348
00:13:01,860 --> 00:13:04,180
manager is in
category healthcare

349
00:13:04,180 --> 00:13:06,600
jobs will force
us to incorrectly

350
00:13:06,740 --> 00:13:08,260
classify professionals who

351
00:13:08,260 --> 00:13:10,875
cultivate trees and shrubs as

352
00:13:10,875 --> 00:13:11,775
health care workers.

353
00:13:12,955 --> 00:13:14,575
In part because of
this assumption,

354
00:13:14,955 --> 00:13:16,610
we still don't
have good methods

355
00:13:16,770 --> 00:13:18,290
for evaluating items that are

356
00:13:18,290 --> 00:13:20,790
partially correct or
totally irrelevant.

357
00:13:24,055 --> 00:13:26,695
Taxonomies also
assume that only

358
00:13:26,695 --> 00:13:28,395
one kind of relation exists

359
00:13:28,615 --> 00:13:30,155
between items and categories.

360
00:13:30,535 --> 00:13:32,155
In parallel to set theory,

361
00:13:32,310 --> 00:13:34,170
an item is a member
of a category.

362
00:13:35,270 --> 00:13:37,530
Like Fido is
an example of setter.

363
00:13:40,055 --> 00:13:41,335
But that means that we can't

364
00:13:41,335 --> 00:13:43,015
describe things like Fido is

365
00:13:43,015 --> 00:13:44,935
bigger than poodles or similar

366
00:13:44,935 --> 00:13:45,595
to terriers.

367
00:13:46,615 --> 00:13:48,315
The usual conventions
of taxonomies

368
00:13:48,695 --> 00:13:50,530
make it very difficult for us

369
00:13:50,590 --> 00:13:52,030
to describe other kinds of

370
00:13:52,030 --> 00:13:54,450
relations between
items and categories.

371
00:13:56,935 --> 00:13:58,695
The same thing holds
for the relation

372
00:13:58,695 --> 00:14:01,335
between one category
and another.

373
00:14:01,335 --> 00:14:02,875
In parallel to set theory,

374
00:14:03,095 --> 00:14:05,060
a category can be a subset of

375
00:14:05,060 --> 00:14:05,800
another category,

376
00:14:05,940 --> 00:14:08,520
like setters or a kind
of hunting dogs.

377
00:14:10,660 --> 00:14:13,080
But cats aren't
a subset of dogs,

378
00:14:13,335 --> 00:14:15,115
so we can't describe
any relations

379
00:14:15,175 --> 00:14:15,995
between them.

380
00:14:17,575 --> 00:14:19,355
The usual conventions
of taxonomies

381
00:14:19,735 --> 00:14:21,290
make it very difficult for us

382
00:14:21,290 --> 00:14:22,730
to describe other kinds of

383
00:14:22,730 --> 00:14:24,190
relations between categories

384
00:14:24,730 --> 00:14:26,430
like the ones listed here.

385
00:14:29,295 --> 00:14:30,915
We've learned a few
more things.

386
00:14:31,695 --> 00:14:33,395
So now we can see
why taxonomies

387
00:14:33,615 --> 00:14:35,795
create a range of
big problems.

388
00:14:36,735 --> 00:14:38,710
Assumptions about items and

389
00:14:38,710 --> 00:14:40,570
relations lead to
problems of coverage.

390
00:14:41,350 --> 00:14:42,650
Assumptions about categories

391
00:14:42,790 --> 00:14:44,410
lead to problems
of communication

392
00:14:44,710 --> 00:14:45,690
and of accuracy.

393
00:14:46,815 --> 00:14:48,175
And assumptions
about the nature

394
00:14:48,175 --> 00:14:50,015
of true and false
lead to problems

395
00:14:50,015 --> 00:14:51,955
of accuracy and scalability.

396
00:14:53,860 --> 00:14:55,460
Taxonomies create
problems because

397
00:14:55,460 --> 00:14:56,580
they're simply not the right

398
00:14:56,580 --> 00:14:58,440
tool for many of
our use cases.

399
00:14:59,860 --> 00:15:01,460
And we've seen
why the field is

400
00:15:01,460 --> 00:15:03,725
moving away from taxonomies to

401
00:15:03,725 --> 00:15:05,585
ontologies and
knowledge graphs,

402
00:15:06,205 --> 00:15:08,125
because ontologies
and knowledge

403
00:15:08,125 --> 00:15:10,145
graphs impose
fewer restrictions

404
00:15:10,285 --> 00:15:12,100
on the kinds of
knowledge we can

405
00:15:12,100 --> 00:15:12,600
represent.

406
00:15:15,460 --> 00:15:16,980
So my first lesson from all of

407
00:15:16,980 --> 00:15:18,740
this is that taxonomies are in

408
00:15:18,740 --> 00:15:21,455
fact a kludge, not a fix.

409
00:15:22,175 --> 00:15:23,955
We're barking up
the wrong tree.

410
00:15:26,335 --> 00:15:28,655
And my second lesson is that

411
00:15:28,655 --> 00:15:31,530
build a taxonomy
doesn't always

412
00:15:31,670 --> 00:15:34,230
mean that we should
build an actual

413
00:15:34,230 --> 00:15:36,810
taxonomy because stakeholders

414
00:15:36,950 --> 00:15:38,890
often aren't clear
on what a taxonomy

415
00:15:39,110 --> 00:15:42,865
is or on the other
options that we have.

416
00:15:43,485 --> 00:15:45,105
So we need to
understand taxonomies

417
00:15:45,325 --> 00:15:47,265
better to guide
other stakeholders

418
00:15:47,645 --> 00:15:48,145
better.

419
00:15:51,010 --> 00:15:52,610
The good news is
that we can do

420
00:15:52,610 --> 00:15:53,830
much better than taxonomies.

421
00:15:54,690 --> 00:15:56,630
In fact, we have to
do much better.

422
00:15:57,045 --> 00:15:58,345
We're building the foundations

423
00:15:58,405 --> 00:16:00,185
for a new generation
of semantic

424
00:16:00,245 --> 00:16:01,465
technologies and artificial

425
00:16:01,525 --> 00:16:04,585
intelligence. We have
to get it right.

426
00:16:06,220 --> 00:16:07,820
I'd like to backtrack
for a minute

427
00:16:07,820 --> 00:16:09,740
and ask, why did we care about

428
00:16:09,740 --> 00:16:11,440
taxonomies in
the first place?

429
00:16:12,060 --> 00:16:13,740
What are we trying to get done

430
00:16:13,740 --> 00:16:14,400
with them?

431
00:16:16,255 --> 00:16:17,135
For a long time,

432
00:16:17,135 --> 00:16:18,975
we've thought in
stark black and

433
00:16:18,975 --> 00:16:19,875
white terms:

434
00:16:20,255 --> 00:16:22,515
machine only versus human only

435
00:16:22,655 --> 00:16:25,130
intelligence. We assume that

436
00:16:25,130 --> 00:16:27,070
there are only two
options available.

437
00:16:28,090 --> 00:16:30,030
Indeed, many AI practitioners

438
00:16:30,250 --> 00:16:32,365
assume that autonomous machine

439
00:16:32,365 --> 00:16:35,265
only AI is the best
goal for the field.

440
00:16:36,205 --> 00:16:38,205
And human only
intelligence does

441
00:16:38,205 --> 00:16:39,645
not scale in the ways that we

442
00:16:39,645 --> 00:16:40,465
need it to.

443
00:16:41,470 --> 00:16:42,990
In addition, today's standard

444
00:16:42,990 --> 00:16:44,750
practice is to keep human

445
00:16:44,750 --> 00:16:46,670
expertise separate
and leverage

446
00:16:46,670 --> 00:16:48,610
it mostly for better AI,

447
00:16:49,165 --> 00:16:51,105
and only sometimes to leverage

448
00:16:51,245 --> 00:16:53,185
AI for better
human expertise.

449
00:16:55,980 --> 00:16:57,500
But what about
the Fifty Shades

450
00:16:57,500 --> 00:16:58,880
of Grey in the middle?

451
00:16:59,820 --> 00:17:01,200
Saying that
machine intelligence

452
00:17:01,420 --> 00:17:03,340
and human expertise
are the only

453
00:17:03,340 --> 00:17:05,925
two options is fake news.

454
00:17:06,545 --> 00:17:08,705
It's a false dichotomy because

455
00:17:08,705 --> 00:17:10,945
there are many
unexplored shades

456
00:17:10,945 --> 00:17:13,610
of mixed intelligence
in the middle.

457
00:17:15,190 --> 00:17:16,550
We can arrange the options on

458
00:17:16,550 --> 00:17:18,390
a scale from least machine

459
00:17:18,390 --> 00:17:20,010
participation to most.

460
00:17:20,795 --> 00:17:22,575
And from the beginning
of the field,

461
00:17:22,635 --> 00:17:24,175
there have been
heated discussions

462
00:17:24,555 --> 00:17:25,855
about whether the overarching

463
00:17:25,995 --> 00:17:28,555
goal should be
autonomous machine

464
00:17:28,555 --> 00:17:31,550
intelligence or
augmentation of

465
00:17:31,550 --> 00:17:38,115
human intelligence And

466
00:17:38,115 --> 00:17:39,555
now the discussion
has progressed

467
00:17:39,555 --> 00:17:41,895
to talk about hybrid
intelligence,

468
00:17:42,355 --> 00:17:44,620
where humans and machines work

469
00:17:44,620 --> 00:17:46,640
as one integrated system.

470
00:17:49,900 --> 00:17:51,900
So be sure to watch Frank von

471
00:17:51,900 --> 00:17:54,065
Harmelin's keynote
about hybrid

472
00:17:54,065 --> 00:17:55,905
intelligence, and let me wet

473
00:17:55,905 --> 00:17:57,345
your appetite with a taste of

474
00:17:57,345 --> 00:17:58,725
what he'll be talking about.

475
00:18:02,760 --> 00:18:04,600
Hybrid intelligence refers to

476
00:18:04,600 --> 00:18:07,720
systems where humans
contribute insight,

477
00:18:07,720 --> 00:18:09,260
creativity, strategy,

478
00:18:09,785 --> 00:18:11,785
and qualitative
evaluation that

479
00:18:11,785 --> 00:18:14,205
machines lack. And machines

480
00:18:14,265 --> 00:18:15,725
contribute speed,
thoroughness,

481
00:18:15,785 --> 00:18:16,765
strength, comprehensiveness,

482
00:18:17,545 --> 00:18:19,005
coordination, and reliability

483
00:18:19,930 --> 00:18:21,530
that humans lack.

484
00:18:21,530 --> 00:18:23,390
That is, we're
looking for systems

485
00:18:23,450 --> 00:18:24,810
where we get the best of both

486
00:18:24,810 --> 00:18:26,830
human expertise and machine

487
00:18:27,130 --> 00:18:27,630
intelligence.

488
00:18:30,455 --> 00:18:32,555
And what is hybrid
intelligence like?

489
00:18:32,855 --> 00:18:34,695
It's like the situations where

490
00:18:34,695 --> 00:18:37,150
humans and machines
do the same

491
00:18:37,150 --> 00:18:38,930
task at the same time.

492
00:18:39,950 --> 00:18:41,710
Humans and machines
interact in

493
00:18:41,710 --> 00:18:43,070
real time. This is like

494
00:18:43,070 --> 00:18:44,370
collaborative AI.

495
00:18:44,785 --> 00:18:47,045
And for that, we need
explainable AI.

496
00:18:47,505 --> 00:18:49,265
Machines learn from humans and

497
00:18:49,265 --> 00:18:50,485
humans from machines,

498
00:18:51,025 --> 00:18:52,805
which I call
reciprocal learning.

499
00:18:54,640 --> 00:18:56,180
And this isn't
science fiction.

500
00:18:56,480 --> 00:18:57,940
There are cutting
edge products

501
00:18:58,000 --> 00:18:59,940
with hybrid
intelligence already

502
00:19:00,160 --> 00:19:01,460
available on the market,

503
00:19:01,520 --> 00:19:03,300
like adaptive machine
translation,

504
00:19:04,125 --> 00:19:05,325
where the machine adapts

505
00:19:05,325 --> 00:19:07,085
translations and style in real

506
00:19:07,085 --> 00:19:09,345
time according
to human input,

507
00:19:09,485 --> 00:19:11,905
and humans can learn
from the machine's

508
00:19:12,045 --> 00:19:17,630
consensual
translations as well.

509
00:19:17,630 --> 00:19:19,470
We strategically
choose the right

510
00:19:19,470 --> 00:19:20,830
intelligence for
the right parts

511
00:19:20,830 --> 00:19:23,170
of each problem to get
the best of both.

512
00:19:23,615 --> 00:19:25,215
We trust the machine based on

513
00:19:25,215 --> 00:19:26,975
understanding and
monitoring its

514
00:19:26,975 --> 00:19:28,815
reasoning. Of course,

515
00:19:28,815 --> 00:19:30,415
we need lots more research to

516
00:19:30,415 --> 00:19:32,260
understand better what humans

517
00:19:32,260 --> 00:19:33,700
do best and what machines do

518
00:19:33,700 --> 00:19:35,700
best in these kinds of hybrid

519
00:19:35,700 --> 00:19:36,660
intelligence settings,

520
00:19:36,660 --> 00:19:38,660
and this will allow us to

521
00:19:38,660 --> 00:19:40,845
partition and assign tasks to

522
00:19:40,845 --> 00:19:42,225
achieve the best of both.

523
00:19:43,565 --> 00:19:45,005
But it's already
clear that for

524
00:19:45,005 --> 00:19:45,985
hybrid intelligence,

525
00:19:46,205 --> 00:19:47,885
we'll need knowledge
in different

526
00:19:47,885 --> 00:19:50,030
forms that both humans and

527
00:19:50,030 --> 00:19:51,330
machines can use.

528
00:19:52,270 --> 00:19:54,270
So be sure to watch
Gadi Singer's

529
00:19:54,270 --> 00:19:56,930
keynote here about
levels of knowledge.

530
00:19:57,585 --> 00:19:58,705
And again, let me whet your

531
00:19:58,705 --> 00:19:59,825
appetite with a taste of what

532
00:19:59,825 --> 00:20:01,045
he'll be talking about.

533
00:20:01,665 --> 00:20:03,925
Goddy makes a very
significant point.

534
00:20:04,465 --> 00:20:06,950
We don't need to
choose between

535
00:20:06,950 --> 00:20:09,030
deep learning
models and symbolic

536
00:20:09,030 --> 00:20:12,650
knowledge. We'll
need both and more!

537
00:20:13,785 --> 00:20:15,945
Neurosymbolic
systems are starting

538
00:20:15,945 --> 00:20:17,325
to explore this space.

539
00:20:19,465 --> 00:20:21,145
Gotti talks about three levels

540
00:20:21,145 --> 00:20:22,365
of knowledge, instantaneous

541
00:20:22,745 --> 00:20:24,730
knowledge that's directly

542
00:20:24,790 --> 00:20:27,190
available in an AI system in

543
00:20:27,190 --> 00:20:29,370
the form of embeddings
or models,

544
00:20:29,830 --> 00:20:31,590
standby knowledge
which requires

545
00:20:31,590 --> 00:20:33,465
little extra processing and is

546
00:20:33,465 --> 00:20:35,405
slower than instantaneous
knowledge.

547
00:20:35,785 --> 00:20:37,565
But it's applicable
to more situations,

548
00:20:38,185 --> 00:20:39,565
and it's probably formulated

549
00:20:39,785 --> 00:20:41,885
into some standardized
representation.

550
00:20:42,730 --> 00:20:44,250
Unless he talks
about retrieved

551
00:20:44,250 --> 00:20:45,230
external knowledge,

552
00:20:45,930 --> 00:20:47,630
which is external information

553
00:20:47,930 --> 00:20:49,470
that is probably temporarily

554
00:20:49,690 --> 00:20:52,295
relevant and often shows up in

555
00:20:52,295 --> 00:20:53,595
the form of free text.

556
00:20:54,935 --> 00:20:56,375
So let's leverage the concepts

557
00:20:56,375 --> 00:20:58,530
of hybrid intelligence
and levels

558
00:20:58,530 --> 00:21:00,930
of knowledge to
articulate more

559
00:21:00,930 --> 00:21:02,370
precise goals for knowledge

560
00:21:02,370 --> 00:21:04,470
organization and
connected data.

561
00:21:05,595 --> 00:21:06,875
This way, we'll have a clearer

562
00:21:06,875 --> 00:21:08,315
direction to lead us beyond

563
00:21:08,315 --> 00:21:10,495
building simplistic
taxonomies.

564
00:21:13,480 --> 00:21:15,340
Again, we've learned
a few more things.

565
00:21:15,640 --> 00:21:17,160
Now we can see why we need to

566
00:21:17,160 --> 00:21:19,660
move beyond taxonomies
and duct tape.

567
00:21:20,285 --> 00:21:22,145
We need different
forms of knowledge,

568
00:21:22,205 --> 00:21:24,705
not just taxonomies
or just models.

569
00:21:25,245 --> 00:21:27,245
We need to work toward hybrid

570
00:21:27,245 --> 00:21:29,085
intelligence, not just machine

571
00:21:29,085 --> 00:21:30,740
intelligence. And we need to

572
00:21:30,740 --> 00:21:32,520
enable human
machine communication

573
00:21:32,820 --> 00:21:34,120
with clear semantics.

574
00:21:38,995 --> 00:21:40,215
For hybrid intelligence,

575
00:21:40,435 --> 00:21:42,275
we'll need Godly's standby

576
00:21:42,275 --> 00:21:43,875
knowledge in place
of simplistic

577
00:21:43,875 --> 00:21:46,430
taxonomies. And how
can we get there?

578
00:21:46,810 --> 00:21:48,510
Let's make a to do list.

579
00:21:49,370 --> 00:21:50,670
First, we need to understand

580
00:21:51,050 --> 00:21:53,130
what are more
reliable building

581
00:21:53,130 --> 00:21:54,515
blocks than taxonomies.

582
00:21:56,095 --> 00:21:57,775
And the first of those is what

583
00:21:57,775 --> 00:21:59,075
I call concept catalogs,

584
00:22:01,190 --> 00:22:02,870
List of distinct important

585
00:22:02,870 --> 00:22:04,650
concepts in
different domains,

586
00:22:06,070 --> 00:22:07,590
along with different ways of

587
00:22:07,590 --> 00:22:08,570
expressing them,

588
00:22:09,145 --> 00:22:10,925
as you can see in
the table below.

589
00:22:13,545 --> 00:22:15,065
They have many advantages over

590
00:22:15,065 --> 00:22:17,840
taxonomies, and
possibly the biggest

591
00:22:17,840 --> 00:22:19,280
advantage is that they reduce

592
00:22:19,280 --> 00:22:21,620
subsequent processing
and human review,

593
00:22:22,080 --> 00:22:26,115
often by a factor
of fifty or more,

594
00:22:26,575 --> 00:22:28,255
because there are often fifty

595
00:22:28,255 --> 00:22:31,315
or more different
textual forms

596
00:22:31,615 --> 00:22:32,835
for the same concept.

597
00:22:34,710 --> 00:22:36,010
So with that,
they dramatically

598
00:22:36,070 --> 00:22:37,610
increase recall for search,

599
00:22:37,830 --> 00:22:39,450
instances for
machine learning,

600
00:22:39,510 --> 00:22:41,270
and reliability
of insights and

601
00:22:41,270 --> 00:22:43,805
analytics. Concept
catalogs are

602
00:22:43,805 --> 00:22:46,225
useful whether you
build taxonomies

603
00:22:46,365 --> 00:22:48,605
or not, and I
suspect that they

604
00:22:48,605 --> 00:22:50,680
account for most
of the ROI that

605
00:22:50,680 --> 00:22:52,380
we get from building
taxonomies.

606
00:22:55,240 --> 00:22:56,300
We're all newbies,

607
00:22:56,600 --> 00:22:58,235
but biologists
have been working

608
00:22:58,235 --> 00:22:59,835
with taxonomies for more than

609
00:22:59,835 --> 00:23:00,815
three hundred years.

610
00:23:01,435 --> 00:23:02,795
They've learned a few useful

611
00:23:02,795 --> 00:23:04,255
things from all of
that experience.

612
00:23:05,280 --> 00:23:07,600
One is building what they call

613
00:23:07,600 --> 00:23:08,980
identification keys,

614
00:23:09,520 --> 00:23:10,960
which are essentially feature

615
00:23:10,960 --> 00:23:13,060
arrays that
constitute definitions

616
00:23:13,200 --> 00:23:15,415
of species. They are a list of

617
00:23:15,415 --> 00:23:17,575
distinct important
features and

618
00:23:17,575 --> 00:23:19,515
values for each species.

619
00:23:23,110 --> 00:23:24,650
We need something very similar

620
00:23:24,950 --> 00:23:26,250
for concepts generally,

621
00:23:26,630 --> 00:23:27,930
not just for species.

622
00:23:28,550 --> 00:23:30,310
This is very
similar to what AI

623
00:23:30,310 --> 00:23:31,815
engineers call
a feature space.

624
00:23:35,015 --> 00:23:36,135
There are lots
of advantages of

625
00:23:36,135 --> 00:23:37,275
this over taxonomies.

626
00:23:37,575 --> 00:23:39,495
Categories are
output, not input.

627
00:23:39,495 --> 00:23:40,855
We can combine the features in

628
00:23:40,855 --> 00:23:42,690
different ways to
make different

629
00:23:42,690 --> 00:23:43,670
kinds of categories,

630
00:23:44,770 --> 00:23:47,030
it's not restricted
to one entity type,

631
00:23:47,250 --> 00:23:48,550
and the features are explicit

632
00:23:48,610 --> 00:23:50,150
and accessible to algorithms

633
00:23:50,745 --> 00:23:52,665
rather than hidden
inside human

634
00:23:52,665 --> 00:23:53,165
definitions.

635
00:23:55,705 --> 00:23:57,065
Another building block that we

636
00:23:57,065 --> 00:23:58,985
have to talk about is another

637
00:23:58,985 --> 00:24:00,285
kind of feature space,

638
00:24:00,960 --> 00:24:02,480
one that I haven't
seen deployed

639
00:24:02,480 --> 00:24:03,540
in recent work.

640
00:24:04,240 --> 00:24:05,520
But feature spaces I just

641
00:24:05,520 --> 00:24:07,440
mentioned for concepts usually

642
00:24:07,440 --> 00:24:09,140
focus on things or entities.

643
00:24:09,835 --> 00:24:11,535
This one focuses on defining

644
00:24:11,675 --> 00:24:13,935
relations in a similar way.

645
00:24:14,795 --> 00:24:16,075
And of course, this has many

646
00:24:16,075 --> 00:24:17,835
advantages over taxonomies as

647
00:24:17,835 --> 00:24:19,970
well because taxonomies have

648
00:24:19,970 --> 00:24:22,290
very few relation
concepts, kind of,

649
00:24:22,290 --> 00:24:23,810
example of, things like that,

650
00:24:23,810 --> 00:24:25,410
and taxonomies focus only on

651
00:24:25,410 --> 00:24:26,630
categorizing entities.

652
00:24:29,075 --> 00:24:30,275
Other knowledge organization

653
00:24:30,275 --> 00:24:32,595
methods also describe
events, actions,

654
00:24:32,595 --> 00:24:34,835
and contingencies
with relations

655
00:24:34,835 --> 00:24:36,775
like agent, cause,
instrument,

656
00:24:36,995 --> 00:24:39,430
manner, temporal order, etc.

657
00:24:40,850 --> 00:24:42,370
And we've seen
that sets of well

658
00:24:42,370 --> 00:24:43,750
defined conceptual relations

659
00:24:43,890 --> 00:24:44,870
already exist.

660
00:24:45,810 --> 00:24:48,025
They were developed
for artificial

661
00:24:48,165 --> 00:24:50,585
intelligence the first
time around,

662
00:24:50,645 --> 00:24:51,465
last century.

663
00:24:53,925 --> 00:24:55,945
These are epistemological
assumptions,

664
00:24:56,570 --> 00:24:58,170
assumptions about the form and

665
00:24:58,170 --> 00:24:59,310
nature of knowledge,

666
00:24:59,930 --> 00:25:01,530
in particular
about the role of

667
00:25:01,530 --> 00:25:02,910
different notions of truth.

668
00:25:04,005 --> 00:25:06,005
One very key
assumption is that

669
00:25:06,005 --> 00:25:07,705
assertions are either entirely

670
00:25:07,765 --> 00:25:09,625
true or entirely false.

671
00:25:10,325 --> 00:25:11,685
There are no other options in

672
00:25:11,685 --> 00:25:12,505
any circumstances.

673
00:25:13,720 --> 00:25:16,300
So if item x is in category y

674
00:25:16,600 --> 00:25:18,200
has to be entirely true or

675
00:25:18,200 --> 00:25:19,420
entirely false,

676
00:25:19,800 --> 00:25:21,635
then a statement like nursery

677
00:25:21,635 --> 00:25:23,735
manager is in
category healthcare

678
00:25:23,795 --> 00:25:26,295
jobs will force
us to incorrectly

679
00:25:26,515 --> 00:25:27,955
classify professionals who

680
00:25:27,955 --> 00:25:31,140
cultivate trees as
healthcare workers.

681
00:25:32,080 --> 00:25:33,860
The most important
change here,

682
00:25:34,000 --> 00:25:35,680
as advances in
machine learning

683
00:25:35,680 --> 00:25:37,140
and deep learning have shown,

684
00:25:37,555 --> 00:25:39,315
is to move from right wrong

685
00:25:39,315 --> 00:25:41,395
present absent binary truth

686
00:25:41,395 --> 00:25:43,635
values to
continuous confidence

687
00:25:43,635 --> 00:25:45,735
scores that
represent likelihood

688
00:25:46,210 --> 00:25:47,830
instead of absolute truth.

689
00:25:50,050 --> 00:25:52,450
So if x if item
x is in category

690
00:25:52,450 --> 00:25:54,930
y is no longer
entirely true or

691
00:25:54,930 --> 00:25:55,910
entirely false,

692
00:25:56,515 --> 00:25:57,955
then we can talk
about multiple

693
00:25:57,955 --> 00:26:00,275
parents and use
case or context

694
00:26:00,275 --> 00:26:02,195
dependent confidence
scores for

695
00:26:02,195 --> 00:26:03,255
category assignment.

696
00:26:04,180 --> 00:26:06,100
For example, in the context of

697
00:26:06,100 --> 00:26:07,160
babies in hospitals,

698
00:26:07,620 --> 00:26:09,540
nursery manager
is likely to be

699
00:26:09,540 --> 00:26:10,760
a healthcare position.

700
00:26:11,445 --> 00:26:13,385
In the context of
trees and shrubs,

701
00:26:13,525 --> 00:26:15,125
nursery manager
is likely to be

702
00:26:15,125 --> 00:26:16,665
an agricultural position.

703
00:26:17,525 --> 00:26:19,225
We can make
category assignment

704
00:26:19,525 --> 00:26:22,150
context dependent,
which is very,

705
00:26:22,150 --> 00:26:24,090
very hard to do
with taxonomies.

706
00:26:28,635 --> 00:26:30,635
All these building blocks will

707
00:26:30,635 --> 00:26:32,235
allow us to
accumulate knowledge

708
00:26:32,235 --> 00:26:33,835
and connect data by using

709
00:26:33,835 --> 00:26:35,215
statements that
have explicitly

710
00:26:35,355 --> 00:26:36,255
defined semantics,

711
00:26:37,220 --> 00:26:38,840
what I call next generation

712
00:26:39,300 --> 00:26:40,200
knowledge graphs.

713
00:26:40,740 --> 00:26:42,660
Next generation
because today's

714
00:26:42,660 --> 00:26:44,020
knowledge graphs do not always

715
00:26:44,020 --> 00:26:46,475
use concepts with
explicit human

716
00:26:46,475 --> 00:26:47,415
readable semantics.

717
00:26:48,755 --> 00:26:49,395
And, of course,

718
00:26:49,395 --> 00:26:50,755
there are many advantages over

719
00:26:50,755 --> 00:26:52,295
taxonomies for these.

720
00:26:54,710 --> 00:26:55,990
Some of them are things like

721
00:26:55,990 --> 00:26:57,350
describing knowledge of events

722
00:26:57,350 --> 00:26:59,050
and of relations
between statements,

723
00:26:59,430 --> 00:27:00,330
not just entities.

724
00:27:01,510 --> 00:27:02,550
And knowledge graphs aren't

725
00:27:02,550 --> 00:27:04,155
restricted to one
entity type,

726
00:27:05,035 --> 00:27:06,475
and they enable more kinds of

727
00:27:06,475 --> 00:27:07,615
reliable inference.

728
00:27:09,115 --> 00:27:10,395
Knowledge in this form will

729
00:27:10,395 --> 00:27:12,095
provide a more
reliable foundation

730
00:27:12,395 --> 00:27:14,180
for the next generation of

731
00:27:14,180 --> 00:27:16,360
semantic technologies and AI.

732
00:27:17,540 --> 00:27:18,900
So once again,
we've learned a few

733
00:27:18,900 --> 00:27:21,300
more things. Now
we can see why

734
00:27:21,300 --> 00:27:22,840
we need these
building blocks:

735
00:27:23,140 --> 00:27:25,435
concept catalogs,
concept models,

736
00:27:26,055 --> 00:27:27,515
explicit relation concepts,

737
00:27:28,135 --> 00:27:29,515
more realistic epistemological

738
00:27:30,055 --> 00:27:32,155
assumptions, and
knowledge graphs.

739
00:27:32,660 --> 00:27:34,120
But how can we get there?

740
00:27:34,900 --> 00:27:36,520
We need to shore
up our foundations

741
00:27:36,740 --> 00:27:37,860
to reach these goals,

742
00:27:37,860 --> 00:27:39,860
and I see significant
issues at

743
00:27:39,860 --> 00:27:41,080
the base of our efforts.

744
00:27:42,015 --> 00:27:44,415
We have to move
beyond believing

745
00:27:44,415 --> 00:27:46,335
knowledge creation for AI in

746
00:27:46,335 --> 00:27:48,115
the hands of naive, novice,

747
00:27:48,335 --> 00:27:49,155
non practitioners.

748
00:27:50,740 --> 00:27:52,260
We need systematic training

749
00:27:52,260 --> 00:27:54,520
programs to create
essential talent.

750
00:27:55,220 --> 00:27:56,280
We don't have them.

751
00:27:56,740 --> 00:27:58,500
I've built taxonomy teams and

752
00:27:58,500 --> 00:27:59,720
crowdsourcing programs.

753
00:28:00,245 --> 00:28:01,525
I can tell you how very,

754
00:28:01,525 --> 00:28:02,745
very hard it is.

755
00:28:03,125 --> 00:28:04,665
We have to start
with fundamental

756
00:28:04,725 --> 00:28:06,505
questions like, do we
need taxonomists?

757
00:28:07,045 --> 00:28:08,245
What do they look like?

758
00:28:08,245 --> 00:28:09,520
Where can we find them?

759
00:28:10,320 --> 00:28:11,680
We need to explain this to

760
00:28:11,680 --> 00:28:13,520
managers and
executives to fund

761
00:28:13,520 --> 00:28:15,120
the work. We need to explain

762
00:28:15,120 --> 00:28:17,600
this to HR to help us find and

763
00:28:17,600 --> 00:28:18,660
cultivate talent.

764
00:28:20,965 --> 00:28:22,425
Once we have the teams,

765
00:28:22,565 --> 00:28:24,425
what's the best way
for them to work?

766
00:28:24,885 --> 00:28:26,265
We simply don't know.

767
00:28:26,760 --> 00:28:28,520
But we do know that we have to

768
00:28:28,520 --> 00:28:30,380
move beyond simply
improvising.

769
00:28:30,920 --> 00:28:32,860
We need industry
best practices

770
00:28:33,000 --> 00:28:33,660
to follow.

771
00:28:36,095 --> 00:28:37,875
We need industry
backed processes

772
00:28:38,175 --> 00:28:40,035
to ensure reliable results,

773
00:28:40,335 --> 00:28:41,715
and we don't have them.

774
00:28:43,980 --> 00:28:45,340
Once we have a clear idea of

775
00:28:45,340 --> 00:28:47,340
the best ways for
our teams to work,

776
00:28:47,340 --> 00:28:48,640
how can we help them?

777
00:28:48,860 --> 00:28:49,980
We don't want them to work

778
00:28:49,980 --> 00:28:52,005
independently on
one item at a time

779
00:28:52,085 --> 00:28:54,745
in random order,
slowly and manually,

780
00:28:54,965 --> 00:28:57,305
like a sculptor crafting
a tiny statue.

781
00:28:58,085 --> 00:28:59,945
We have to move
beyond crafting

782
00:29:00,005 --> 00:29:01,545
to manufacturing knowledge.

783
00:29:01,890 --> 00:29:04,770
We need tools to design and

784
00:29:04,770 --> 00:29:05,910
validate knowledge.

785
00:29:06,770 --> 00:29:08,770
We have to have
tools to ensure

786
00:29:08,770 --> 00:29:10,470
reliable results at scale.

787
00:29:11,295 --> 00:29:12,435
We don't have them,

788
00:29:12,495 --> 00:29:15,155
and spreadsheets
just won't suffice.

789
00:29:17,455 --> 00:29:18,915
To make semantic technologies

790
00:29:19,135 --> 00:29:20,655
really thrive, we need all of

791
00:29:20,655 --> 00:29:22,120
these things: better building

792
00:29:22,120 --> 00:29:23,180
blocks and taxonomies,

793
00:29:23,880 --> 00:29:25,420
more better trained
professionals,

794
00:29:26,040 --> 00:29:27,340
explicit best practices,

795
00:29:28,095 --> 00:29:29,855
and AI tools for design and

796
00:29:29,855 --> 00:29:31,075
validation of knowledge,

797
00:29:31,535 --> 00:29:33,795
not just for storage
and display.

798
00:29:35,990 --> 00:29:37,990
Let's create together a better

799
00:29:37,990 --> 00:29:39,830
foundation for
the next generation

800
00:29:39,830 --> 00:29:41,990
of Symantec technologies and

801
00:29:41,990 --> 00:29:43,050
connected data.

802
00:29:43,901 --> 00:29:45,201
Thanks for your attention.


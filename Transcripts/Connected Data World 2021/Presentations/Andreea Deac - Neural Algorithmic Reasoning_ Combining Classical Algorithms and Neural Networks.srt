1
00:00:03,720 --> 00:00:04,380
Hello everybody.

2
00:00:04,600 --> 00:00:05,640
I'm Andreea Deac,

3
00:00:05,640 --> 00:00:07,320
PhD student at
Mila University

4
00:00:07,320 --> 00:00:09,240
of Montreal. And
today I'm happy

5
00:00:09,240 --> 00:00:11,705
to present a talk
that I think will,

6
00:00:11,705 --> 00:00:13,305
will be interesting
to all problem

7
00:00:13,305 --> 00:00:14,685
solvers among us.

8
00:00:15,225 --> 00:00:16,905
This is called
neural algorithmic

9
00:00:16,905 --> 00:00:19,150
reasoning. And
we'll we'll talk

10
00:00:19,150 --> 00:00:20,770
about how to combine classical

11
00:00:20,910 --> 00:00:22,450
algorithms and
neural networks.

12
00:00:23,710 --> 00:00:26,485
This is, as you might
think already,

13
00:00:26,705 --> 00:00:29,025
there are two well
known approaches

14
00:00:29,025 --> 00:00:30,405
to problem solving,

15
00:00:31,265 --> 00:00:32,625
each with their
own benefits and

16
00:00:32,625 --> 00:00:35,420
drawbacks. So algorithms are

17
00:00:35,420 --> 00:00:37,040
trivially strongly
generalizable.

18
00:00:37,980 --> 00:00:40,240
You can apply
them to different

19
00:00:40,700 --> 00:00:43,695
sized inputs, and they
will still work.

20
00:00:43,755 --> 00:00:45,675
They you can
compose them if you

21
00:00:45,675 --> 00:00:47,375
have different functions,
subroutines.

22
00:00:48,155 --> 00:00:49,935
You can you can use
them together,

23
00:00:49,995 --> 00:00:50,735
change them.

24
00:00:51,260 --> 00:00:53,120
They have
guaranteed correctness

25
00:00:53,660 --> 00:00:55,600
and they are interpretable.

26
00:00:56,220 --> 00:00:57,920
They have interpretable
operations.

27
00:00:58,060 --> 00:00:59,520
We always know what
they're doing.

28
00:01:00,545 --> 00:01:03,025
However, their
inputs must always

29
00:01:03,025 --> 00:01:04,485
match a specific format,

30
00:01:05,505 --> 00:01:07,185
and they're not robust to task

31
00:01:07,185 --> 00:01:09,830
variations. On
the other hand,

32
00:01:09,830 --> 00:01:14,550
the the more recent, go to,

33
00:01:14,550 --> 00:01:15,930
the the neural networks,

34
00:01:17,235 --> 00:01:19,495
they can operate
on raw inputs.

35
00:01:20,035 --> 00:01:22,195
They can generalize
on basic conditions.

36
00:01:22,195 --> 00:01:23,815
So even if,

37
00:01:24,515 --> 00:01:26,220
our inputs are
are not precise,

38
00:01:26,220 --> 00:01:27,480
they will still work.

39
00:01:28,340 --> 00:01:30,440
They can be used
across tasks.

40
00:01:32,020 --> 00:01:35,075
But a a downside
is that before

41
00:01:35,075 --> 00:01:36,935
getting a neural network to

42
00:01:37,155 --> 00:01:39,575
perform well, we
usually require

43
00:01:39,635 --> 00:01:41,335
a lot of data to train them,

44
00:01:41,795 --> 00:01:44,050
to get them to
a good performance.

45
00:01:45,410 --> 00:01:47,170
They are also unreliable when

46
00:01:47,170 --> 00:01:50,930
extrapolating, and they lack

47
00:01:50,930 --> 00:01:52,870
interpretability,
although that's

48
00:01:53,135 --> 00:01:54,675
actively being worked on.

49
00:01:55,695 --> 00:01:57,615
You might notice
that these two

50
00:01:57,615 --> 00:01:59,935
approaches have
attributes that

51
00:01:59,935 --> 00:02:03,490
are complementary,
and what we,

52
00:02:03,490 --> 00:02:04,850
what we might want is to get

53
00:02:04,850 --> 00:02:06,130
the best of both worlds.

54
00:02:06,130 --> 00:02:07,730
So this is what
today's talk is

55
00:02:07,730 --> 00:02:08,630
going to be about.

56
00:02:09,650 --> 00:02:11,455
And I'll start
by talking about

57
00:02:11,455 --> 00:02:14,755
a problem that is,
quite simple.

58
00:02:14,895 --> 00:02:17,215
Most computer science
students meet it,

59
00:02:17,455 --> 00:02:18,755
at some point or another.

60
00:02:20,950 --> 00:02:22,870
So if we have a weighted graph

61
00:02:22,870 --> 00:02:24,890
with a specific source,

62
00:02:25,510 --> 00:02:26,490
node of interest,

63
00:02:26,950 --> 00:02:28,390
and we want to compute all

64
00:02:28,390 --> 00:02:29,805
shortest paths from this node

65
00:02:29,805 --> 00:02:31,505
to the other nodes
in the graph.

66
00:02:32,365 --> 00:02:34,925
We can do this by using some

67
00:02:34,925 --> 00:02:36,465
dynamic programming
algorithm,

68
00:02:36,525 --> 00:02:38,840
for example,
Bellman form being

69
00:02:38,840 --> 00:02:39,740
one of them.

70
00:02:41,400 --> 00:02:44,840
And recently, there,
there was the,

71
00:02:44,840 --> 00:02:46,325
the paper called
neural execution

72
00:02:46,325 --> 00:02:48,505
of graph algorithms, where,

73
00:02:50,005 --> 00:02:52,265
a team of researchers
tried to,

74
00:02:52,870 --> 00:02:54,630
to propose a neural
network that

75
00:02:54,630 --> 00:02:56,010
can achieve the same goal.

76
00:02:56,390 --> 00:02:58,230
So this was a graph
neural network

77
00:02:58,230 --> 00:03:00,890
in particular that was
supervised to on,

78
00:03:01,635 --> 00:03:03,875
intermediate outputs
of the Bellman

79
00:03:03,875 --> 00:03:04,615
Ford algorithm.

80
00:03:05,955 --> 00:03:07,795
So this was this is also known

81
00:03:07,795 --> 00:03:10,330
as trunk supervision of at,

82
00:03:10,650 --> 00:03:12,910
at every step of
the of the iteration.

83
00:03:14,170 --> 00:03:16,890
And you can see then the what

84
00:03:16,890 --> 00:03:19,175
what we the the operation in

85
00:03:19,175 --> 00:03:20,795
the dynamic programming
algorithm,

86
00:03:21,735 --> 00:03:23,815
aligns quite well
with the message

87
00:03:23,815 --> 00:03:26,315
passing update
rule, in a way.

88
00:03:26,750 --> 00:03:29,250
So this observation was,

89
00:03:32,830 --> 00:03:35,265
was something that was,

90
00:03:35,805 --> 00:03:38,625
explored more in, in
a concurrent work,

91
00:03:39,485 --> 00:03:41,890
where where they
they discovered

92
00:03:41,890 --> 00:03:43,750
that graph neural
networks align well,

93
00:03:44,210 --> 00:03:45,990
in general with
dynamic programming

94
00:03:46,050 --> 00:03:47,910
algorithms, not
just Bellman Ford.

95
00:03:48,865 --> 00:03:50,405
And some other,

96
00:03:51,025 --> 00:03:56,245
findings were were
were pointed out.

97
00:03:56,625 --> 00:03:59,070
So, for example,

98
00:04:00,010 --> 00:04:01,210
this strong supervision I was

99
00:04:01,210 --> 00:04:02,490
talking about is
actually quite

100
00:04:02,490 --> 00:04:04,010
important to
a good performance

101
00:04:04,010 --> 00:04:05,370
of the graph neural network in

102
00:04:05,370 --> 00:04:06,510
imitating the algorithm.

103
00:04:08,675 --> 00:04:10,435
We it requires things like,

104
00:04:10,675 --> 00:04:11,575
a different aggregation,

105
00:04:11,635 --> 00:04:13,575
the max aggregation
to perform well,

106
00:04:13,635 --> 00:04:14,375
which aligns,

107
00:04:15,075 --> 00:04:17,590
again with the with
what we know

108
00:04:17,590 --> 00:04:19,610
the dynamic programming
algorithm,

109
00:04:20,150 --> 00:04:21,990
does. More recently,

110
00:04:21,990 --> 00:04:23,670
there's also been
a lot of work

111
00:04:23,670 --> 00:04:25,935
on proposing better
architectures,

112
00:04:26,075 --> 00:04:27,615
for example, for for,

113
00:04:28,715 --> 00:04:30,635
achieving some
computation classic

114
00:04:30,635 --> 00:04:31,775
computational goals,

115
00:04:32,555 --> 00:04:35,760
and the some even more
recent insights,

116
00:04:36,620 --> 00:04:38,240
for example,
linear algorithmic

117
00:04:38,460 --> 00:04:39,840
alignment is highly
beneficial.

118
00:04:41,020 --> 00:04:43,680
And if we learn
multiple algorithms

119
00:04:43,740 --> 00:04:45,385
in a multi tasking way,

120
00:04:45,685 --> 00:04:47,225
this can also improve
performance.

121
00:04:47,365 --> 00:04:48,985
So this is also very useful,

122
00:04:49,285 --> 00:04:51,145
especially if we
want a component

123
00:04:51,205 --> 00:04:53,145
that learns multiple
algorithms,

124
00:04:53,205 --> 00:04:54,105
not just one.

125
00:04:55,100 --> 00:04:57,820
So this led to
a blueprint being

126
00:04:57,820 --> 00:04:59,260
proposed by Velich, Komichi,

127
00:04:59,260 --> 00:05:02,000
and Glanton, in in patterns.

128
00:05:02,685 --> 00:05:05,105
So under the the name
of neural

129
00:05:05,245 --> 00:05:06,305
algorithmic reasoning,

130
00:05:06,365 --> 00:05:07,425
we have this blueprint,

131
00:05:08,445 --> 00:05:11,300
which starts from
from the assumption

132
00:05:11,300 --> 00:05:13,140
that if we have
a task where we

133
00:05:13,140 --> 00:05:14,900
know an algorithm
could be could

134
00:05:14,900 --> 00:05:16,565
be useful to solve this task,

135
00:05:16,885 --> 00:05:18,505
Then we can pretrain
the processor

136
00:05:18,805 --> 00:05:21,445
on some abstract
inputs to learn this,

137
00:05:21,445 --> 00:05:22,725
how to execute this,

138
00:05:22,725 --> 00:05:24,425
how to simulate
this algorithm.

139
00:05:25,110 --> 00:05:26,230
And then we can take this

140
00:05:26,230 --> 00:05:27,990
processor and plug it into our

141
00:05:27,990 --> 00:05:29,130
natural pipeline.

142
00:05:29,510 --> 00:05:32,010
So in the, in the case of

143
00:05:32,150 --> 00:05:34,410
navigation where we're
interested from,

144
00:05:34,495 --> 00:05:36,815
from getting, in getting from

145
00:05:36,815 --> 00:05:38,995
point a to b, c, or d,

146
00:05:39,455 --> 00:05:40,815
we might want to use something

147
00:05:40,815 --> 00:05:41,535
like Bellarmine Fund,

148
00:05:41,535 --> 00:05:42,975
which computes surface path to

149
00:05:42,975 --> 00:05:45,260
see what is the best way to to

150
00:05:45,260 --> 00:05:48,560
get somewhere, to to
do, to to navigate.

151
00:05:49,500 --> 00:05:51,520
So keeping this
blueprint in mind,

152
00:05:51,740 --> 00:05:52,800
you might be wondering,

153
00:05:53,485 --> 00:05:54,945
does this work in practice?

154
00:05:55,005 --> 00:05:58,205
Has this been used in in some

155
00:05:58,205 --> 00:06:00,525
tasks already?
So in this talk,

156
00:06:00,525 --> 00:06:01,425
I'll talk about,

157
00:06:02,250 --> 00:06:03,790
how this was used
in reinforcement

158
00:06:03,850 --> 00:06:07,130
learning. Our our
proposed agent,

159
00:06:07,130 --> 00:06:10,110
Excelvin, was done
in collaboration

160
00:06:10,250 --> 00:06:12,285
with Petar Velish
Velishkovich,

161
00:06:12,425 --> 00:06:14,925
Piotr Bakon, Jan Tang,
and Vlad Nikolic.

162
00:06:16,105 --> 00:06:17,645
And even more recently,

163
00:06:18,800 --> 00:06:20,080
explored this
blueprint was also

164
00:06:20,080 --> 00:06:21,780
explored in a self supervised

165
00:06:21,920 --> 00:06:22,820
learning setup,

166
00:06:23,520 --> 00:06:25,300
in the paper named reasoning

167
00:06:25,360 --> 00:06:27,475
modulated
representations about

168
00:06:27,475 --> 00:06:28,915
which I won't have
time to talk,

169
00:06:28,915 --> 00:06:31,655
but I recommend you
you go check it out.

170
00:06:32,515 --> 00:06:34,040
So to jump straight into it,

171
00:06:34,920 --> 00:06:36,600
in a reinforcement
learning setup,

172
00:06:36,600 --> 00:06:38,460
we have an agent that,

173
00:06:39,400 --> 00:06:41,560
acts upon a word and receives

174
00:06:41,560 --> 00:06:43,395
observations back
from this word.

175
00:06:43,955 --> 00:06:47,095
This agent can decide
to build a plan,

176
00:06:47,635 --> 00:06:49,075
and update this plan based on

177
00:06:49,075 --> 00:06:51,770
observations, a plan that can

178
00:06:51,770 --> 00:06:54,490
then be used on deciding which

179
00:06:54,490 --> 00:06:55,550
actions to take.

180
00:06:56,330 --> 00:06:58,570
So formalizing this a bit,

181
00:06:58,730 --> 00:07:01,595
this is usually found under

182
00:07:01,595 --> 00:07:03,535
the Markov decision
process framework,

183
00:07:04,475 --> 00:07:06,255
where we have a state space,

184
00:07:07,275 --> 00:07:08,335
an action space.

185
00:07:08,810 --> 00:07:10,330
We have transition
the transition

186
00:07:10,330 --> 00:07:11,950
matrix. So what's
the probability

187
00:07:12,330 --> 00:07:12,990
of being,

188
00:07:13,770 --> 00:07:15,790
of getting to a state s frame

189
00:07:15,965 --> 00:07:17,645
given that we're in a current

190
00:07:17,645 --> 00:07:20,305
state s and we take
a specific action a.

191
00:07:21,085 --> 00:07:21,905
Also rewards.

192
00:07:22,045 --> 00:07:23,870
So what's the reward that,

193
00:07:24,910 --> 00:07:26,670
the agent will receive by,

194
00:07:27,070 --> 00:07:29,170
doing action a in state s?

195
00:07:29,950 --> 00:07:31,970
And the goal is to
find the policy,

196
00:07:33,135 --> 00:07:35,055
pi that tells me what what is

197
00:07:35,055 --> 00:07:36,655
the sequence of actions that I

198
00:07:36,655 --> 00:07:39,395
need to take in
order to optimize

199
00:07:39,455 --> 00:07:41,315
the discounted
cumulative reward.

200
00:07:41,375 --> 00:07:42,100
So get,

201
00:07:42,900 --> 00:07:44,740
as much reward over a longer

202
00:07:44,740 --> 00:07:46,760
time horizon as possible.

203
00:07:48,340 --> 00:07:50,435
So policies that act purely

204
00:07:50,575 --> 00:07:52,175
through adapting
to rewards are

205
00:07:52,175 --> 00:07:52,995
called reactive.

206
00:07:53,695 --> 00:07:55,075
And in many cases,

207
00:07:55,375 --> 00:07:57,055
to to get them to work well,

208
00:07:57,055 --> 00:07:58,655
they require a lot of data and

209
00:07:58,655 --> 00:08:00,020
are quite slow to adapt.

210
00:08:00,880 --> 00:08:02,240
And planning is something that

211
00:08:02,240 --> 00:08:04,240
was proposed to
ameliorate these

212
00:08:04,240 --> 00:08:06,720
issues by maintaining
an explicit

213
00:08:06,720 --> 00:08:07,860
model of the world.

214
00:08:08,335 --> 00:08:09,615
So what this means is that we

215
00:08:09,615 --> 00:08:10,735
would have a state transition

216
00:08:10,735 --> 00:08:12,835
model and the reward model,

217
00:08:12,895 --> 00:08:14,655
which would usually train from

218
00:08:14,655 --> 00:08:15,955
some observed trajectory.

219
00:08:16,015 --> 00:08:17,235
So having the agent,

220
00:08:18,340 --> 00:08:19,940
acting to the world and gather

221
00:08:19,940 --> 00:08:22,420
some data. And using
these motors,

222
00:08:22,420 --> 00:08:24,420
a planner can
simulate the effects

223
00:08:24,420 --> 00:08:26,020
of actions before
taking them,

224
00:08:26,020 --> 00:08:27,765
which is very important and

225
00:08:27,765 --> 00:08:29,685
comes with some
important benefits

226
00:08:29,685 --> 00:08:31,465
as as we are going
to see now.

227
00:08:31,925 --> 00:08:33,925
So some of these
benefits well,

228
00:08:33,925 --> 00:08:35,945
the first one is
data efficiency.

229
00:08:37,120 --> 00:08:38,480
And this is very important if

230
00:08:38,480 --> 00:08:39,840
we're planning to
use our agents

231
00:08:39,840 --> 00:08:41,200
in real world where we don't

232
00:08:41,200 --> 00:08:42,800
have access to
millions of frames

233
00:08:42,800 --> 00:08:44,580
as we do in
the case of games.

234
00:08:46,245 --> 00:08:48,965
So if if we have
the good model,

235
00:08:48,965 --> 00:08:50,245
that would mean that we'd have

236
00:08:50,245 --> 00:08:51,785
to interact less
with the environment

237
00:08:52,165 --> 00:08:54,505
in order to get,
a good policy.

238
00:08:55,820 --> 00:08:57,500
Then strong models will also

239
00:08:57,500 --> 00:09:00,320
allow us to adapt to
unseen situations.

240
00:09:02,220 --> 00:09:05,445
So that is very important,

241
00:09:06,145 --> 00:09:08,145
if if anything is changing in

242
00:09:08,145 --> 00:09:10,565
the environment, for example,

243
00:09:11,060 --> 00:09:12,740
And also very important for

244
00:09:12,740 --> 00:09:14,500
safety reasons because if we

245
00:09:14,500 --> 00:09:15,880
have a strong model predicting

246
00:09:16,340 --> 00:09:17,940
if some action would be would

247
00:09:17,940 --> 00:09:19,640
lead to a unsafe outcome,

248
00:09:20,005 --> 00:09:21,205
that that means that we can

249
00:09:21,205 --> 00:09:22,805
avoid taking that that action

250
00:09:22,805 --> 00:09:25,125
to to learn, that
would happen.

251
00:09:25,125 --> 00:09:27,285
So, this would this is quite

252
00:09:27,285 --> 00:09:28,905
important from
a safety considerate.

253
00:09:30,280 --> 00:09:32,860
It will also allow
us to account for,

254
00:09:33,560 --> 00:09:35,320
external factors such as human

255
00:09:35,320 --> 00:09:36,680
interactions. And in fact,

256
00:09:36,680 --> 00:09:39,020
this was already used
in game training,

257
00:09:39,275 --> 00:09:40,555
alpha go, which
you've probably

258
00:09:40,555 --> 00:09:42,655
heard about, and
across the sciences,

259
00:09:43,355 --> 00:09:45,535
for example, for
chemical synthesis.

260
00:09:47,980 --> 00:09:50,240
Planning has some,
theoretical,

261
00:09:52,300 --> 00:09:54,640
results that that are
very encouraging.

262
00:09:55,715 --> 00:09:57,575
So if we had
the perfect model,

263
00:09:58,035 --> 00:09:59,715
this would allow
us to plan for

264
00:09:59,715 --> 00:10:00,595
perfect policies,

265
00:10:00,595 --> 00:10:02,375
and this is quite important.

266
00:10:04,630 --> 00:10:07,350
One algorithm that
is very useful

267
00:10:07,350 --> 00:10:08,890
for planning is
value iteration.

268
00:10:09,590 --> 00:10:11,690
This is a dynamic
programming algorithm,

269
00:10:12,325 --> 00:10:14,325
which is we'll
see why why it's

270
00:10:14,325 --> 00:10:15,625
important in a bit,

271
00:10:16,085 --> 00:10:18,005
that can allow us to perfectly

272
00:10:18,005 --> 00:10:19,525
solve a reinforcement learning

273
00:10:19,525 --> 00:10:23,240
environment. So what
this does is it,

274
00:10:23,560 --> 00:10:25,400
it computes values of states

275
00:10:25,400 --> 00:10:28,380
based on the values
of neighboring

276
00:10:28,520 --> 00:10:31,455
states. And it starts
with, for example,

277
00:10:31,455 --> 00:10:34,035
a random estimate
and gradually

278
00:10:34,415 --> 00:10:36,900
improves this
estimate until it

279
00:10:36,900 --> 00:10:38,360
reaches an optimal solution.

280
00:10:39,220 --> 00:10:41,160
So this is guaranteed
to happen,

281
00:10:41,620 --> 00:10:42,760
which is very convenient.

282
00:10:43,965 --> 00:10:45,805
And if once we complete this

283
00:10:45,805 --> 00:10:46,785
optimal solution,

284
00:10:47,165 --> 00:10:49,085
then the optimal policy can be

285
00:10:49,085 --> 00:10:50,605
found just by
taking the actions

286
00:10:50,605 --> 00:10:52,065
that maximize these values.

287
00:10:54,030 --> 00:10:56,670
So once we now
now that we know

288
00:10:56,670 --> 00:10:58,210
about this very
useful algorithm,

289
00:10:58,910 --> 00:11:00,590
well, we we we could think,

290
00:11:00,590 --> 00:11:02,030
what what can we do with it?

291
00:11:02,030 --> 00:11:04,705
So could we actually use it in

292
00:11:04,705 --> 00:11:06,145
a reinforcement
learning environment?

293
00:11:06,145 --> 00:11:07,765
That would be
a a great thing.

294
00:11:08,785 --> 00:11:10,360
Assuming for now,

295
00:11:10,360 --> 00:11:12,200
we'll assume that
we have the reward

296
00:11:12,200 --> 00:11:13,820
function and
the transition matrix.

297
00:11:14,120 --> 00:11:15,400
And in a bit, we'll talk about

298
00:11:15,400 --> 00:11:16,680
what what to do when we don't

299
00:11:16,680 --> 00:11:17,645
have these two things.

300
00:11:18,205 --> 00:11:19,645
So we assume the transition

301
00:11:19,645 --> 00:11:21,345
matrix is fixed and known.

302
00:11:25,230 --> 00:11:26,770
By known, for example,

303
00:11:27,390 --> 00:11:29,230
each state has no
neighbors, up,

304
00:11:29,230 --> 00:11:30,750
down, left, right.

305
00:11:30,750 --> 00:11:31,890
The actions are
deterministic,

306
00:11:32,795 --> 00:11:34,795
and computing
value doing value

307
00:11:34,795 --> 00:11:36,635
iteration would
amount computing

308
00:11:36,635 --> 00:11:38,255
sums of neighboring values.

309
00:11:38,795 --> 00:11:40,315
And this might already remind

310
00:11:40,315 --> 00:11:42,200
you of something that's
that's familiar.

311
00:11:42,260 --> 00:11:44,440
So convolutional
neural networks

312
00:11:45,140 --> 00:11:46,900
are quite well
suited to computing

313
00:11:46,900 --> 00:11:49,560
this convolution
like, computation.

314
00:11:50,745 --> 00:11:52,285
And this idea was,

315
00:11:53,145 --> 00:11:54,905
leveraged in value
iteration networks,

316
00:11:54,905 --> 00:11:56,765
which got the best paper award

317
00:11:57,145 --> 00:11:58,685
in NeurIPS in twenty sixteen.

318
00:12:00,020 --> 00:12:01,320
So to to summarize,

319
00:12:01,620 --> 00:12:04,740
they assuming the MDP
is discrete,

320
00:12:04,740 --> 00:12:05,800
fixed, and null,

321
00:12:05,940 --> 00:12:07,400
they perform value iteration

322
00:12:08,145 --> 00:12:09,205
computation by stacking,

323
00:12:10,305 --> 00:12:11,925
shared convolutional errors.

324
00:12:13,425 --> 00:12:15,605
And while this is great,

325
00:12:15,930 --> 00:12:17,610
it has the the downside that

326
00:12:17,610 --> 00:12:19,130
this is quite restricted in

327
00:12:19,130 --> 00:12:20,970
the sense the MDP
needs to be discrete,

328
00:12:20,970 --> 00:12:21,950
fixed, and no.

329
00:12:22,010 --> 00:12:24,910
And Givens already
take a step towards,

330
00:12:26,325 --> 00:12:31,225
more general cases
extending to

331
00:12:31,365 --> 00:12:33,225
to the case where the the MDP

332
00:12:33,365 --> 00:12:34,970
doesn't have to be
agreed for it.

333
00:12:36,090 --> 00:12:38,190
But it is still
fixed and known.

334
00:12:38,810 --> 00:12:41,690
So in that case,
like, so far,

335
00:12:41,690 --> 00:12:43,790
we didn't need to
estimate the transition

336
00:12:43,850 --> 00:12:45,935
model. We didn't
need to to find

337
00:12:45,935 --> 00:12:48,115
one that the the p would be,

338
00:12:48,495 --> 00:12:49,855
and we didn't
have to deal with

339
00:12:49,855 --> 00:12:51,375
continuous state
spaces either.

340
00:12:51,375 --> 00:12:52,735
But what would
happen if we did

341
00:12:52,735 --> 00:12:53,715
another mdp?

342
00:12:54,120 --> 00:12:55,500
Well, we can think a bit,

343
00:12:56,040 --> 00:12:57,320
what would the human feature

344
00:12:57,320 --> 00:12:59,180
engineer do to
use validation,

345
00:12:59,560 --> 00:13:01,720
which you've seen with a very

346
00:13:01,720 --> 00:13:02,620
useful algorithm.

347
00:13:03,725 --> 00:13:05,505
So the human feature engineer

348
00:13:05,645 --> 00:13:09,165
would take the game
frame, the,

349
00:13:09,165 --> 00:13:10,945
which we call
the natural input

350
00:13:11,370 --> 00:13:13,130
and compute some
abstract input

351
00:13:13,130 --> 00:13:16,250
from it on which it they would

352
00:13:16,250 --> 00:13:18,570
be able to run
the value iteration

353
00:13:18,570 --> 00:13:20,670
algorithm to get
abstract outputs.

354
00:13:22,345 --> 00:13:24,185
However, we've seen that deep

355
00:13:24,185 --> 00:13:25,865
learning does a very good job

356
00:13:25,865 --> 00:13:27,785
when we don't have to manually

357
00:13:27,785 --> 00:13:30,250
compute features.

358
00:13:31,750 --> 00:13:34,310
So we'll we'll use
some of this,

359
00:13:34,790 --> 00:13:36,230
some of this insight and have

360
00:13:36,230 --> 00:13:41,475
an encoder, that,
bypasses this part of,

361
00:13:41,795 --> 00:13:42,775
human engineering.

362
00:13:43,795 --> 00:13:46,215
So this would stick
our natural input,

363
00:13:46,960 --> 00:13:47,940
to an embedding.

364
00:13:48,800 --> 00:13:51,120
And that is great,

365
00:13:51,120 --> 00:13:52,640
but that that
will still not be

366
00:13:52,640 --> 00:13:53,680
everything we need to run

367
00:13:53,680 --> 00:13:55,595
validation if we didn't have

368
00:13:55,675 --> 00:13:56,575
the transition matrix.

369
00:13:56,715 --> 00:13:59,775
For that, we can use
a transition model,

370
00:14:00,155 --> 00:14:02,475
to build this local MDP that

371
00:14:02,475 --> 00:14:04,490
where we need in order to run

372
00:14:04,490 --> 00:14:05,390
value iteration.

373
00:14:05,850 --> 00:14:07,630
And this was already studied,

374
00:14:08,010 --> 00:14:09,370
quite a bit, and there exist

375
00:14:09,370 --> 00:14:11,290
many popular methods for for

376
00:14:11,290 --> 00:14:12,830
training this
transition model.

377
00:14:13,005 --> 00:14:14,205
I'll just name one of them,

378
00:14:14,205 --> 00:14:16,125
which is what we
used in our in

379
00:14:16,125 --> 00:14:17,345
our proposed agent.

380
00:14:18,845 --> 00:14:20,145
So contrastive learning,

381
00:14:20,685 --> 00:14:23,540
is is one way of training t.

382
00:14:24,320 --> 00:14:26,240
And this would be this would

383
00:14:26,240 --> 00:14:28,020
mean training t
to discriminate

384
00:14:28,160 --> 00:14:31,995
between true next states and

385
00:14:31,995 --> 00:14:33,595
some fake next next states,

386
00:14:33,595 --> 00:14:36,175
some randomly
sampled, s tilde.

387
00:14:36,955 --> 00:14:39,060
So if we have a traditional

388
00:14:39,060 --> 00:14:41,220
model that learned how to how

389
00:14:41,220 --> 00:14:44,040
the next state s primes
will look like,

390
00:14:44,100 --> 00:14:45,860
this transition model then can

391
00:14:45,860 --> 00:14:50,265
then be used in a in
a in a generative

392
00:14:50,725 --> 00:14:53,365
manner in a way to to build

393
00:14:53,365 --> 00:14:55,445
the the tree over which we had

394
00:14:55,445 --> 00:14:56,585
run value iteration.

395
00:15:00,920 --> 00:15:04,780
So if we have this
tree, we have the p,

396
00:15:05,305 --> 00:15:07,385
but we still don't
have the reward

397
00:15:07,385 --> 00:15:08,545
model. So for now,

398
00:15:08,545 --> 00:15:10,285
we'll assume that
this is given.

399
00:15:10,585 --> 00:15:12,665
We'll assume that the nodes in

400
00:15:12,665 --> 00:15:14,560
it in the in the tree I I've

401
00:15:14,560 --> 00:15:16,100
previously shown are no.

402
00:15:17,360 --> 00:15:18,800
And that would
be everything we

403
00:15:18,800 --> 00:15:20,180
need to run value iteration,

404
00:15:21,360 --> 00:15:22,845
directly over this tree.

405
00:15:22,925 --> 00:15:24,365
And this is exactly what was

406
00:15:24,365 --> 00:15:26,045
done in pre q n and value

407
00:15:26,045 --> 00:15:27,025
prediction networks.

408
00:15:27,565 --> 00:15:29,265
And to summarize
their architecture,

409
00:15:29,405 --> 00:15:31,505
we have the state
and the encoder,

410
00:15:33,130 --> 00:15:34,190
which is then,

411
00:15:35,050 --> 00:15:37,870
is then used repeatedly
to build a tree.

412
00:15:39,585 --> 00:15:40,645
And from industry,

413
00:15:41,025 --> 00:15:43,025
the values are
estimated in each

414
00:15:43,025 --> 00:15:43,765
of the nodes,

415
00:15:44,945 --> 00:15:46,385
and then this then this can be

416
00:15:46,385 --> 00:15:48,145
used for value iteration to to

417
00:15:48,145 --> 00:15:51,430
do the backup and
and use this.

418
00:15:52,850 --> 00:15:54,450
So to to summarize a bit what

419
00:15:54,450 --> 00:15:55,650
I've talked about so far,

420
00:15:55,650 --> 00:15:57,325
we mapped our
natural inputs to

421
00:15:57,325 --> 00:15:58,645
the space of abstract inputs

422
00:15:58,645 --> 00:15:59,625
using an encoder.

423
00:16:00,245 --> 00:16:01,685
Using a transition model,

424
00:16:01,685 --> 00:16:03,145
we build a local MDP,

425
00:16:04,150 --> 00:16:06,230
and we estimated
the rewards in

426
00:16:06,230 --> 00:16:08,470
in each of the nodes
in in the case

427
00:16:08,470 --> 00:16:09,050
of GQN.

428
00:16:10,150 --> 00:16:11,830
And this allowed
us to run value

429
00:16:11,830 --> 00:16:13,770
iteration directly
on this tree.

430
00:16:14,795 --> 00:16:16,175
And this is quite convenient

431
00:16:16,235 --> 00:16:17,995
because it aligns
in the direction

432
00:16:17,995 --> 00:16:19,215
of implicit planners.

433
00:16:19,995 --> 00:16:21,595
That is a very
neat direction.

434
00:16:21,595 --> 00:16:23,500
I I recommend you
read more about,

435
00:16:24,300 --> 00:16:25,840
if you're if this sounds,

436
00:16:26,620 --> 00:16:28,160
like something that would be.

437
00:16:29,180 --> 00:16:35,585
However, doing this running

438
00:16:35,585 --> 00:16:37,925
value iteration
directly on this tree,

439
00:16:39,120 --> 00:16:40,740
presents us with
the algorithmic

440
00:16:40,800 --> 00:16:42,960
bottleneck. So real world data

441
00:16:42,960 --> 00:16:44,580
is often incredibly rich,

442
00:16:45,040 --> 00:16:47,040
and we still have
to in the previous

443
00:16:47,040 --> 00:16:48,265
case, we still had to compress

444
00:16:50,425 --> 00:16:50,825
it to scalar values.

445
00:16:51,145 --> 00:16:54,125
So the the value
iteration solver

446
00:16:54,505 --> 00:16:55,965
committed to using the scalar

447
00:16:56,025 --> 00:16:58,200
the model predicted
and assumed

448
00:16:58,200 --> 00:16:59,020
it was perfect.

449
00:16:59,560 --> 00:17:01,100
And if there is insufficient

450
00:17:01,160 --> 00:17:02,840
data to estimate
these scalars,

451
00:17:02,840 --> 00:17:04,280
then the algorithm is running

452
00:17:04,280 --> 00:17:06,060
on incorrect inputs.

453
00:17:08,115 --> 00:17:09,795
So incorrect outputs will very

454
00:17:09,795 --> 00:17:10,935
likely go out.

455
00:17:11,875 --> 00:17:13,315
So this means that we need to

456
00:17:13,315 --> 00:17:14,995
have correct inputs
for the value

457
00:17:14,995 --> 00:17:16,900
iteration to do what we want,

458
00:17:16,900 --> 00:17:18,280
and we hit data efficiency

459
00:17:18,420 --> 00:17:19,320
problems again,

460
00:17:19,700 --> 00:17:21,140
which is precisely
what planning

461
00:17:21,140 --> 00:17:22,280
was supposed to solve.

462
00:17:22,820 --> 00:17:25,275
So trying to avoid
this bottleneck

463
00:17:25,335 --> 00:17:27,415
of the algorithm
gives a perfect

464
00:17:27,415 --> 00:17:28,875
solution but in a suboptimal

465
00:17:29,015 --> 00:17:30,615
environment, we propose our

466
00:17:30,615 --> 00:17:31,435
agent exfiltrim,

467
00:17:31,575 --> 00:17:33,940
which is aimed at
breaking the bottleneck

468
00:17:34,800 --> 00:17:36,340
. And, the main,

469
00:17:36,800 --> 00:17:38,720
idea behind it is that neural

470
00:17:38,720 --> 00:17:40,580
networks derive
great flexibility

471
00:17:40,800 --> 00:17:41,940
from their late
representations.

472
00:17:42,945 --> 00:17:44,885
They are inherently
high dimensional,

473
00:17:46,145 --> 00:17:48,625
which means that
if any part of

474
00:17:48,625 --> 00:17:50,165
that of that high dimensional

475
00:17:50,225 --> 00:17:52,070
vector is predicted poorly,

476
00:17:52,530 --> 00:17:54,210
then the rest of
the vector can

477
00:17:54,210 --> 00:17:56,150
be can be used
to to compensate

478
00:17:56,850 --> 00:17:59,110
and still lead us to
a correct answer.

479
00:18:00,465 --> 00:18:01,845
So to break the bottleneck,

480
00:18:01,985 --> 00:18:04,725
we replace the value
iteration solver,

481
00:18:05,265 --> 00:18:07,185
like, by we we train the value

482
00:18:07,185 --> 00:18:09,125
iteration directly
on the scalars

483
00:18:09,410 --> 00:18:10,630
with the neural network.

484
00:18:10,850 --> 00:18:12,450
So that combination I was,

485
00:18:12,450 --> 00:18:14,070
I was mentioning earlier on.

486
00:18:14,690 --> 00:18:16,370
So what we'll do is we'll have

487
00:18:16,370 --> 00:18:17,890
a neural network
between natural

488
00:18:17,890 --> 00:18:19,325
inputs and abstract inputs in

489
00:18:19,325 --> 00:18:20,925
that encoder, and we'll also

490
00:18:20,925 --> 00:18:22,125
have a neural network between

491
00:18:22,125 --> 00:18:23,565
our abstract inputs
and abstract

492
00:18:23,565 --> 00:18:26,125
output instead of
having the value

493
00:18:26,125 --> 00:18:29,750
iteration algorithm.
How do we do that?

494
00:18:29,750 --> 00:18:31,750
We do it by
pretraining a graph

495
00:18:31,750 --> 00:18:33,510
neural network
to perform value

496
00:18:33,510 --> 00:18:34,650
iteration style computations,

497
00:18:36,235 --> 00:18:38,015
on synthetic graphs.

498
00:18:38,075 --> 00:18:40,415
So something we can
easily generate.

499
00:18:41,115 --> 00:18:42,395
And then we freeze this.

500
00:18:42,395 --> 00:18:43,835
We keep this as a trained

501
00:18:43,835 --> 00:18:46,070
reasoning component and deploy

502
00:18:46,070 --> 00:18:47,290
it within our planner.

503
00:18:48,390 --> 00:18:51,110
And you might
remember as value

504
00:18:51,110 --> 00:18:52,730
iteration is
a dynamic programming

505
00:18:52,870 --> 00:18:55,295
algorithm, this is
quite easy to do,

506
00:18:55,615 --> 00:18:56,835
thanks to this algorithmic

507
00:18:56,895 --> 00:18:58,015
alignment that,

508
00:18:58,335 --> 00:19:01,855
was pointed in in the in the I

509
00:19:01,855 --> 00:19:03,075
clear twenty paper.

510
00:19:04,590 --> 00:19:06,210
So putting all together,

511
00:19:06,430 --> 00:19:08,910
our Excel agent
looks like this.

512
00:19:08,910 --> 00:19:10,450
We have the the state,

513
00:19:10,510 --> 00:19:11,730
our neural network,

514
00:19:12,465 --> 00:19:14,305
encoder taking to a latent

515
00:19:14,305 --> 00:19:16,565
representation, our transition

516
00:19:16,625 --> 00:19:19,665
model that is used
to build that

517
00:19:19,665 --> 00:19:22,400
local MDP that in the case of

518
00:19:22,400 --> 00:19:24,320
value iteration networks
was assumed no,

519
00:19:24,320 --> 00:19:25,620
but now we don't have,

520
00:19:27,760 --> 00:19:30,275
as as we won't
have have in most

521
00:19:30,275 --> 00:19:31,795
of the reinforcement learning

522
00:19:31,795 --> 00:19:33,255
environments we're
looking at.

523
00:19:33,795 --> 00:19:35,815
Then after we
build this tree,

524
00:19:36,115 --> 00:19:38,215
we use our pretrained
executor,

525
00:19:39,070 --> 00:19:41,170
that we pre trained
on synthetic graphs.

526
00:19:41,310 --> 00:19:44,210
And we use this
to predict values

527
00:19:44,270 --> 00:19:46,350
and actions and plug this into

528
00:19:46,350 --> 00:19:47,810
your reinforcement learning

529
00:19:48,155 --> 00:19:49,835
algorithm of choice,
in our case,

530
00:19:49,835 --> 00:19:53,355
BPO. So to look
a bit on the on

531
00:19:53,355 --> 00:19:54,575
the empirical side,

532
00:19:55,755 --> 00:19:57,820
our our agent is in green.

533
00:19:58,780 --> 00:20:00,480
We compare it with HCC,

534
00:20:00,540 --> 00:20:03,340
which is the the the model I

535
00:20:03,340 --> 00:20:05,040
talked about earlier, which,

536
00:20:06,135 --> 00:20:07,755
actually runs value iteration

537
00:20:07,815 --> 00:20:09,915
in scalar space rather than,

538
00:20:10,455 --> 00:20:11,595
in latent space,

539
00:20:12,135 --> 00:20:14,610
as Excel VIN does with our pre

540
00:20:14,610 --> 00:20:15,510
trained executor.

541
00:20:15,970 --> 00:20:17,910
And we also compare
with a component

542
00:20:18,130 --> 00:20:22,210
that, is just model
free, doesn't have,

543
00:20:22,530 --> 00:20:23,750
any planning component.

544
00:20:24,135 --> 00:20:25,515
So we see that usually,

545
00:20:26,055 --> 00:20:27,595
in in a lot of the cases,

546
00:20:29,495 --> 00:20:31,735
the XAV and the ATC do better

547
00:20:31,735 --> 00:20:34,030
than the than
the PPO baseline.

548
00:20:35,130 --> 00:20:37,370
And something
else that is very

549
00:20:37,370 --> 00:20:39,150
interesting to notice
is the Excelfin

550
00:20:39,290 --> 00:20:40,805
does better than HCC,

551
00:20:41,025 --> 00:20:42,785
particularly in the first half

552
00:20:42,785 --> 00:20:43,685
of the training.

553
00:20:44,625 --> 00:20:47,125
So it does well in
low data cases,

554
00:20:47,185 --> 00:20:49,200
which is one of
the main things

555
00:20:49,200 --> 00:20:50,640
why we're looking
at culling in

556
00:20:50,640 --> 00:20:51,540
the first place.

557
00:20:51,920 --> 00:20:54,420
So this is quite
an encouraging result.

558
00:20:55,735 --> 00:20:57,115
To draw some conclusions,

559
00:20:57,255 --> 00:20:58,955
we we looked at we presented

560
00:20:59,175 --> 00:21:00,155
this this blueprint,

561
00:21:01,335 --> 00:21:02,935
that is applicable if we know

562
00:21:02,935 --> 00:21:04,935
a specific algorithm
will be of

563
00:21:04,935 --> 00:21:07,240
interest for
solving a natural,

564
00:21:07,240 --> 00:21:08,380
a real world task.

565
00:21:09,000 --> 00:21:10,620
So we,

566
00:21:10,760 --> 00:21:12,380
we see that real
world solutions

567
00:21:12,415 --> 00:21:14,275
can benefit from
combining classic

568
00:21:14,655 --> 00:21:16,515
algorithms with
neural networks,

569
00:21:16,655 --> 00:21:18,675
and this is one way
of going about it.

570
00:21:19,135 --> 00:21:21,940
Then we build on
the on the findings

571
00:21:21,940 --> 00:21:23,220
that graph neural networks are

572
00:21:23,220 --> 00:21:25,240
particularly well suited to

573
00:21:25,300 --> 00:21:26,840
imitate some algorithms,

574
00:21:28,855 --> 00:21:30,535
in particular
dynamic programming

575
00:21:30,535 --> 00:21:32,215
algorithms. And one example is

576
00:21:32,215 --> 00:21:33,655
backward forward and other is

577
00:21:33,655 --> 00:21:34,475
value iteration.

578
00:21:35,815 --> 00:21:37,495
Value iteration, which is,

579
00:21:37,815 --> 00:21:41,320
a very useful algorithm in

580
00:21:41,320 --> 00:21:42,600
reinforcement learning as it

581
00:21:42,600 --> 00:21:44,300
allows allows us to plan,

582
00:21:44,600 --> 00:21:49,315
and it can lead to
to perfect plans.

583
00:21:50,415 --> 00:21:53,015
And using this,

584
00:21:53,455 --> 00:21:55,730
this component that
learns the immediate

585
00:21:55,730 --> 00:21:57,170
value iteration in a,

586
00:21:57,170 --> 00:21:59,110
in a reinforcement
learning agent,

587
00:21:59,970 --> 00:22:01,810
led us to find that it can,

588
00:22:01,810 --> 00:22:03,350
it can have great benefits.

589
00:22:03,585 --> 00:22:05,345
For example, having
good performance

590
00:22:05,345 --> 00:22:07,045
in low data cases.

591
00:22:08,305 --> 00:22:09,365
Thank you for listening.

592
00:22:10,305 --> 00:22:12,770
Some of this, work was already

593
00:22:12,990 --> 00:22:16,210
presented in in some
some nice articles.

594
00:22:16,350 --> 00:22:18,510
So, do check them out if you

595
00:22:18,510 --> 00:22:20,495
would like to hear to hear see

596
00:22:20,495 --> 00:22:21,555
more about this.

597
00:22:22,415 --> 00:22:23,635
And, of course,

598
00:22:23,775 --> 00:22:25,855
these were presented in in

599
00:22:25,855 --> 00:22:26,835
research papers,

600
00:22:27,690 --> 00:22:29,290
neuroalgosmic
reasoning, again,

601
00:22:29,290 --> 00:22:31,050
neuroalgosmic reasoning
as an inclusive

602
00:22:31,050 --> 00:22:32,570
planners. I'll also link them

603
00:22:32,570 --> 00:22:34,010
here if you'd
like to read more

604
00:22:34,010 --> 00:22:34,750
about them.

605
00:22:35,655 --> 00:22:37,895
Last time, lastly,
but not not least,

606
00:22:37,895 --> 00:22:39,515
I'm happy to take questions.

607
00:22:39,895 --> 00:22:40,855
And in general,

608
00:22:40,855 --> 00:22:42,235
if you if you have thoughts,

609
00:22:42,295 --> 00:22:43,915
feel free to send
me an email.

610
00:22:44,667 --> 00:22:44,992
Thank you.


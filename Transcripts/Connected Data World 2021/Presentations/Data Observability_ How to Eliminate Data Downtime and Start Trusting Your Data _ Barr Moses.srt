1
00:00:03,200 --> 00:00:08,240
Hi, everyone.
Great to be here.

2
00:00:08,240 --> 00:00:09,540
My name is Bar Moses.

3
00:00:09,600 --> 00:00:11,335
I'm the CEO and cofounder of

4
00:00:11,335 --> 00:00:13,115
Monte Carlo,
the data reliability

5
00:00:13,255 --> 00:00:15,115
platform. And today,

6
00:00:15,175 --> 00:00:16,695
I am stoked to
have a chat with

7
00:00:16,695 --> 00:00:18,375
you all about how to eliminate

8
00:00:18,375 --> 00:00:20,135
data downtime and
start trusting

9
00:00:20,135 --> 00:00:21,470
your data. Hopefully,

10
00:00:21,470 --> 00:00:22,910
you all can see my screen,

11
00:00:23,230 --> 00:00:25,250
and we're gonna
get started here.

12
00:00:25,950 --> 00:00:27,230
So just a little
bit of background

13
00:00:27,230 --> 00:00:29,705
about myself. As I mentioned,

14
00:00:29,925 --> 00:00:31,205
CEO of Monte Carlo.

15
00:00:31,205 --> 00:00:32,505
Prior to Monte Carlo,

16
00:00:32,965 --> 00:00:34,825
I worked at a company
called Gainsight,

17
00:00:35,845 --> 00:00:37,690
worked mostly
with companies to

18
00:00:37,690 --> 00:00:39,230
help them become data driven,

19
00:00:39,850 --> 00:00:41,610
to actually make
use of their data,

20
00:00:41,850 --> 00:00:43,630
for various, purposes.

21
00:00:45,105 --> 00:00:47,905
I, am also in the process of

22
00:00:47,905 --> 00:00:49,585
writing the very first book on

23
00:00:49,585 --> 00:00:50,865
data quality in collaboration

24
00:00:50,865 --> 00:00:54,090
with O'Reilly. Super
excited about that.

25
00:00:54,710 --> 00:00:55,690
We just prereleased,

26
00:00:56,550 --> 00:00:58,490
so the very first chapter.

27
00:00:58,550 --> 00:01:00,225
So check that out
if you'd like.

28
00:01:00,625 --> 00:01:02,145
And then another
fun fact about

29
00:01:02,145 --> 00:01:03,985
me is that I'm a very big,

30
00:01:04,465 --> 00:01:06,245
fan of Bruce Willis movies.

31
00:01:07,320 --> 00:01:08,680
So you'll you'll find me,

32
00:01:09,240 --> 00:01:11,080
watching those in
my spare time,

33
00:01:11,400 --> 00:01:12,840
when I'm not
thinking about data

34
00:01:12,840 --> 00:01:15,160
downtime. So that's just

35
00:01:15,160 --> 00:01:16,540
introduction about myself.

36
00:01:16,895 --> 00:01:18,175
Again, stoked to
be here and to

37
00:01:18,175 --> 00:01:19,615
speak with you all about data

38
00:01:19,615 --> 00:01:20,995
downtime and data
observability.

39
00:01:22,575 --> 00:01:23,795
So let's get started.

40
00:01:25,170 --> 00:01:26,450
What is the problem that we're

41
00:01:26,450 --> 00:01:27,910
all here today to discuss?

42
00:01:28,370 --> 00:01:30,210
The problem is what we call

43
00:01:30,210 --> 00:01:32,450
the good pipeline's
bad data problem.

44
00:01:32,450 --> 00:01:34,070
And what does this
actually mean?

45
00:01:34,485 --> 00:01:36,405
Everyone on this call probably

46
00:01:36,405 --> 00:01:38,325
has some experience
working with,

47
00:01:38,645 --> 00:01:41,145
data lakes, data
warehouses, ETL,

48
00:01:41,365 --> 00:01:45,250
reverse ETL, BI
models, ML models.

49
00:01:45,470 --> 00:01:46,270
Whatever you'd like,

50
00:01:46,270 --> 00:01:47,490
we have all the acronyms.

51
00:01:47,950 --> 00:01:49,170
In short, everyone,

52
00:01:49,230 --> 00:01:50,510
typically most companies,

53
00:01:50,510 --> 00:01:52,675
have invested a lot in setting

54
00:01:52,735 --> 00:01:53,875
up world class,

55
00:01:54,335 --> 00:01:56,035
best in class
data infrastructure

56
00:01:56,095 --> 00:01:56,915
and data systems.

57
00:01:57,215 --> 00:01:58,815
And so we're all
sort of ingesting,

58
00:01:58,815 --> 00:02:00,990
processing,
transforming, modeling,

59
00:02:01,130 --> 00:02:02,910
making great use of the data.

60
00:02:03,530 --> 00:02:04,570
But here's the problem.

61
00:02:04,570 --> 00:02:06,490
We've invested so
much in having

62
00:02:06,490 --> 00:02:08,010
amazing pipelines and amazing

63
00:02:08,010 --> 00:02:08,990
data infrastructure.

64
00:02:09,595 --> 00:02:12,075
However, so often
the data that's

65
00:02:12,075 --> 00:02:13,775
actually powering
those systems

66
00:02:13,835 --> 00:02:14,975
is often wrong.

67
00:02:15,915 --> 00:02:18,360
Not sure if anyone
here, today,

68
00:02:18,420 --> 00:02:20,040
you know, the example
here is familiar.

69
00:02:20,100 --> 00:02:21,300
You know, you kinda wake up

70
00:02:21,300 --> 00:02:22,120
Monday morning,

71
00:02:22,500 --> 00:02:23,780
you come into the office or

72
00:02:23,780 --> 00:02:25,525
maybe you log into
your office,

73
00:02:26,085 --> 00:02:27,365
and you suddenly get sort of

74
00:02:27,365 --> 00:02:29,605
slammed with this,
you know, this,

75
00:02:29,605 --> 00:02:30,665
like, meteor,

76
00:02:32,005 --> 00:02:34,425
shower of pings
from Slack asking,

77
00:02:34,780 --> 00:02:36,320
what's wrong with my report?

78
00:02:36,540 --> 00:02:38,060
Or, hey. It looks
like the data

79
00:02:38,060 --> 00:02:39,580
here doesn't quite
look right.

80
00:02:39,580 --> 00:02:40,560
What am I missing?

81
00:02:41,580 --> 00:02:42,880
Or, you know, get pinged.

82
00:02:43,425 --> 00:02:45,425
What what type of,
what data what,

83
00:02:45,825 --> 00:02:47,025
table should I be using?

84
00:02:47,025 --> 00:02:48,225
What what is right for this

85
00:02:48,225 --> 00:02:49,685
question that I'm
trying to answer?

86
00:02:50,910 --> 00:02:52,590
And it's always at
the very last minute.

87
00:02:52,590 --> 00:02:53,390
It's always, like,

88
00:02:53,390 --> 00:02:54,930
four minutes
before a meeting.

89
00:02:55,070 --> 00:02:56,750
Or, you you know,
if you get lucky,

90
00:02:56,750 --> 00:02:58,190
it might be on
a Friday night,

91
00:02:58,670 --> 00:03:00,635
as well. In any case,

92
00:03:00,635 --> 00:03:02,635
this sort of
situation is really

93
00:03:02,635 --> 00:03:04,495
widespread across
the industry.

94
00:03:04,875 --> 00:03:06,235
There isn't anyone that isn't

95
00:03:06,235 --> 00:03:08,670
hit by this. For
me in particular,

96
00:03:08,670 --> 00:03:10,030
I experienced this when I was

97
00:03:10,030 --> 00:03:12,850
managing a data team,
at Gainsight,

98
00:03:13,630 --> 00:03:14,510
and we were, you know,

99
00:03:14,510 --> 00:03:15,925
sort of hit by lots
of questions.

100
00:03:16,005 --> 00:03:17,370
Know, I felt like, oh, man.

101
00:03:17,370 --> 00:03:18,240
We had, like, one
job to do right.

102
00:03:18,240 --> 00:03:18,403
It was get the data right.

103
00:03:18,430 --> 00:03:18,538
And we, you know,

104
00:03:18,538 --> 00:03:19,565
we weren't able to do that.

105
00:03:19,565 --> 00:03:21,465
It was really,
really hard to do.

106
00:03:25,860 --> 00:03:27,300
And I think there's
many reasons

107
00:03:27,300 --> 00:03:28,340
for that. Right?

108
00:03:29,460 --> 00:03:30,180
There's, you know,

109
00:03:30,180 --> 00:03:31,460
way way more data that we're

110
00:03:31,460 --> 00:03:32,180
managing today.

111
00:03:32,180 --> 00:03:33,320
There's way more
stakeholders,

112
00:03:34,695 --> 00:03:37,435
and and data is, a lot
more distributed,

113
00:03:38,055 --> 00:03:38,935
in different systems.

114
00:03:38,935 --> 00:03:40,215
And so let's talk a little bit

115
00:03:40,215 --> 00:03:41,575
about this problem and how it

116
00:03:41,575 --> 00:03:43,870
sort of emerged
emerges over time.

117
00:03:45,290 --> 00:03:47,070
We sort of call this the data

118
00:03:47,210 --> 00:03:48,810
data downtime.
So data downtime

119
00:03:48,810 --> 00:03:50,555
refers to periods of time when

120
00:03:50,555 --> 00:03:52,095
your data is wrong,
inaccurate,

121
00:03:52,315 --> 00:03:53,295
otherwise erroneous.

122
00:03:54,315 --> 00:03:55,435
And the interesting
thing about

123
00:03:55,435 --> 00:03:56,475
data downtime, again,

124
00:03:56,475 --> 00:03:57,915
something that
everyone here is

125
00:03:57,915 --> 00:03:58,815
likely experienced,

126
00:03:59,370 --> 00:04:00,890
is that the impact of data

127
00:04:00,890 --> 00:04:02,890
downtime actually is worse as

128
00:04:02,890 --> 00:04:04,350
you kind of progress across

129
00:04:04,810 --> 00:04:06,510
different stakeholders
in the organization

130
00:04:07,450 --> 00:04:09,015
. So if you think
about a couple

131
00:04:09,015 --> 00:04:10,535
of years ago,
maybe three, five,

132
00:04:10,535 --> 00:04:12,135
ten years ago, there weren't

133
00:04:12,135 --> 00:04:13,815
that many people
who were actually

134
00:04:13,815 --> 00:04:15,755
working with data in
the organization.

135
00:04:16,690 --> 00:04:19,190
And today, there's
data engineers,

136
00:04:19,250 --> 00:04:21,110
data analytics, data science.

137
00:04:21,410 --> 00:04:22,950
There might be ML engineers,

138
00:04:23,010 --> 00:04:25,395
software engineers,
definitely you know,

139
00:04:25,395 --> 00:04:27,075
teams that are working in in

140
00:04:27,075 --> 00:04:27,975
business functions.

141
00:04:28,115 --> 00:04:29,075
There's way, way,

142
00:04:29,075 --> 00:04:30,435
way more people
that are actually

143
00:04:30,435 --> 00:04:31,655
making use of the data.

144
00:04:32,090 --> 00:04:33,370
And so if you think about sort

145
00:04:33,370 --> 00:04:35,310
of the impact of
data being wrong,

146
00:04:35,930 --> 00:04:36,970
at the starting point,

147
00:04:36,970 --> 00:04:38,350
maybe when
the data engineering

148
00:04:38,410 --> 00:04:40,915
team actually
catches that issue,

149
00:04:41,055 --> 00:04:42,495
that is what you'd
call sort of

150
00:04:42,495 --> 00:04:44,655
under control. However,

151
00:04:44,655 --> 00:04:46,095
there might be a couple weeks

152
00:04:46,095 --> 00:04:48,190
later that an issue
goes unnoticed,

153
00:04:48,190 --> 00:04:49,950
and then that is discovered by

154
00:04:49,950 --> 00:04:51,390
the data analytics or the data

155
00:04:51,390 --> 00:04:52,990
science team, which might be

156
00:04:52,990 --> 00:04:54,430
frustrating that we as data

157
00:04:54,430 --> 00:04:56,485
engineers didn't catch
that issue first.

158
00:04:57,365 --> 00:04:59,045
Maybe, you know,
worse over time,

159
00:04:59,045 --> 00:05:00,645
that issue lingers or actually

160
00:05:00,645 --> 00:05:02,085
starts to have
an impact across

161
00:05:02,085 --> 00:05:03,980
the business.
Those can actually

162
00:05:03,980 --> 00:05:06,480
have material impact
on companies,

163
00:05:06,540 --> 00:05:08,640
on organizations,
on people. Right?

164
00:05:09,020 --> 00:05:10,720
And so thinking
about companies

165
00:05:10,780 --> 00:05:13,180
in media or in
retail or ecommerce

166
00:05:13,180 --> 00:05:14,925
companies who really sort of,

167
00:05:15,165 --> 00:05:16,765
are at material risk in terms

168
00:05:16,765 --> 00:05:18,285
of compliance if
the data is wrong,

169
00:05:18,285 --> 00:05:19,185
if you, you know,

170
00:05:19,325 --> 00:05:20,925
mistakenly get credit card

171
00:05:20,925 --> 00:05:21,805
information wrong.

172
00:05:21,805 --> 00:05:23,400
You might be overcharging

173
00:05:23,540 --> 00:05:25,400
customers or
undercharging customers.

174
00:05:25,460 --> 00:05:27,220
You might be
powering the wrong

175
00:05:27,220 --> 00:05:29,480
marketing campaign
with incorrect data.

176
00:05:30,305 --> 00:05:31,745
The list is long. Right?

177
00:05:31,745 --> 00:05:33,605
But the bottom
line is that data

178
00:05:33,665 --> 00:05:36,005
data downtime
impacts all of us.

179
00:05:36,545 --> 00:05:38,490
Its importance is rising in

180
00:05:38,730 --> 00:05:40,250
organizations
because the impact

181
00:05:40,250 --> 00:05:41,310
of data downtime,

182
00:05:42,170 --> 00:05:44,270
is is severe over time.

183
00:05:44,650 --> 00:05:45,450
And so, you know,

184
00:05:45,450 --> 00:05:46,925
I come to you today with a lot

185
00:05:46,925 --> 00:05:48,365
of bad news. I realize this is

186
00:05:48,365 --> 00:05:50,125
a little bit of
a depressing start,

187
00:05:50,125 --> 00:05:52,705
but I have some good
news for you all.

188
00:05:53,085 --> 00:05:54,625
And the good news
is, actually,

189
00:05:55,380 --> 00:05:56,660
in order to think about how do

190
00:05:56,660 --> 00:05:59,400
we build reliable
data products,

191
00:05:59,540 --> 00:06:01,560
it is helpful to look at,

192
00:06:02,020 --> 00:06:03,780
a corollary or
look at our friend

193
00:06:03,780 --> 00:06:05,125
software engineers
who who have

194
00:06:05,125 --> 00:06:07,225
been building
reliable products,

195
00:06:08,005 --> 00:06:09,525
for decades now. Right?

196
00:06:09,525 --> 00:06:11,045
So how do engineers actually

197
00:06:11,045 --> 00:06:12,760
approach building
reliable products?

198
00:06:12,760 --> 00:06:14,440
You know, what
you can see here

199
00:06:14,440 --> 00:06:16,540
is sort of, various categories

200
00:06:16,600 --> 00:06:17,800
and various tools that have

201
00:06:17,800 --> 00:06:19,580
built around each
of the categories

202
00:06:20,015 --> 00:06:22,015
that ultimately help data help

203
00:06:22,015 --> 00:06:23,695
engineering teams
build products

204
00:06:23,695 --> 00:06:26,995
that are reliable,
secure, and scalable.

205
00:06:27,780 --> 00:06:29,320
Now in data so far,

206
00:06:29,380 --> 00:06:30,980
it's kind of been
the Wild West.

207
00:06:30,980 --> 00:06:32,420
Right? Like, you get up,

208
00:06:32,420 --> 00:06:34,760
spin snow spin up, Snowflake,

209
00:06:34,820 --> 00:06:36,775
spin up Looker, and
you get started.

210
00:06:36,775 --> 00:06:38,315
Everyone has access
to everything.

211
00:06:39,495 --> 00:06:41,355
There's no test.
There's no monitors.

212
00:06:41,815 --> 00:06:42,855
You put things in the wild,

213
00:06:42,855 --> 00:06:44,135
and you hope that
they're okay.

214
00:06:44,135 --> 00:06:47,080
Right? In a lot of
those instances,

215
00:06:47,220 --> 00:06:49,060
data downtime rises and starts

216
00:06:49,060 --> 00:06:50,500
to become more prominent in

217
00:06:50,500 --> 00:06:52,835
organizations. So what can we

218
00:06:52,835 --> 00:06:54,275
actually learn
from our friends

219
00:06:54,275 --> 00:06:55,415
in software engineering?

220
00:06:56,035 --> 00:06:57,075
At a very high level,

221
00:06:57,075 --> 00:06:58,515
there's sort of three core

222
00:06:58,515 --> 00:07:01,060
categories here that,

223
00:07:01,380 --> 00:07:02,820
that emerge from this that we

224
00:07:02,820 --> 00:07:04,180
would like to
actually implement

225
00:07:04,180 --> 00:07:05,620
for data and to take as best

226
00:07:05,620 --> 00:07:06,840
practices as well.

227
00:07:07,645 --> 00:07:09,165
And these three categories at

228
00:07:09,165 --> 00:07:10,045
a very high level,

229
00:07:10,045 --> 00:07:11,505
the categories of discovering

230
00:07:11,725 --> 00:07:13,105
problems as they arise,

231
00:07:13,965 --> 00:07:16,800
resolving problems as
fast as possible,

232
00:07:16,800 --> 00:07:19,140
and then preventing
them to begin with.

233
00:07:19,200 --> 00:07:20,640
So, again, these
are all concepts

234
00:07:20,640 --> 00:07:21,680
that are taken from software

235
00:07:21,680 --> 00:07:22,640
engineering, but what do they

236
00:07:22,640 --> 00:07:24,820
look like when we
apply them to data?

237
00:07:25,715 --> 00:07:27,575
What does it mean to
actually discover,

238
00:07:28,355 --> 00:07:31,555
when an issue is
detected when an issue,

239
00:07:31,795 --> 00:07:33,175
sort of arises in data?

240
00:07:33,790 --> 00:07:35,410
You know, I'll
say most often,

241
00:07:35,550 --> 00:07:37,150
many data teams that we find

242
00:07:37,310 --> 00:07:38,430
that we work with,

243
00:07:38,430 --> 00:07:40,110
we find that they are the last

244
00:07:40,110 --> 00:07:43,515
to learn about issues
arising in data.

245
00:07:44,135 --> 00:07:45,675
So, you know, they
might sometimes

246
00:07:45,975 --> 00:07:47,915
hear about it from
their internal

247
00:07:48,055 --> 00:07:48,855
customers, say,

248
00:07:48,855 --> 00:07:51,450
the marketing team or
the product team,

249
00:07:52,230 --> 00:07:54,570
or support or customer
success team.

250
00:07:55,190 --> 00:07:56,710
Oftentimes, they also learn

251
00:07:56,710 --> 00:07:58,265
about this from
real customers,

252
00:07:58,345 --> 00:08:00,025
external customers,
if you will,

253
00:08:00,025 --> 00:08:01,485
not real external customers.

254
00:08:02,905 --> 00:08:04,025
And in those cases,

255
00:08:04,025 --> 00:08:07,165
they're caught blinded,
if you will,

256
00:08:08,130 --> 00:08:09,910
learning about
an issue from others.

257
00:08:10,210 --> 00:08:11,890
So how do we
actually turn this

258
00:08:11,890 --> 00:08:13,650
around and develop
the tools so

259
00:08:13,650 --> 00:08:15,275
that data teams are the first

260
00:08:15,275 --> 00:08:17,135
to know and the first
to discover

261
00:08:17,195 --> 00:08:18,335
about data issues.

262
00:08:19,115 --> 00:08:20,875
A lot of that goes
into actually

263
00:08:20,875 --> 00:08:22,895
setting up
monitoring, alerts,

264
00:08:23,035 --> 00:08:24,415
strong anomaly detection,

265
00:08:25,500 --> 00:08:26,540
and different things that that

266
00:08:26,540 --> 00:08:27,520
we'll touch on.

267
00:08:28,380 --> 00:08:29,740
Once you've
actually identified

268
00:08:29,740 --> 00:08:30,780
that there is a problem,

269
00:08:30,780 --> 00:08:32,220
how quickly does
it take you to

270
00:08:32,220 --> 00:08:34,615
resolve it? Many
data teams that

271
00:08:34,615 --> 00:08:35,895
we speak with, sometimes it

272
00:08:35,895 --> 00:08:37,575
takes them weeks
or even months

273
00:08:37,575 --> 00:08:38,795
to resolve an issue.

274
00:08:39,095 --> 00:08:41,255
What if you had an approach to

275
00:08:41,255 --> 00:08:44,730
actually resolving
data downtime issues,

276
00:08:45,110 --> 00:08:46,630
in a way that
will allow you to

277
00:08:46,630 --> 00:08:48,870
do it in minutes or in hours

278
00:08:48,870 --> 00:08:50,310
instead of weeks or months?

279
00:08:50,550 --> 00:08:51,670
And what does that look like?

280
00:08:51,670 --> 00:08:55,385
What are some of
the root cause

281
00:08:55,385 --> 00:08:57,145
analysis that you
need to do in

282
00:08:57,145 --> 00:08:58,045
order to identify,

283
00:08:58,665 --> 00:09:00,125
what exactly is the issue?

284
00:09:00,730 --> 00:09:02,810
And then finally,
prevention. Right?

285
00:09:02,810 --> 00:09:04,010
If we're doing this right,

286
00:09:04,010 --> 00:09:05,850
we can actually
reduce the number

287
00:09:05,850 --> 00:09:07,530
of incidents,
the number of data

288
00:09:07,530 --> 00:09:09,085
downtime incidents
to begin with.

289
00:09:09,325 --> 00:09:10,945
If we're actually
getting smarter

290
00:09:11,005 --> 00:09:12,685
over time, if we're learning,

291
00:09:12,685 --> 00:09:14,605
what are the, you
what are the main

292
00:09:14,605 --> 00:09:16,465
sources or the main pipelines

293
00:09:16,605 --> 00:09:17,745
that tend to break?

294
00:09:17,830 --> 00:09:19,110
What are the main issues that

295
00:09:19,110 --> 00:09:20,950
are causing data downtime that

296
00:09:20,950 --> 00:09:22,730
are sort of draining
a lot of our time?

297
00:09:22,870 --> 00:09:25,110
If we continue to
collect insight

298
00:09:25,110 --> 00:09:26,535
and information about this,

299
00:09:26,615 --> 00:09:28,455
we should ultimately
be able to

300
00:09:28,455 --> 00:09:30,295
prevent these issues
to begin with.

301
00:09:31,015 --> 00:09:32,695
So I very much
believe in actually

302
00:09:32,695 --> 00:09:34,775
adopting the sort
of three three

303
00:09:34,775 --> 00:09:37,140
step framework, that
we that, you know,

304
00:09:37,140 --> 00:09:38,340
is tried, tested,

305
00:09:38,340 --> 00:09:40,260
and proven in
software engineering

306
00:09:40,260 --> 00:09:42,280
and now applying it
to data engineering.

307
00:09:43,165 --> 00:09:44,525
So today, we don't
have time to

308
00:09:44,525 --> 00:09:46,845
double click into each
in each of these,

309
00:09:46,845 --> 00:09:48,125
but I will double click into

310
00:09:48,125 --> 00:09:49,805
discover and talk
about some of

311
00:09:49,805 --> 00:09:51,425
the methods that we've used,

312
00:09:52,400 --> 00:09:53,760
that we've identified as sort

313
00:09:53,760 --> 00:09:55,600
of best in class and that some

314
00:09:55,600 --> 00:09:56,740
of the best organizations,

315
00:09:56,960 --> 00:09:58,480
some of the strongest
data teams

316
00:09:58,480 --> 00:10:00,415
are actually adopting in order

317
00:10:00,415 --> 00:10:02,675
to improve the ability
to discover.

318
00:10:03,855 --> 00:10:05,695
Now, you know, one of
the questions is,

319
00:10:05,695 --> 00:10:06,895
how do we actually measure

320
00:10:06,895 --> 00:10:08,310
ourselves on these three?

321
00:10:08,310 --> 00:10:10,010
How do we know that
we've gotten better?

322
00:10:10,150 --> 00:10:11,350
And so we're seeing more and

323
00:10:11,350 --> 00:10:13,030
more data teams develop bet

324
00:10:13,110 --> 00:10:14,390
better methods of actually

325
00:10:14,390 --> 00:10:15,885
measuring themselves
on these.

326
00:10:15,885 --> 00:10:17,485
To be honest, most data teams

327
00:10:17,485 --> 00:10:18,925
don't measure
themselves today,

328
00:10:18,925 --> 00:10:20,685
but, actually,
just starting to

329
00:10:20,685 --> 00:10:22,465
measure is a great
step forward.

330
00:10:23,610 --> 00:10:26,010
So on Discover, folks
actually look at,

331
00:10:27,130 --> 00:10:28,650
time to resolution. Sorry.

332
00:10:28,650 --> 00:10:29,630
It's time to detection.

333
00:10:29,850 --> 00:10:32,075
So how quickly I'm
thinking ahead here.

334
00:10:32,635 --> 00:10:33,695
So how quickly,

335
00:10:35,035 --> 00:10:37,595
is there actually
what is the time

336
00:10:37,595 --> 00:10:39,515
lapse between
when the incident

337
00:10:39,515 --> 00:10:40,715
actually happened when we and

338
00:10:40,715 --> 00:10:41,850
when we detected it?

339
00:10:42,890 --> 00:10:44,430
That's sort of
the first metric.

340
00:10:44,970 --> 00:10:47,130
The second metric is
around resolution.

341
00:10:47,130 --> 00:10:49,150
And so once we have
detected an issue,

342
00:10:49,210 --> 00:10:51,055
how quickly until
we resolved it?

343
00:10:51,135 --> 00:10:51,975
And obviously, you know,

344
00:10:51,975 --> 00:10:54,035
you sort of expect
that, you know,

345
00:10:54,255 --> 00:10:55,475
incidents will happen,

346
00:10:55,775 --> 00:10:56,895
but that over time,

347
00:10:56,895 --> 00:10:58,255
we are improving in both of

348
00:10:58,255 --> 00:11:00,070
those metrics.
And then the third

349
00:11:00,070 --> 00:11:01,190
metric is prevention.

350
00:11:01,190 --> 00:11:02,870
Are we able to
reduce the number

351
00:11:02,870 --> 00:11:03,910
of incidents overall?

352
00:11:03,910 --> 00:11:05,290
So actually
starting to measure

353
00:11:05,350 --> 00:11:06,950
how many p one, p two,

354
00:11:06,950 --> 00:11:08,550
p three incidents do we have?

355
00:11:08,550 --> 00:11:09,015
What is,

356
00:11:09,895 --> 00:11:11,975
what is the the time to detect

357
00:11:11,975 --> 00:11:13,755
and time to resolution
per issue,

358
00:11:14,135 --> 00:11:16,155
and are we able to
improve over time?

359
00:11:16,460 --> 00:11:17,500
So that's just to
give you a little

360
00:11:17,500 --> 00:11:18,540
bit of sense of how you can

361
00:11:18,540 --> 00:11:20,160
measure yourself
as an organization

362
00:11:20,620 --> 00:11:21,500
to improve this.

363
00:11:21,500 --> 00:11:23,420
Now let's double click into

364
00:11:23,420 --> 00:11:25,100
the discover part here,

365
00:11:25,100 --> 00:11:26,080
the first portion,

366
00:11:26,385 --> 00:11:27,905
and talk a little
bit about what

367
00:11:27,905 --> 00:11:30,565
are the methods that
teams are using to,

368
00:11:31,025 --> 00:11:32,705
really operationalize that as

369
00:11:32,705 --> 00:11:33,685
part of improving,

370
00:11:34,980 --> 00:11:36,260
their data operations and

371
00:11:36,260 --> 00:11:37,640
minimizing data downtime.

372
00:11:38,900 --> 00:11:40,660
So continuing to
borrow a little

373
00:11:40,660 --> 00:11:42,020
bit some concepts
from software

374
00:11:42,020 --> 00:11:43,165
engineering, there's a concept

375
00:11:43,165 --> 00:11:44,845
called observability
in software

376
00:11:44,845 --> 00:11:46,125
engineering,
which is yet again

377
00:11:46,125 --> 00:11:47,665
a very well
understood concept,

378
00:11:49,085 --> 00:11:49,805
which, you know,

379
00:11:50,605 --> 00:11:51,930
if you check out this quote,

380
00:11:51,930 --> 00:11:53,050
also has a lot to do with,

381
00:11:53,370 --> 00:11:55,070
with monitoring as well.

382
00:11:55,290 --> 00:11:56,410
And there's a lot that's been

383
00:11:56,410 --> 00:11:57,370
written about the difference

384
00:11:57,370 --> 00:11:59,070
between observability
and monitoring.

385
00:11:59,925 --> 00:12:00,805
But in software engineering,

386
00:12:00,805 --> 00:12:02,245
it's sort of like a no brainer

387
00:12:02,245 --> 00:12:03,525
to have something
like this. Right?

388
00:12:03,525 --> 00:12:05,065
And so the most
common things,

389
00:12:05,285 --> 00:12:06,085
you know, talked about,

390
00:12:06,085 --> 00:12:08,105
like metrics and
traces and logs.

391
00:12:08,280 --> 00:12:09,240
And there's sort of a lot of

392
00:12:09,240 --> 00:12:10,600
kind of solutions that enable

393
00:12:10,600 --> 00:12:12,040
software engineers to do their

394
00:12:12,040 --> 00:12:14,060
job in making sure
that applications

395
00:12:14,120 --> 00:12:15,500
are, reliable.

396
00:12:15,560 --> 00:12:17,785
So solutions like
PagerDuty and

397
00:12:17,785 --> 00:12:20,025
Splunk and New
Relic and Datadog

398
00:12:20,025 --> 00:12:21,625
are all solutions that we are

399
00:12:21,625 --> 00:12:23,145
very accustomed to work with.

400
00:12:23,305 --> 00:12:24,505
And in software engineering,

401
00:12:24,505 --> 00:12:25,650
they make a lot of sense.

402
00:12:26,050 --> 00:12:27,170
And so the question is,

403
00:12:27,170 --> 00:12:28,290
in the data space,

404
00:12:28,290 --> 00:12:29,830
why are we flying blind?

405
00:12:30,450 --> 00:12:31,890
Why don't we have
something like

406
00:12:31,890 --> 00:12:33,410
this that will allow us data

407
00:12:33,410 --> 00:12:35,170
engineers to
actually do our job

408
00:12:35,170 --> 00:12:37,205
properly? And so imagine that

409
00:12:37,205 --> 00:12:38,565
you're actually
taking the concept

410
00:12:38,565 --> 00:12:40,725
of observability
and now applying

411
00:12:40,725 --> 00:12:42,680
that to data. What
does that look like?

412
00:12:43,160 --> 00:12:44,760
So let's actually
define the term

413
00:12:44,760 --> 00:12:46,200
data observability here so

414
00:12:46,200 --> 00:12:47,740
everyone is on the same page.

415
00:12:48,600 --> 00:12:50,380
Data observability
is an organization's

416
00:12:50,680 --> 00:12:52,605
ability to
understand the state

417
00:12:52,685 --> 00:12:54,205
and health of
the data in their

418
00:12:54,205 --> 00:12:56,205
system with the objective of

419
00:12:56,205 --> 00:12:57,585
mitigating data downtime.

420
00:12:58,365 --> 00:13:00,045
Again, the the measure
of success

421
00:13:00,045 --> 00:13:01,565
here is if we are
able to prevent

422
00:13:01,565 --> 00:13:02,740
data downtime to begin with.

423
00:13:02,740 --> 00:13:04,420
We probably won't
reach a hundred

424
00:13:04,420 --> 00:13:06,280
percent. We will
not be perfect.

425
00:13:06,420 --> 00:13:08,340
But if we can
actually minimize

426
00:13:08,340 --> 00:13:09,300
it and reduce this,

427
00:13:09,300 --> 00:13:10,900
we will all be able to spend

428
00:13:10,900 --> 00:13:12,875
time elsewhere
on other revenue

429
00:13:13,495 --> 00:13:14,315
generating projects,

430
00:13:15,735 --> 00:13:16,775
or other things
that, you know,

431
00:13:16,775 --> 00:13:18,715
we are curious and
excited about.

432
00:13:20,270 --> 00:13:21,490
And so data observability,

433
00:13:22,590 --> 00:13:23,790
barring again from the concept

434
00:13:23,790 --> 00:13:25,230
of observability from software

435
00:13:25,230 --> 00:13:27,070
engineering,
actually allows us

436
00:13:27,070 --> 00:13:27,810
to understand,

437
00:13:28,030 --> 00:13:31,245
to discover data
downtime issues,

438
00:13:31,705 --> 00:13:33,945
ultimately increasing
trust in the data.

439
00:13:33,945 --> 00:13:35,785
So continuing
down this path of

440
00:13:35,785 --> 00:13:36,605
data observability,

441
00:13:37,060 --> 00:13:38,200
what does data observability

442
00:13:38,260 --> 00:13:39,540
actually mean? So in software

443
00:13:39,540 --> 00:13:42,180
engineering, it's super well

444
00:13:42,180 --> 00:13:43,720
understood and used.

445
00:13:44,155 --> 00:13:45,455
In in data observability,

446
00:13:45,835 --> 00:13:47,675
it's a new term. Right?

447
00:13:48,235 --> 00:13:50,075
And so what we did at Monte

448
00:13:50,075 --> 00:13:52,155
Carlo is actually we spoke to

449
00:13:52,155 --> 00:13:53,455
hundreds of data organizations

450
00:13:53,850 --> 00:13:55,690
ranging from small startups to

451
00:13:55,690 --> 00:13:57,770
large organizations
like Netflix

452
00:13:57,770 --> 00:14:01,025
and Facebook and
Uber and, actually,

453
00:14:01,025 --> 00:14:02,465
sort of created a sort of or

454
00:14:02,465 --> 00:14:05,025
collated really big dataset of

455
00:14:05,025 --> 00:14:06,785
what are all
the reasons for why

456
00:14:06,785 --> 00:14:09,320
data downtime happens to to

457
00:14:09,320 --> 00:14:10,600
organizations, what are all

458
00:14:10,600 --> 00:14:12,440
the symptoms that,

459
00:14:12,760 --> 00:14:15,000
folks see when data
downtime happens,

460
00:14:15,000 --> 00:14:16,280
and then all the reasons that

461
00:14:16,280 --> 00:14:17,785
folks or all the ways in which

462
00:14:17,785 --> 00:14:19,805
folks actually resolve
those issues.

463
00:14:21,065 --> 00:14:22,825
And so we actually
codified all

464
00:14:22,825 --> 00:14:24,265
of that good stuff
into what we

465
00:14:24,265 --> 00:14:25,785
call the five pillars of data

466
00:14:25,785 --> 00:14:27,970
observability. And
in our experience,

467
00:14:27,970 --> 00:14:29,490
we see that when you actually

468
00:14:29,490 --> 00:14:31,350
sort of put these
to work, when you,

469
00:14:31,890 --> 00:14:34,390
instrument, monitor,
analyze these,

470
00:14:35,065 --> 00:14:36,685
data teams are actually able,

471
00:14:37,385 --> 00:14:39,465
to to start this
sort of journey

472
00:14:39,465 --> 00:14:41,725
towards operationalizing
trust in data.

473
00:14:42,880 --> 00:14:44,640
And and having
this combination

474
00:14:44,640 --> 00:14:46,800
of these five
actually provides

475
00:14:46,800 --> 00:14:48,560
a very strong view
into the health

476
00:14:48,560 --> 00:14:49,300
of your data.

477
00:14:49,815 --> 00:14:51,435
And for the first time,

478
00:14:51,735 --> 00:14:53,495
data organizations
are actually

479
00:14:53,495 --> 00:14:54,055
able to see,

480
00:14:55,895 --> 00:14:57,015
to understand the health of

481
00:14:57,015 --> 00:14:58,940
their data and
understand where

482
00:14:58,940 --> 00:15:01,280
are the sort of vulnerability

483
00:15:01,500 --> 00:15:02,940
spots and what are the areas

484
00:15:02,940 --> 00:15:06,860
where some corrections need to

485
00:15:06,860 --> 00:15:07,600
be implemented.

486
00:15:08,215 --> 00:15:09,575
So let's double
click into each

487
00:15:09,575 --> 00:15:11,735
of these briefly to
give you a little

488
00:15:11,735 --> 00:15:13,015
bit of an example
of what these

489
00:15:13,015 --> 00:15:14,955
data observability
pillars mean.

490
00:15:15,820 --> 00:15:17,020
So starting with freshness,

491
00:15:17,020 --> 00:15:18,380
which is the first
one, which,

492
00:15:18,700 --> 00:15:20,380
freshness means
a lot of different

493
00:15:20,380 --> 00:15:21,580
things. This is a particular

494
00:15:21,580 --> 00:15:23,255
example of it. But really sort

495
00:15:23,255 --> 00:15:25,395
of it comes down
to the timeliness

496
00:15:25,535 --> 00:15:26,815
of the data. Right?

497
00:15:27,295 --> 00:15:28,655
So in this example,

498
00:15:28,655 --> 00:15:30,175
what you see here
is a specific

499
00:15:30,175 --> 00:15:31,970
table that, you know,

500
00:15:31,970 --> 00:15:33,490
the the lines here indicate

501
00:15:33,490 --> 00:15:34,950
the table getting updated,

502
00:15:35,730 --> 00:15:36,770
over sort of this,

503
00:15:37,330 --> 00:15:39,010
axis of time here from from

504
00:15:39,010 --> 00:15:40,390
November tenth onwards.

505
00:15:41,285 --> 00:15:42,645
And you can see that the table

506
00:15:42,645 --> 00:15:44,505
is getting
periodically updated

507
00:15:44,965 --> 00:15:46,005
once or twice a day,

508
00:15:46,005 --> 00:15:47,125
a couple of times a day.

509
00:15:47,125 --> 00:15:47,845
And then suddenly,

510
00:15:47,845 --> 00:15:49,125
there's a period of three or

511
00:15:49,125 --> 00:15:51,380
four days with no
updates at all.

512
00:15:52,080 --> 00:15:53,060
In this instance,

513
00:15:53,280 --> 00:15:56,240
this might indicate that there

514
00:15:56,240 --> 00:15:58,015
is a potential issue
with the data.

515
00:15:58,895 --> 00:15:59,615
And so actually,

516
00:15:59,615 --> 00:16:01,475
by using machine learning to

517
00:16:01,775 --> 00:16:03,135
observe the data over time,

518
00:16:03,135 --> 00:16:04,815
we're able to
identify these in

519
00:16:04,815 --> 00:16:05,955
an automatic way.

520
00:16:06,415 --> 00:16:08,010
And now, oftentimes,

521
00:16:08,230 --> 00:16:10,330
data teams find themselves

522
00:16:10,390 --> 00:16:12,230
manually specifying a lot of

523
00:16:12,230 --> 00:16:13,050
these thresholds.

524
00:16:13,510 --> 00:16:14,950
I'm happy to say with some

525
00:16:14,950 --> 00:16:16,845
advances around
automation machine

526
00:16:16,845 --> 00:16:18,525
learning, it is
actually possible

527
00:16:18,525 --> 00:16:20,685
to do this, not only
for a particular

528
00:16:20,685 --> 00:16:22,685
table, but rather for hundreds

529
00:16:22,685 --> 00:16:24,400
of thousands of
tables at scale.

530
00:16:24,400 --> 00:16:26,020
And so you can automatically

531
00:16:26,320 --> 00:16:29,140
sort of turn on
a slew of metrics,

532
00:16:29,600 --> 00:16:31,460
around sort of
the freshness of data,

533
00:16:31,520 --> 00:16:33,220
this being one
example of them.

534
00:16:35,205 --> 00:16:37,125
The second important pillar is

535
00:16:37,125 --> 00:16:38,425
the concept of volume.

536
00:16:39,205 --> 00:16:40,745
So pretty straightforward,

537
00:16:40,885 --> 00:16:41,765
as you can see here,

538
00:16:41,765 --> 00:16:44,790
an example where
you see a number

539
00:16:44,790 --> 00:16:46,310
of rows. And in
this particular

540
00:16:46,310 --> 00:16:47,770
incident, there's an unusual

541
00:16:47,830 --> 00:16:49,430
number of rows that
were removed.

542
00:16:50,070 --> 00:16:51,595
You can see there's
sort of a nice

543
00:16:51,755 --> 00:16:53,455
trend. So slowly increasing

544
00:16:53,995 --> 00:16:55,755
the number of rows
and row count.

545
00:16:55,755 --> 00:16:56,575
And then suddenly,

546
00:16:57,275 --> 00:16:58,575
on September thirtieth,

547
00:16:59,570 --> 00:17:01,090
there's a very high number of

548
00:17:01,090 --> 00:17:02,390
rows that have been removed.

549
00:17:02,930 --> 00:17:05,090
So this is an example
of one way

550
00:17:05,090 --> 00:17:06,150
to track volume.

551
00:17:07,515 --> 00:17:09,195
And, again, another sort of

552
00:17:09,195 --> 00:17:10,635
reason for why or another

553
00:17:10,635 --> 00:17:12,555
indication for data might be,

554
00:17:12,875 --> 00:17:14,015
that might be wrong.

555
00:17:15,620 --> 00:17:16,980
The third sort of
pillar of data

556
00:17:16,980 --> 00:17:18,500
observability is what
we call schema,

557
00:17:18,500 --> 00:17:20,920
and schema is often
the culprit of data,

558
00:17:21,940 --> 00:17:23,880
going wrong or going down.

559
00:17:24,395 --> 00:17:26,395
Oftentimes, schema or actually

560
00:17:26,475 --> 00:17:27,435
or schema changes,

561
00:17:27,435 --> 00:17:28,395
they happen quite a lot,

562
00:17:28,395 --> 00:17:30,175
but they're not
communicated about.

563
00:17:30,315 --> 00:17:31,755
So one team might
make a change,

564
00:17:31,755 --> 00:17:33,275
but then the other
team is unaware

565
00:17:33,275 --> 00:17:34,500
of that. And oftentimes,

566
00:17:34,560 --> 00:17:36,160
in that breaking point in

567
00:17:36,160 --> 00:17:38,160
communication is where sort of

568
00:17:38,160 --> 00:17:40,180
lies the data
downtime problem.

569
00:17:40,725 --> 00:17:42,645
And so what we see data teams

570
00:17:42,645 --> 00:17:44,325
do is actually
have an automated

571
00:17:44,325 --> 00:17:45,845
way of tracking
schema changes.

572
00:17:45,845 --> 00:17:47,065
And so in this example,

573
00:17:47,365 --> 00:17:48,645
you see there's
a bunch of fields

574
00:17:48,645 --> 00:17:49,925
that have been
completely deleted

575
00:17:49,925 --> 00:17:51,540
and removed. There's probably

576
00:17:51,540 --> 00:17:54,100
someone downstream
that has a report

577
00:17:54,100 --> 00:17:55,960
or other tables
or another model

578
00:17:56,100 --> 00:17:57,540
that actually relies on these

579
00:17:57,540 --> 00:17:59,415
fields and needs to
be notified of this.

580
00:18:00,215 --> 00:18:02,475
You might actually
have also a specific

581
00:18:02,535 --> 00:18:03,915
field change in type,

582
00:18:04,295 --> 00:18:05,675
which might impact
downstream.

583
00:18:06,970 --> 00:18:08,730
And so having an automated way

584
00:18:08,730 --> 00:18:10,650
to track these the changes in

585
00:18:10,650 --> 00:18:12,510
schema and a way
to communicate

586
00:18:12,730 --> 00:18:13,930
about them is a very,

587
00:18:13,930 --> 00:18:15,370
very important part of this

588
00:18:15,370 --> 00:18:16,190
fourth pillar.

589
00:18:17,505 --> 00:18:19,685
And then the fifth
pillar is is,

590
00:18:20,225 --> 00:18:21,585
or sorry. The fourth pillar is

591
00:18:21,585 --> 00:18:23,845
distribution, and distribution

592
00:18:24,385 --> 00:18:27,820
really has to do with metrics

593
00:18:27,820 --> 00:18:29,420
and health at
the field level.

594
00:18:29,980 --> 00:18:31,360
So as an example here,

595
00:18:31,420 --> 00:18:32,860
you can see there's a field

596
00:18:32,860 --> 00:18:35,245
called count pets
one five years old,

597
00:18:35,405 --> 00:18:37,585
and we're looking at
percentage null.

598
00:18:38,285 --> 00:18:40,765
And there's
a specific average,

599
00:18:40,765 --> 00:18:42,045
a seventeen day average,

600
00:18:42,205 --> 00:18:43,245
so a little less than three

601
00:18:43,245 --> 00:18:45,050
weeks average.
And then today,

602
00:18:45,110 --> 00:18:46,790
the percentage of
knowledge just spiked.

603
00:18:46,790 --> 00:18:49,510
It's way higher
than the average

604
00:18:49,510 --> 00:18:51,450
in the last, two
to three weeks.

605
00:18:51,715 --> 00:18:52,995
And so in this
instance, you know,

606
00:18:52,995 --> 00:18:54,615
this might be a field where,

607
00:18:55,635 --> 00:18:57,335
it's it's it is
quite bizarre,

608
00:18:58,115 --> 00:19:01,050
to have so many, so
many null values.

609
00:19:01,050 --> 00:19:02,510
And so this might actually,

610
00:19:03,850 --> 00:19:04,670
be an incident,

611
00:19:05,610 --> 00:19:07,025
that you'd wanna look into.

612
00:19:07,585 --> 00:19:09,505
And so this is
an example of a type

613
00:19:09,505 --> 00:19:14,040
of distribution
issue, if you will.

614
00:19:14,600 --> 00:19:16,360
And, again, there's
a whole you know,

615
00:19:16,360 --> 00:19:17,160
under distribution,

616
00:19:17,160 --> 00:19:19,020
you could look at null rates,

617
00:19:19,080 --> 00:19:19,960
negative rates.

618
00:19:19,960 --> 00:19:22,520
You could look at,
average, min,

619
00:19:22,520 --> 00:19:26,985
max, a whole slew of different

620
00:19:26,985 --> 00:19:28,205
metrics under distribution,

621
00:19:28,265 --> 00:19:29,805
everything at
the field level.

622
00:19:30,985 --> 00:19:34,290
And then the fifth
linea the fifth,

623
00:19:35,230 --> 00:19:37,490
pillar here is
the lineage pillar.

624
00:19:38,110 --> 00:19:39,330
It might be my favorite.

625
00:19:40,145 --> 00:19:41,585
And this pillar
actually allows

626
00:19:41,585 --> 00:19:43,365
us to bring the whole
story together.

627
00:19:43,905 --> 00:19:45,685
So what you can see here is,

628
00:19:46,065 --> 00:19:49,650
a table level lineage,
where you have,

629
00:19:50,450 --> 00:19:51,970
tables from a data
warehouse and

630
00:19:51,970 --> 00:19:54,070
then views downstream
in Looker.

631
00:19:54,850 --> 00:19:56,385
And there's
a particular incident

632
00:19:56,385 --> 00:19:57,985
that's been identified
in a particular

633
00:19:57,985 --> 00:20:01,205
table called recent metrics.

634
00:20:01,345 --> 00:20:02,865
And you can see all the tables

635
00:20:02,865 --> 00:20:05,330
downstream and the views
and explores,

636
00:20:05,790 --> 00:20:07,630
and dashboards downstream that

637
00:20:07,630 --> 00:20:08,910
have been impacted by this.

638
00:20:08,910 --> 00:20:10,430
Now the importance
of lineage,

639
00:20:10,430 --> 00:20:13,010
both at the table level
and field level,

640
00:20:13,245 --> 00:20:16,045
is that lineage by itself is

641
00:20:16,045 --> 00:20:17,745
quite useless, to be honest.

642
00:20:18,205 --> 00:20:19,885
So if you just have lineage,

643
00:20:19,885 --> 00:20:21,245
there's not that much that you

644
00:20:21,245 --> 00:20:22,850
can actually do with it,

645
00:20:24,050 --> 00:20:25,910
or it's mostly sort
of eye candy,

646
00:20:26,530 --> 00:20:27,990
for for most teams,

647
00:20:28,690 --> 00:20:30,370
where we do find lineage being

648
00:20:30,370 --> 00:20:32,550
helpful when it's
applied to a specific

649
00:20:32,745 --> 00:20:33,565
use case.

650
00:20:33,945 --> 00:20:35,785
And in this
particular use case,

651
00:20:35,785 --> 00:20:37,645
it's around data
observability.

652
00:20:38,505 --> 00:20:39,625
And so I think when you take

653
00:20:39,625 --> 00:20:41,145
lineage and you combine that

654
00:20:41,145 --> 00:20:42,700
with the sort of other pillars

655
00:20:42,700 --> 00:20:43,900
that we talked about today,

656
00:20:43,900 --> 00:20:45,660
that's really where
the magic lies.

657
00:20:46,060 --> 00:20:47,840
So, you know, let's
say, for example,

658
00:20:47,900 --> 00:20:49,340
there's a particular
table that

659
00:20:49,340 --> 00:20:50,640
has a freshness problem.

660
00:20:50,825 --> 00:20:55,245
So there's data that's loading

661
00:20:56,025 --> 00:20:59,670
once an hour at any given day

662
00:20:59,750 --> 00:21:01,430
and then data stopped loading

663
00:21:01,430 --> 00:21:03,590
that table. It
hasn't been loaded

664
00:21:03,590 --> 00:21:04,470
for three hours.

665
00:21:04,470 --> 00:21:05,910
And then downstream
from that,

666
00:21:05,910 --> 00:21:08,215
there's another
table that might

667
00:21:08,215 --> 00:21:09,735
actually, as
a result of that,

668
00:21:09,735 --> 00:21:11,595
have a problem has
a distribution

669
00:21:11,735 --> 00:21:14,775
problem. And as
a result of that,

670
00:21:14,775 --> 00:21:15,995
there might be a dashboard

671
00:21:16,055 --> 00:21:18,100
downstream that might have

672
00:21:18,100 --> 00:21:19,400
incorrect data now.

673
00:21:19,780 --> 00:21:21,860
And so lineage helps us piece

674
00:21:21,860 --> 00:21:23,220
all of that together and help

675
00:21:23,220 --> 00:21:24,580
us make sense of, Okay,

676
00:21:24,580 --> 00:21:26,040
there's a problem somewhere,

677
00:21:26,405 --> 00:21:28,245
but should I care
about that problem?

678
00:21:28,245 --> 00:21:29,465
Maybe there are
no dependencies.

679
00:21:29,765 --> 00:21:30,965
Nobody's using this table,

680
00:21:30,965 --> 00:21:32,505
so nobody cares about it.

681
00:21:32,565 --> 00:21:33,525
So maybe, you know,

682
00:21:33,525 --> 00:21:35,045
we don't care about
that specific

683
00:21:35,045 --> 00:21:36,550
problem. However,

684
00:21:36,690 --> 00:21:38,550
maybe there is
a specific incident

685
00:21:39,090 --> 00:21:41,190
with hundreds of
tables downstream,

686
00:21:41,570 --> 00:21:44,935
key reports that
your board and

687
00:21:44,935 --> 00:21:46,635
execs and customers
are using,

688
00:21:46,775 --> 00:21:47,495
in that instance,

689
00:21:47,495 --> 00:21:50,530
you probably want to give that

690
00:21:50,530 --> 00:21:52,630
incident a higher
degree of attention,

691
00:21:52,690 --> 00:21:53,910
a higher degree of severity.

692
00:21:53,970 --> 00:21:55,990
And so lineage is incredibly

693
00:21:56,130 --> 00:21:57,490
powerful in helping us sort of

694
00:21:57,490 --> 00:21:59,625
bring this together
and help us

695
00:21:59,625 --> 00:22:01,265
understand both
on the one hand

696
00:22:01,265 --> 00:22:02,325
impact assessment.

697
00:22:02,465 --> 00:22:03,585
Should I care about this?

698
00:22:03,585 --> 00:22:04,965
Who cares about this?

699
00:22:05,025 --> 00:22:06,065
And then on the other hand,

700
00:22:06,065 --> 00:22:07,505
it helps us understand root

701
00:22:07,505 --> 00:22:08,720
cause analysis. Right?

702
00:22:08,720 --> 00:22:09,860
So if there's a particular

703
00:22:09,920 --> 00:22:10,820
incident somewhere,

704
00:22:11,280 --> 00:22:12,960
what are the upstream sources

705
00:22:12,960 --> 00:22:15,520
of that we can
learn from around

706
00:22:15,520 --> 00:22:17,700
what might have gone
wrong and where?

707
00:22:18,485 --> 00:22:20,085
So being able to answer all of

708
00:22:20,085 --> 00:22:23,045
these questions is really

709
00:22:23,045 --> 00:22:24,725
fundamental to our ability to

710
00:22:24,725 --> 00:22:26,085
restore trust in data,

711
00:22:26,085 --> 00:22:27,910
or to have more
trust in data,

712
00:22:28,070 --> 00:22:29,190
if you will.

713
00:22:29,430 --> 00:22:30,950
And so finding or sort of

714
00:22:30,950 --> 00:22:32,890
developing ways to automate

715
00:22:33,590 --> 00:22:35,270
the instrumentation
and the monitoring

716
00:22:35,270 --> 00:22:36,845
of these and bringing them

717
00:22:36,845 --> 00:22:38,845
together in one view is really

718
00:22:38,845 --> 00:22:42,525
what helps us in
building towards

719
00:22:42,525 --> 00:22:44,125
this new paradigm,
if you will,

720
00:22:44,125 --> 00:22:46,660
this new data
reliability stack,

721
00:22:47,200 --> 00:22:49,760
which includes
sort of the three

722
00:22:49,760 --> 00:22:51,220
steps that we talked about.

723
00:22:53,485 --> 00:22:54,925
And so when you
think about that

724
00:22:54,925 --> 00:22:56,785
first step,
the discover step,

725
00:22:57,565 --> 00:22:59,405
going back to kind
of the initial

726
00:22:59,405 --> 00:23:00,225
prompt here,

727
00:23:00,800 --> 00:23:03,680
most of our reality
today is a reality

728
00:23:03,680 --> 00:23:06,720
where we created some tests to

729
00:23:06,720 --> 00:23:08,320
test the things
that we know can

730
00:23:08,320 --> 00:23:09,700
go wrong with our data,

731
00:23:09,985 --> 00:23:11,765
and that's a very
important part

732
00:23:12,145 --> 00:23:13,985
of our job. And then eighty

733
00:23:13,985 --> 00:23:15,825
percent of our life is really

734
00:23:15,825 --> 00:23:18,140
kind of getting
angry Slacks or

735
00:23:18,140 --> 00:23:20,220
emails from colleagues
that are really,

736
00:23:20,220 --> 00:23:21,580
really unhappy with some of

737
00:23:21,580 --> 00:23:24,300
the data going
wrong or reports

738
00:23:24,300 --> 00:23:27,200
getting messy or,
model drift.

739
00:23:27,795 --> 00:23:28,835
There's all these things that

740
00:23:28,835 --> 00:23:30,375
people can get
really angry at,

741
00:23:30,915 --> 00:23:32,295
and then the finger pointing,

742
00:23:33,555 --> 00:23:34,535
game starts.

743
00:23:35,280 --> 00:23:37,280
You you know,
who actually owns

744
00:23:37,280 --> 00:23:39,040
this table and
whose fault it is.

745
00:23:39,040 --> 00:23:41,120
Right? That's the reality that

746
00:23:41,120 --> 00:23:42,180
we all live in.

747
00:23:42,985 --> 00:23:44,345
However, I think
there could be

748
00:23:44,345 --> 00:23:46,745
a better way, and
the better way

749
00:23:46,745 --> 00:23:48,045
has to do with observability.

750
00:23:48,985 --> 00:23:51,165
With observability, you know,

751
00:23:51,600 --> 00:23:53,680
you still have
tests that we've

752
00:23:53,680 --> 00:23:55,060
created ahead of time.

753
00:23:55,600 --> 00:23:58,900
However, there's
broad automated

754
00:23:58,960 --> 00:24:00,660
coverage that we can achieve,

755
00:24:01,265 --> 00:24:03,585
with observability for eighty

756
00:24:03,585 --> 00:24:05,605
percent of the incidents.

757
00:24:06,705 --> 00:24:09,365
So we start out
with a good base

758
00:24:10,940 --> 00:24:12,300
of issues that are detected in

759
00:24:12,300 --> 00:24:13,420
a way that we don't need to

760
00:24:13,420 --> 00:24:14,560
specify manually,

761
00:24:14,700 --> 00:24:16,060
but rather we can have this

762
00:24:16,060 --> 00:24:17,440
broad coverage for.

763
00:24:17,865 --> 00:24:19,145
Of course, we will always need

764
00:24:19,145 --> 00:24:20,265
to have tests. There's always

765
00:24:20,265 --> 00:24:22,425
going to be things
that, you know,

766
00:24:22,425 --> 00:24:24,105
us as sort of folks closest to

767
00:24:24,105 --> 00:24:25,805
the data would know best.

768
00:24:26,150 --> 00:24:27,830
And it's very hard
for any machine

769
00:24:27,830 --> 00:24:29,270
to actually learn
or for anyone

770
00:24:29,270 --> 00:24:30,950
to do for us. And those will

771
00:24:30,950 --> 00:24:31,770
always continue.

772
00:24:31,990 --> 00:24:33,210
But with observability,

773
00:24:33,350 --> 00:24:35,305
you can rely on sort of broad

774
00:24:35,305 --> 00:24:36,905
base of coverage to help make

775
00:24:36,905 --> 00:24:38,345
sure that you're
sort of starting

776
00:24:38,345 --> 00:24:40,445
from a, from a good place.

777
00:24:40,665 --> 00:24:42,025
And then I wish I could say we

778
00:24:42,025 --> 00:24:43,640
could eliminate the angry text

779
00:24:43,880 --> 00:24:46,540
completely, the angry
Slack messages,

780
00:24:46,600 --> 00:24:47,880
but, you know, I do think that

781
00:24:47,880 --> 00:24:49,240
there's probably a one percent

782
00:24:49,240 --> 00:24:50,760
that will always
remain with us.

783
00:24:50,760 --> 00:24:52,360
We we can try to minimize as

784
00:24:52,360 --> 00:24:53,795
much as as possible and maybe

785
00:24:53,795 --> 00:24:55,095
even laugh about it.

786
00:24:55,395 --> 00:24:57,175
But that's sort of,
with observability,

787
00:24:57,875 --> 00:25:00,295
the benefits that
data teams see.

788
00:25:02,300 --> 00:25:04,160
And so going back to kind of

789
00:25:04,540 --> 00:25:05,840
the three core components,

790
00:25:06,460 --> 00:25:08,400
we talked a lot about Discover

791
00:25:08,460 --> 00:25:10,235
and sort of what
that looks like.

792
00:25:10,315 --> 00:25:11,935
We talked a little
bit about Resolve.

793
00:25:12,635 --> 00:25:15,195
The five pillars of data

794
00:25:15,195 --> 00:25:17,275
observability fit nicely into

795
00:25:17,275 --> 00:25:20,450
both of these and really help

796
00:25:22,430 --> 00:25:24,110
us have a starting point for

797
00:25:24,110 --> 00:25:25,630
the data that we
need to do our

798
00:25:25,630 --> 00:25:27,070
job well and to actually sort

799
00:25:27,070 --> 00:25:29,455
of generate results here to

800
00:25:29,455 --> 00:25:30,755
reduce time to detection,

801
00:25:30,895 --> 00:25:31,875
time to resolution.

802
00:25:32,095 --> 00:25:32,995
And then ultimately,

803
00:25:33,375 --> 00:25:34,915
we'll talk more about this

804
00:25:36,095 --> 00:25:38,120
potentially in
a future talk, But,

805
00:25:38,360 --> 00:25:39,720
there's a lot of work more for

806
00:25:39,720 --> 00:25:41,180
us to do on sort
of prevention,

807
00:25:41,800 --> 00:25:43,260
as an industry overall.

808
00:25:43,800 --> 00:25:45,100
I think we've made tremendous

809
00:25:45,160 --> 00:25:46,680
progress in some
of these areas,

810
00:25:46,680 --> 00:25:48,905
but I'm really excited for

811
00:25:48,905 --> 00:25:51,645
developments in other
areas as well.

812
00:25:53,705 --> 00:25:55,065
And so with that in mind,

813
00:25:55,065 --> 00:25:56,825
data observability
is just getting

814
00:25:56,825 --> 00:25:59,030
started. It's very
much a new term.

815
00:25:59,410 --> 00:26:01,030
It's taken the world
by storm.

816
00:26:01,410 --> 00:26:02,850
We're seeing more
and more data

817
00:26:02,850 --> 00:26:05,190
organizations, implement this

818
00:26:05,385 --> 00:26:06,685
as part of their,

819
00:26:07,385 --> 00:26:09,085
part of their
operational work.

820
00:26:09,625 --> 00:26:11,625
You know, team
syncs to actually

821
00:26:11,625 --> 00:26:13,065
review some dashboards of how

822
00:26:13,065 --> 00:26:14,590
we've improved in
time to detection,

823
00:26:14,590 --> 00:26:15,570
time to resolution.

824
00:26:16,110 --> 00:26:17,010
What are the main,

825
00:26:17,470 --> 00:26:18,910
areas where we
where we're seeing

826
00:26:18,910 --> 00:26:20,830
a higher incident
of data downtime

827
00:26:20,830 --> 00:26:22,975
issues that we want
to work through?

828
00:26:23,515 --> 00:26:24,795
What are the areas where we're

829
00:26:24,795 --> 00:26:25,615
seeing an improvement?

830
00:26:26,395 --> 00:26:27,675
What are the different teams

831
00:26:27,675 --> 00:26:28,875
that are working with us that

832
00:26:28,875 --> 00:26:30,075
we can actually have contracts

833
00:26:30,075 --> 00:26:32,660
and SLAs with in
order to develop

834
00:26:32,660 --> 00:26:34,360
a stronger
organization overall,

835
00:26:34,500 --> 00:26:35,780
sort of going beyond the data

836
00:26:35,780 --> 00:26:36,760
engineering team,

837
00:26:37,060 --> 00:26:38,520
and including all
the stakeholders

838
00:26:38,660 --> 00:26:39,405
that we work with.

839
00:26:40,285 --> 00:26:41,565
So there's a lot more work for

840
00:26:41,565 --> 00:26:43,105
us to to be done here.

841
00:26:43,485 --> 00:26:44,765
I hope this gave you a little

842
00:26:44,765 --> 00:26:46,045
bit of a taste of what data

843
00:26:46,045 --> 00:26:47,745
observability actually is.

844
00:26:48,170 --> 00:26:49,530
I hope you left with a better

845
00:26:49,530 --> 00:26:52,010
sense of some
examples, you know,

846
00:26:52,010 --> 00:26:53,630
maybe something that
you can implement,

847
00:26:54,170 --> 00:26:55,870
and get started
on your journey.

848
00:26:56,685 --> 00:26:59,005
If you'd like to reach
out, feel free.

849
00:26:59,005 --> 00:27:00,285
This is a topic that I'm most

850
00:27:00,285 --> 00:27:01,265
passionate about.

851
00:27:01,565 --> 00:27:03,665
And if you have
an example or a story,

852
00:27:04,100 --> 00:27:06,280
or a bad data horror
story to share,

853
00:27:06,820 --> 00:27:08,280
would love to hear from you.

854
00:27:08,580 --> 00:27:10,180
Thanks so much,
for having me,

855
00:27:10,180 --> 00:27:11,620
and I'm looking
forward to the q

856
00:27:11,620 --> 00:27:12,360
and a portion.


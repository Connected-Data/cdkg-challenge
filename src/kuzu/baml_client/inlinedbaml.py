###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n    temperature 0.3\n  }\n}\n\nclient<llm> Gemini2Flash {\n  provider google-ai\n  options {\n    model \"gemini-2.0-flash\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "extract_keywords.baml": "// Extract the names of tools and technical frameworks mentioned in a talk's transcript\nclass Entity {\n  tag string[] @description(\"ALWAYS lowercase this value\")\n  // leave room for other entities to be added in the future\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractTags(text: string) -> Entity {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Extract techniques/tools/frameworks mentioned in the following text:\n\n    {{ text }}\n\n    {{ ctx.output_format }}\n\n    Return individual names without repetition.\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest TestOne {\n  functions [ExtractTags]\n  args {\n    text #\"\n    But at the same time, still be very suitable for for parallelization with things like Dask and\n    Ray and RAPIDS and Spark and that. So we've been working on a lot of integration. We pull together\n    a lot of packages into this kind of abstraction layer. And I I want to show a few of these here.\n    \"#\n  }\n}\n\n\ntest TestTwo {\n  functions [ExtractTags]\n  args {\n    text #\"\n    However, we've seen that deep learning does a very good job when we don't have to manually compute features.\n    So we'll we'll use some of this, some of this insight and have an encoder, that, bypasses this part of, human\n    engineering. So this would stick our natural input, to an embedding. And that is great, but that that will\n    still not be everything we need to run validation if we didn't have the transition matrix. For that, we can\n    use a transition model, to build this local MDP that where we need in order to run value iteration.\n\n    So we see that usually, in in a lot of the cases, the XAV and the ATC do better than the than the PPO\n    baseline. And something else that is very interesting to notice is the Excelfin does better than HCC,\n    particularly in the first half of the training. So it does well in low data cases, which is one of the main\n    things why we're looking at culling in the first place. So this is quite an encouraging result. To draw some\n    conclusions, we we looked at we presented this this blueprint, that is applicable if we know a specific algorithm\n    will be of interest for solving a natural, a real world task. So we, we see that real world solutions can benefit\n    from combining classic algorithms with neural networks, and this is one way of going about it. Then we build on\n    the on the findings that graph neural networks are particularly well suited to imitate some algorithms,\n    in particular dynamic programming algorithms.\n    \"#\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.78.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "graphrag.baml": "// --- Data models ---\nclass Cypher {\n  query string\n}\n\nclass Answer {\n  question string\n  answer string\n}\n\n// --- Functions ---\n\nfunction RAGText2Cypher(schema: string, question: string) -> Cypher {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an expert in translating natural language questions into Cypher statements.\n    You will be provided with a question and a graph schema.\n    Use only the provided relationship types and properties in the schema to generate a Cypher\n    statement.\n    The Cypher statement could retrieve nodes, relationships, or both.\n    Do not include any explanations or apologies in your responses.\n    Do not respond to any questions that might ask anything else than for you to construct a\n    Cypher statement.\n    Answer in no more than 5 sentences\n\n    {{ _.role(\"user\") }}\n    Task: Generate a Cypher statement to query a graph database.\n\n    {{ schema}}\n\n    The question is:\n    {{ question }}\n\n    Instructions:\n    1. Use only the provided node and relationship types and properties in the schema.\n    2. When returning results, return property values rather than the entire node or relationship.\n    3. ALWAYS use the WHERE clause to compare string properties, and compare them using the\n       LOWER() function.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction RAGAnswerQuestion(question: string, context: string) -> Answer {\n  client CustomGPT4oMini\n  prompt #\"\n    You are an AI assistant using Retrieval-Augmented Generation (RAG).\n    RAG enhances your responses by retrieving relevant information from a knowledge base.\n    You will be provided with a question and relevant context. Use only this context to answer\n    the question.\n    Do not make up an answer. If you don't know the answer, say so clearly.\n    Always strive to provide concise, helpful, and context-aware answers.\n\n    {{ _.role(\"user\") }}\n    QUESTION: {{ question }}\n    RELEVANT CONTEXT: {{ context }}\n\n    {{ ctx.output_format }}\n\n    RESPONSE:\n  \"#\n}\n\n\ntest Text2Cypher1 {\n  functions [RAGText2Cypher]\n  args {\n    schema #\"\n    ALWAYS RESPECT THE EDGE DIRECTIONS:\n    ---\n    (:Talk) -[:IS_DESCRIBED_BY]-> (:Tag)\n    (:Speaker) -[:GIVES_TALK]-> (:Talk)\n    (:Talk) -[:IS_PART_OF]-> (:Event)\n    (:Talk) -[:IS_CATEGORIZED_AS]-> (:Category)\n    ---\n\n    Node properties:\n    - Tag\n        - keyword: string\n    - Talk\n        - title: string\n        - category: string\n        - url: string\n        - description: string\n        - type: string\n    - Speaker\n        - name: string\n    - Event\n        - name: string\n        - description: string\n    - Category\n        - name: string\n\n    Edge properties:\n    - GIVES_TALK\n        - date: date\n    \"#\n    question \"Who are the speakers whose talks have the tag 'rdf'? Return the speaker names as a numbered list.\"\n  }\n  @@assert(has_return_clause, {{ 'RETURN' in this.query }})\n}\n\ntest RAGAnswer1 {\n  functions [RAGAnswerQuestion]\n  args {\n    question \"Who are the speakers whose talks have the tag 'rdf'? Return the speaker names as a numbered list.\"\n    context #\"\n        ['Marcus NÃ¶lke', 'Veronika Heimsbakk', 'Dave Duggal', 'Kurt Cagle', 'Sebastian Schmidt', 'Veronique Moore', 'Atanas Kiryakov', 'Ora Lassila']\n    \"#\n  }\n}\n\ntest RAGMissingContext {\n  functions [RAGAnswerQuestion]\n  args {\n    question \"What did Paco Nathan say about RDF?\"\n    context \"\"\n  }\n}\n",
}

def get_baml_files():
    return file_map